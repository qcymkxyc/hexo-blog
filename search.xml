<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>人物背景抠图 (二)</title>
    <url>/posts/cc52d48c.html/</url>
    <content><![CDATA[<h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><h2 id="当前效果"><a href="#当前效果" class="headerlink" title="当前效果"></a>当前效果</h2><p>本文章是对<a href="/posts/10cdf8fe.html/" title="人物背景抠图">人物背景抠图</a>的改进,先看效果图:</p>
<p><strong>原图像:</strong></p>
<p><img src="/posts/cc52d48c.html/%E6%95%88%E6%9E%9C%E5%8E%9F%E5%9B%BE%E5%83%8F-1580099162567.png" alt></p>
<p><strong>本次替换后:</strong></p>
<p><img src="/posts/cc52d48c.html/%E6%94%B9%E8%BF%9B%E6%95%88%E6%9E%9C.png" alt></p>
<h2 id="原效果"><a href="#原效果" class="headerlink" title="原效果"></a>原效果</h2><p>对比<a href="/posts/10cdf8fe.html/" title="人物背景抠图">人物背景抠图</a>中的效果:</p>
<p><img src="/posts/cc52d48c.html/%E6%95%88%E6%9E%9C%E5%9B%BE-1580099178206.png" alt></p>
<p>可以看到,针对原效果中结果不太好的有明显改进.例如第一行第四张图片,人物的头发处有许多的”空洞”,在改进后得到了填充;第二行第一张图片,原效果背景也有许多”空洞”,改进后有明显改善.</p>
<h1 id="过程及思路"><a href="#过程及思路" class="headerlink" title="过程及思路"></a>过程及思路</h1><p>事实上,对于这个特定任务,分离前景和背景,前景对象有且仅有一个,从图(数据结构中的图)的角度上看,我只需要找到一个连通域即可,其他的连通域都可以看成是误识别的结果,应该合并成背景.并且,这个前景对应的连通域应该是最大的连通域.下面介绍过程:</p>
<p>下面是对原图像进行掩膜后的结果(开运算后):</p>
<p><img src="/posts/cc52d48c.html/%E5%BC%80%E8%BF%90%E7%AE%97%E7%BB%93%E6%9E%9C.png" alt></p>
<p>可以看到一般效果较好的图片对应的掩膜结果都比较成型,且仅有一个连通域,而效果不好的有多个连通域,通常情况下,最大的连通域就是人物,所以,我们选择最大的连通域作为掩膜结果,下面以第一行第4张图片为例,在得到掩膜结果后我们对连通域编号,并计算每个连通域的大小:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取连通图并找出最大连通图</span></span><br><span class="line">contours,hierarchy = cv2.findContours(template_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">areas = list()</span><br><span class="line"><span class="keyword">for</span> contour <span class="keyword">in</span> contours:</span><br><span class="line">    areas.append(cv2.contourArea(contour))</span><br><span class="line">max_contour_index = np.argmax(areas)</span><br><span class="line">print(<span class="string">"最大连通图: &#123;&#125;"</span>.format(max_contour_index))</span><br></pre></td></tr></table></figure>

<p>在得到每个连通域大小后,找到最大的连通域:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w,h = template_img.shape</span><br><span class="line">black_back = np.zeros(shape=(w,h,<span class="number">3</span>))</span><br><span class="line">plt.imshow(cv2.drawContours(black_back, contours, max_contour_index, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>下面是最大连通域对应的外边框:</p>
<p><img src="/posts/cc52d48c.html/%E6%9C%80%E5%A4%A7%E8%BF%9E%E9%80%9A%E5%9F%9F.png" alt></p>
<p>最大连通域中有许多背景空洞,我们需要填充:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">template_img = np.zeros(shape=template_img.shape)</span><br><span class="line">template_img = cv2.fillConvexPoly(template_img,contours[max_contour_index],(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br></pre></td></tr></table></figure>

<p>最终结果:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r_img = replace_img(img,template_img,back_img)</span><br><span class="line">plt.imshow(r_img)</span><br></pre></td></tr></table></figure>

<p><img src="/posts/cc52d48c.html/%E5%8D%95%E5%9B%BE%E6%B5%8B%E8%AF%95.png" alt></p>
<h1 id="问题及改进思路"><a href="#问题及改进思路" class="headerlink" title="问题及改进思路"></a>问题及改进思路</h1><h2 id="前景和背景边缘问题"><a href="#前景和背景边缘问题" class="headerlink" title="前景和背景边缘问题"></a>前景和背景边缘问题</h2><blockquote>
<p>如上图,前景和背景是有明显的毛边的.事实上,在之前的步骤中,并没有利用边缘检测技术对边缘修正,或者,现在我们的前景和背景已经大致的分出来了,利用Graph Cut或Grab Cut算法来修正应该更加精准.</p>
</blockquote>
<h2 id="前景和背景颜色相近问题"><a href="#前景和背景颜色相近问题" class="headerlink" title="前景和背景颜色相近问题"></a>前景和背景颜色相近问题</h2><blockquote>
<p>这个问题并没有想到解决办法,Grab Cut对于此类问题效果并不理想.或许利用Selective Search中的动态阈值来修正前景和背景效果会比较好,但我并没有尝试过.</p>
</blockquote>
]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>Demo</tag>
      </tags>
  </entry>
  <entry>
    <title>用YOLO3实现犬种实时检测</title>
    <url>/posts/fa14c502.html/</url>
    <content><![CDATA[<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>利用YOLO v3实现的犬种实时检测的一次记录,下面是检测结果:</p>
<h3 id="单个大目标"><a href="#单个大目标" class="headerlink" title="单个大目标:"></a>单个大目标:</h3>
        <style>.bbplayer{width: 100%; height: 500px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" src="//player.bilibili.com/player.html?aid=86257908&page=1&high_quality=1&danmaku=true" allowfullscreen="allowfullscreen" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        

<h3 id="多个小目标"><a href="#多个小目标" class="headerlink" title="多个小目标:"></a>多个小目标:</h3>
        <style>.bbplayer{width: 100%; height: 500px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" src="//player.bilibili.com/player.html?aid=86258451&page=1&high_quality=1&danmaku=true" allowfullscreen="allowfullscreen" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        

<p>FPS大概12左右(!-_- ,显卡1060)</p>
<h3 id="测试集结果"><a href="#测试集结果" class="headerlink" title="测试集结果:"></a>测试集结果:</h3><p><img src="/posts/fa14c502.html/combine_image_result.jpg" alt></p>
<p>上图中蓝色的框表示Ground Truth,红色的框表示Bounding Box</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据来自于ImageNet的<a href="http://vision.stanford.edu/aditya86/ImageNetDogs" target="_blank" rel="noopener">ImageNetDogs</a>,共有120个犬种,20580张图片</p>
<p>由于这里仅是用于检测狗,所以我这里把所有的犬种合为一类,也就是说,class仅有dog一个标签,在yolo v3中对应一个logistic</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>tensorflow-gpu-1.1.3</li>
<li>keras-2.1.5</li>
<li>GTX 1060</li>
</ul>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>训练模型也是在现有的YOLO v3的基础上做fine-tune,<a href="https://github.com/qqwweee/keras-yolo3" target="_blank" rel="noopener">git仓库地址</a></p>
<h3 id="整理数据"><a href="#整理数据" class="headerlink" title="整理数据"></a>整理数据</h3><p>即整理出适合模型的输入形式,以txt文件保存,如下,具体代码不再阐述.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_4801.jpg  <span class="number">93</span>,<span class="number">145</span>,<span class="number">218</span>,<span class="number">371</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_20429.jpg  <span class="number">205</span>,<span class="number">78</span>,<span class="number">336</span>,<span class="number">323</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_5080.jpg  <span class="number">170</span>,<span class="number">73</span>,<span class="number">370</span>,<span class="number">374</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_19261.jpg  <span class="number">26</span>,<span class="number">16</span>,<span class="number">473</span>,<span class="number">481</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_5732.jpg  <span class="number">96</span>,<span class="number">79</span>,<span class="number">267</span>,<span class="number">442</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_4952.jpg  <span class="number">12</span>,<span class="number">0</span>,<span class="number">499</span>,<span class="number">374</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_5066.jpg  <span class="number">85</span>,<span class="number">0</span>,<span class="number">330</span>,<span class="number">490</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_3817.jpg  <span class="number">121</span>,<span class="number">111</span>,<span class="number">468</span>,<span class="number">330</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_4369.jpg  <span class="number">249</span>,<span class="number">34</span>,<span class="number">499</span>,<span class="number">333</span>,<span class="number">0</span> <span class="number">37</span>,<span class="number">41</span>,<span class="number">291</span>,<span class="number">334</span>,<span class="number">0</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>格式为(图片地址 GroundTruth1信息 GroundTruth2信息 ..),每个Ground Truth信息为(x_min,y_min,x_max,y_max,classID),即左上角坐标,右下角坐标以及类别ID</p>
</blockquote>
<h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><blockquote>
<p>主要修改yolov3.cfg文件中的配置</p>
<ul>
<li>三个不同尺度的Feature Map对应的filter均改为改为18,仅有一类</li>
<li>batch改为8(显存限制)</li>
<li>random为1.(调整不同尺寸的图片输入,保证效果)</li>
</ul>
</blockquote>
<h3 id="Anchor-Box聚类"><a href="#Anchor-Box聚类" class="headerlink" title="Anchor Box聚类"></a>Anchor Box聚类</h3><p>(个人认为这是比较重要的一步,后面会说明),通过kmeans对Ground Truth进行kmeans聚类,以此确定Anchor Box的尺寸.所用的衡量标准$1-IOU(ground truth,centroid)$.其中,$centroid$表示聚点的数值,聚类的结果:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">K anchors:</span><br><span class="line"> [[<span class="number">138</span> <span class="number">178</span>]</span><br><span class="line"> [<span class="number">153</span> <span class="number">322</span>]</span><br><span class="line"> [<span class="number">155</span> <span class="number">189</span>]</span><br><span class="line"> [<span class="number">195</span> <span class="number">246</span>]</span><br><span class="line"> [<span class="number">251</span> <span class="number">174</span>]</span><br><span class="line"> [<span class="number">281</span> <span class="number">309</span>]</span><br><span class="line"> [<span class="number">338</span> <span class="number">295</span>]</span><br><span class="line"> [<span class="number">410</span> <span class="number">331</span>]</span><br><span class="line"> [<span class="number">412</span> <span class="number">222</span>]]</span><br><span class="line">Accuracy: <span class="number">91.20</span>%</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里的Accuracy是每个Ground Truth和聚点的平均IOU</p>
</blockquote>
<p><strong>对应的9个Anchor Box散点图(没错,这真的是聚类的结果)</strong></p>
<p><img src="/posts/fa14c502.html/AnchorBox%E8%81%9A%E7%B1%BB.png" alt></p>
<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><p>在台式机上跑了大概两天.但loss一直降不下来,一直维持在17左右.(我怀疑这可能和图片的质量有关,在测试集的示例可以看到,有些样本是没有标记框的,这可能导致loss降不下来,后面总结部分我会详细说明)</p>
<p><img src="/posts/fa14c502.html/val_loss.png" alt></p>
<p>在训练后期,学习率调小至1e-8,但对loss都没什么影响,最多减小0.5左右</p>
<h2 id="问题总结以及改进"><a href="#问题总结以及改进" class="headerlink" title="问题总结以及改进"></a>问题总结以及改进</h2><h3 id="关于Anchor-Box聚类"><a href="#关于Anchor-Box聚类" class="headerlink" title="关于Anchor Box聚类"></a>关于Anchor Box聚类</h3><blockquote>
<p>很多博客上说Anchor Box的聚类对最终结果的影响不大,但是在这个数据集上,聚类的效果挺明显的(可能是数据集本身的差异),下面是用源生的yolo3下的Anchor Box(这个应该是VOC数据集的Anchor Box)训练的结果:</p>
</blockquote>

        <style>.bbplayer{width: 100%; height: 500px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" src="//player.bilibili.com/player.html?aid=86258451&page=2&high_quality=1&danmaku=true" allowfullscreen="allowfullscreen" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        

<blockquote>
<p>对比开始的<a href="#多个小目标">检测视频</a>,可以看到改进还是挺明显的.</p>
</blockquote>
<h3 id="关于模型Loss"><a href="#关于模型Loss" class="headerlink" title="关于模型Loss"></a>关于模型Loss</h3><p>模型loss分两个方面.</p>
<ol>
<li>loss下降到一定的数值就难以下降,大概在17左右</li>
</ol>
<blockquote>
<p>这可能和数据本身的质量有关,因为数据集本身是针对不同的犬种进行标注,并不是对”狗”这个种类进行标注,所以导致有些图片缺少标记框,比如下面几张图片数据:</p>
<p><img src="/posts/fa14c502.html/14.jpg" alt></p>
<p><img src="/posts/fa14c502.html/24.jpg" alt></p>
<p><img src="/posts/fa14c502.html/206.jpg" alt></p>
<p>一旦模型检测出没有标记的狗,就相当于训练数据”告诉”模型检测是错误的,所以,loss居高不下.另外,这也反过来影响模型的表现,此时模型已经不知道孰对孰错了.</p>
<p>所以,要想降低loss,需要对数据进行重新标注,理论上loss应该会下降.</p>
</blockquote>
<ol start="2">
<li>验证集的loss总是低于训练集的loss</li>
</ol>
<blockquote>
<p>在训练的过程中,验证集的loss总是低于训练集的loss,不知道是何原因,这个问题至今无法解决.</p>
</blockquote>
<h3 id="侧面目标效果差"><a href="#侧面目标效果差" class="headerlink" title="侧面目标效果差"></a>侧面目标效果差</h3><blockquote>
<p> 侧面目标检测效果很差,很多时候检测不出或者置信度很低(这其实在测试视频中也有所反应):</p>
<p><img src="/posts/fa14c502.html/12.jpg" alt></p>
<p><img src="/posts/fa14c502.html/26.jpg" alt></p>
<p><img src="/posts/fa14c502.html/143.jpg" alt></p>
<p>可能是由于数据集中侧面图片比较少的关系,需要在原有数据集上对侧面图片做上采样(比如Mix Up,加噪声等).总之,就是增加这类图片的数据量,再放入模型训练.</p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>Demo</tag>
        <tag>原创</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOV3总结</title>
    <url>/posts/69cad793.html/</url>
    <content><![CDATA[<p>总的来说,YOLO V3针对V2的改进并不多,有以下几点: </p>
<ol>
<li><p>网络结构的改变</p>
<blockquote>
<p>YOLO V3采用Darknet-53 的网络结构,整个网络采用全卷积结构,相比于ResNet-152和ResNet-101强很多,速度也更快</p>
</blockquote>
</li>
<li><p>Anchor Box</p>
<blockquote>
<p>由于 YOLO V1和V2 都对小目标支持不好,所以,V3在这上面作出了改进,对大中小目标分别进行处理,大目标的Feature Map缩小,中小目标的Feature Map呈放大</p>
<p>V3的Anchor Box一共9个,大中小各3个</p>
</blockquote>
</li>
<li><p>Loss Function</p>
<blockquote>
<p>V3不再用softmax,而是用logistic(即对每一类做logistic),其目的还是对应V2中出现</p>
</blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>KCF目标跟踪测试</title>
    <url>/posts/849e7948.html/</url>
    <content><![CDATA[
        <style>.bbplayer{width: 100%; height: 500px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" src="//player.bilibili.com/player.html?aid=85098088&page=1&high_quality=1&danmaku=true" allowfullscreen="allowfullscreen" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        ]]></content>
      <categories>
        <category>目标跟踪</category>
      </categories>
      <tags>
        <tag>Demo</tag>
        <tag>目标跟踪</tag>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title>mAP的计算总结</title>
    <url>/posts/b8ba7454.html/</url>
    <content><![CDATA[<p>mAP是目标检测中最为常见的指标,要了解mAP(mean Average Precision),就必须了解recall和precision(目标检测中这两个指标的计算和略有机器学习不同)</p>
<table>
<thead>
<tr>
<th align="right">真\预</th>
<th align="center">正</th>
<th align="left">负</th>
</tr>
</thead>
<tbody><tr>
<td align="right">正</td>
<td align="center">TP</td>
<td align="left">FN</td>
</tr>
<tr>
<td align="right">负</td>
<td align="center">FP</td>
<td align="left">TN</td>
</tr>
</tbody></table>
<p>首先,在进行目标检测时,预测出一个BBox,和对应某类i的概率$P_i$,给出一个阈值$t$,即可以判断出预测是否是这一类,即判定上表中在第一列还是第二列.</p>
<p>然后,对于上一部中分到第一列的,计算BBox和Ground Truth的IOU,大于0.5的标为TP,小于为FP.最后,对于1中第二列的标为FN.</p>
<p>根据公式:</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true">
    <mlabeledtr>
      <mtd id="mjx-eqn-1_1">
        <mtext>(1)</mtext>
      </mtd>
      <mtd>
        <mrow>
          <mo>{</mo>
          <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
            <mtr>
              <mtd>
                <mi>R</mi>
                <mo>=</mo>
                <mi>T</mi>
                <mi>P</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>/</mo>
                </mrow>
                <mo stretchy="false">(</mo>
                <mi>T</mi>
                <mi>P</mi>
                <mo>+</mo>
                <mi>F</mi>
                <mi>N</mi>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mi>P</mi>
                <mo>=</mo>
                <mi>T</mi>
                <mi>P</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>/</mo>
                </mrow>
                <mo stretchy="false">(</mo>
                <mi>F</mi>
                <mi>P</mi>
                <mo>+</mo>
                <mi>T</mi>
                <mi>P</mi>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
          <mo fence="true" stretchy="true" symmetric="true"></mo>
        </mrow>
      </mtd>
    </mlabeledtr>
  </mtable>
</math>



<!--
$$
\begin{cases} R = TP/(TP+FN) \\ P=TP/(FP + TP)\end{cases}
$$



-->

<p>对于上述给定的阈值t,逐渐减小,可形成多组RP数据对,在坐标上绘制,其与坐标轴围成的面积即为AP值.</p>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>目标检测</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLO9000总结</title>
    <url>/posts/5ca973ed.html/</url>
    <content><![CDATA[<p>YOLO9000备忘</p>
<h2 id="Better"><a href="#Better" class="headerlink" title="Better:"></a>Better:</h2><ol>
<li><p>Batch Normalization</p>
</li>
<li><p>高分辨率:即用高分辨率图片,文中用$448 \times 448$</p>
</li>
<li><p>使用Anchor Box</p>
<blockquote>
<p>YOLO V2在使用Anchor Box之后,每一个Anchor Boox包含预测类别+5(4个位置,一个置信度)为数据,文中的Feature Map为$13 \times 13$,5个Anchor Box,20个类别,输出维数就为$13 \times 13 \times 5 \times 25$</p>
<p>并且,V2的Anchor Box不是手动设置的,而是用训练集上的Ground Truth聚类的,所用的衡量标准为$1 - IOU(box,centroid)$</p>
</blockquote>
</li>
<li><p>约束预测边框位置</p>
<blockquote>
<p>V1 预测的Box中随意,中心可以是任意位置,者造成训练时尤其是初期不稳定,V2在位置上包一层sigmoid函数,是的中心落在Feature Map的方框内,这样更稳定.</p>
</blockquote>
</li>
<li><p>细分类特征(即加入PassThrough层)</p>
<blockquote>
<p>Pass Through层类似做步数为2的Pooling,按照相同位置组合成4个块,最后再在通道上叠加,比如上一层的输出为$26 \times 26 \times 512$,拆分成$4 \times 13 \times 13 \times 512$ 最后组成$13 \times 13 \times 3072$</p>
</blockquote>
<p><img src="/posts/5ca973ed.html/passthrough1.jpg" alt></p>
<p><img src="/posts/5ca973ed.html/passthrough2.jpg" alt></p>
</li>
<li><p>多尺度训练</p>
<blockquote>
<p>即以不同的尺寸进行训练</p>
</blockquote>
</li>
</ol>
<h2 id="Faster"><a href="#Faster" class="headerlink" title="Faster:"></a>Faster:</h2><p>采用Darknet-19网络结构</p>
<h2 id="Stronger-YOLO-9000"><a href="#Stronger-YOLO-9000" class="headerlink" title="Stronger(YOLO 9000)"></a>Stronger(YOLO 9000)</h2><p>为了能识别9000个目标,构建了一个WordTree,与一般的softmax不同的是类别本身和气父节点均需标记为1.比如Dog,在Animal位置也需标记为1.</p>
<p><img src="/posts/5ca973ed.html/WordTree.png" alt="&#39;WordTree&#39;"></p>
<p>在预测时,一个类别的概率为根节点到该节点所有概率的乘积,如<br>$$<br>P(Hunting Dog)=p(Hunting Dog|Dog, Animal)P(Dog| Animal)<br>$$<br>其中,由于Animal处于根节点有$P(Animal)=1$</p>
<p>注:在实际计算绝对概率时,并不会真的计算每一个子节点的概率,而是采用贪婪算法,当从根节点项子节点走时,如果小于阈值,则不在向下走了.</p>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLO V1总结</title>
    <url>/posts/16c1a0a5.html/</url>
    <content><![CDATA[<p>YOLO v1的总结,备忘</p>
<h2 id="网络设计"><a href="#网络设计" class="headerlink" title="网络设计"></a>网络设计</h2><p>YOLO算法的设计理念是将图像分成$s \times s$的网络结构,每个网格分别来判定是否目标在其中,这其中运用了用卷积层来代替全连接层,这项技术是Idea的关键.所以最终的结果是</p>
<p>$$s \times  s \times(B \times 5 + C)$$</p>
<p>其中,B表示BBox的个数,C代表类别个数,5表示(x,y,w,h,confidence)</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>由于YOLO算法是将图像切割成方格并预测的思想,所以对图像的输入尺寸并不敏感.</p>
<p>在输出方面,如下图所示:</p>
<p><img src="/posts/16c1a0a5.html/YOLOV1%E7%BB%93%E6%9E%84.jpg" alt></p>
<ol>
<li>Feature Map中的一个值给出一个预测,为何输出中却是两个BBox?</li>
</ol>
<blockquote>
<p>YOLO由3类标签组成:类别,置信度,BBox位置.其中Feature Map中的一个值有两个BBox,而仅有一个One-Hot类别向量.之所以用两个BBox,文中的解释是:两个BBox用结果好的那个,另一个舍去,这样总好过仅用一个BBox的结果.</p>
<p>那么,怎么样判定哪一个BBox结果好呢,答案是IOU,即$IOU_{pred}^{truth}$,选择IOU大的那个</p>
</blockquote>
<ol start="2">
<li>训练集中的confidence如何确定?</li>
</ol>
<blockquote>
<p>在1中可以得到$IOU_{pred}^{truth}$,如果该Feature Map值中有物体,则为IOU,否则为0.</p>
<p>$$ confidenc标签=\begin{cases} IOU_{pred}^{truth},&amp;有物体\ 0,&amp;无物体 \end{cases}$$</p>
<p>值得说明的是,两个BBox,一个为$IOU_{pred}^{truth}$,另一个的confidence也为0</p>
</blockquote>
<ol start="3">
<li>LOSS函数</li>
</ol>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true">
    <mlabeledtr>
      <mtd id="mjx-eqn-1">
        <mtext>(1)</mtext>
      </mtd>
      <mtd>
        <mi>L</mi>
        <mi>o</mi>
        <mi>s</mi>
        <mi>s</mi>
        <mo>=</mo>
        <msub>
          <mi>&#x03BB;<!-- λ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>c</mi>
            <mi>o</mi>
            <mi>o</mi>
            <mi>r</mi>
            <mi>d</mi>
          </mrow>
        </msub>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msup>
              <mi>S</mi>
              <mn>2</mn>
            </msup>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">[</mo>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>x</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>x</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>y</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>y</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo stretchy="false">]</mo>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <msub>
          <mi>&#x03BB;<!-- λ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>c</mi>
            <mi>o</mi>
            <mi>o</mi>
            <mi>r</mi>
            <mi>d</mi>
          </mrow>
        </msub>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msup>
              <mi>S</mi>
              <mn>2</mn>
            </msup>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">[</mo>
          <mo stretchy="false">(</mo>
          <msqrt>
            <msub>
              <mi>w</mi>
              <mi>i</mi>
            </msub>
          </msqrt>
          <mo>&#x2212;<!-- − --></mo>
          <msqrt>
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <msub>
                  <mi>w</mi>
                  <mi>i</mi>
                </msub>
                <mo stretchy="false">&#x005E;<!-- ^ --></mo>
              </mover>
            </mrow>
          </msqrt>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <mo stretchy="false">(</mo>
        <msqrt>
          <msub>
            <mi>h</mi>
            <mi>i</mi>
          </msub>
        </msqrt>
        <mo>&#x2212;<!-- − --></mo>
        <msqrt>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>h</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </msqrt>
        <msup>
          <mo stretchy="false">)</mo>
          <mn>2</mn>
        </msup>
        <mo stretchy="false">]</mo>
        <mo>+</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>S</mi>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>c</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>c</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <msub>
          <mi>&#x03BB;<!-- λ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
            <mi>o</mi>
            <mi>o</mi>
            <mi>b</mi>
            <mi>j</mi>
          </mrow>
        </msub>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>S</mi>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>n</mi>
              <mi>o</mi>
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>c</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>c</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msup>
              <mi>S</mi>
              <mn>2</mn>
            </msup>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <munder>
            <mo>&#x2211;<!-- ∑ --></mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>C</mi>
              <mo>&#x2208;<!-- ∈ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>c</mi>
                <mi>l</mi>
                <mi>a</mi>
                <mi>s</mi>
                <mi>s</mi>
              </mrow>
            </mrow>
          </munder>
          <mo stretchy="false">[</mo>
          <msub>
            <mi>p</mi>
            <mi>i</mi>
          </msub>
          <mo stretchy="false">(</mo>
          <mi>c</mi>
          <mo stretchy="false">)</mo>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>p</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <mo stretchy="false">(</mo>
          <mi>c</mi>
          <mo stretchy="false">)</mo>
          <msup>
            <mo stretchy="false">]</mo>
            <mn>2</mn>
          </msup>
        </mstyle>
      </mspace></mspace></mspace></mspace></mtd>
    </mlabeledtr>
  </mtable>
</math>

<!-- 以下公式hexo无法换行,用以下公式生成MathML,粘贴在上面
$$
Loss=\lambda_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}\large 1_{ij}^{obj}[(x_i-\hat{x_i})^2+(y_i-\hat{y_i})^2] + \\
\lambda_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}\large 1_{ij}^{obj}[(\sqrt{w_i}-\sqrt{\hat{w_i}})^2+\\
(\sqrt{h_i}-\sqrt{\hat{h_i}})^2]+ \sum_{i=0}^{S}\sum_{j=0}^{B} \large 1_{ij}^{obj} (c_i-\hat{c_i})^2 + \\ 
\lambda_{noobj}\sum_{i=0}^{S}\sum_{j=0}^{B} \large 1_{ij}^{noobj} (c_i-\hat{c_i})^2 +\\
\sum_{i=0}^{S^2}\large 1_{ij}^{obj}\sum_{C\in{class}}[p_i(c)-\hat{p_i}(c)]^2
$$
-->

<p>YOLO 算法的LOSS是一个L2 LOSS</p>
<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>对于模型得出的$S\times S \times 2$个BBox</p>
<blockquote>
<ol>
<li><p>先用NMS得出一系列BBox(依据是confidence)</p>
</li>
<li><p>再在这些框中选最大概率的类别</p>
</li>
</ol>
</blockquote>
<h2 id="优点以及缺点"><a href="#优点以及缺点" class="headerlink" title="优点以及缺点"></a>优点以及缺点</h2><blockquote>
<p>优点:</p>
<ol>
<li>速度快</li>
<li>End-2-End</li>
</ol>
<p>缺点: </p>
<ol>
<li><p>小物体效果不好</p>
</li>
<li><p>定位不准确    </p>
</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>人物背景抠图</title>
    <url>/posts/10cdf8fe.html/</url>
    <content><![CDATA[<h2 id="示例图片"><a href="#示例图片" class="headerlink" title="示例图片"></a>示例图片</h2><p>免冠照人物背景抠图实现,先展示一下示例结果:</p>
<p><img src="/posts/10cdf8fe.html/%E5%8E%9F%E5%A7%8B%E7%A4%BA%E4%BE%8B%E5%9B%BE%E7%89%87.png" alt></p>
<p>人物背景抠图后:</p>
<p><img src="/posts/10cdf8fe.html/%E6%9B%BF%E6%8D%A2%E7%A4%BA%E4%BE%8B%E5%9B%BE%E7%89%87.png" alt></p>
<h2 id="执行步骤"><a href="#执行步骤" class="headerlink" title="执行步骤"></a>执行步骤</h2><h3 id="将RGB空间转换为HSV空间"><a href="#将RGB空间转换为HSV空间" class="headerlink" title="将RGB空间转换为HSV空间"></a>将RGB空间转换为HSV空间</h3><p>首先需要统计出背景(蓝色部分)的颜色范围,这里将RGB空间转换为HSV空间,然后只用H分量统计,就可以统计出蓝色背景的大概范围:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">blue_photo_hsv = cv2.cvtColor(blue_photo,cv2.COLOR_RGB2HSV)</span><br><span class="line">h_ele = blue_photo_hsv[:,:,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<h3 id="做H分量的统计"><a href="#做H分量的统计" class="headerlink" title="做H分量的统计"></a>做H分量的统计</h3><p>为了简单起见,这里截取上1/6的部分图像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">sns.set_style(<span class="string">"darkgrid"</span>)</span><br><span class="line"></span><br><span class="line">w,h,_= blue_photo_hsv.shape</span><br><span class="line">hist_bins = plt.hist(blue_photo_hsv[:int(w/<span class="number">6</span>),:,<span class="number">0</span>].flatten(),bins = <span class="number">60</span>)</span><br></pre></td></tr></table></figure>

<p>直方图统计结果:</p>
<p><img src="/posts/10cdf8fe.html/%E7%9B%B4%E6%96%B9%E5%9B%BE%E7%BB%93%E6%9E%9C.png" alt></p>
<h3 id="掩膜"><a href="#掩膜" class="headerlink" title="掩膜"></a>掩膜</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lower_h = hist_bins[<span class="number">1</span>][hist_bins[<span class="number">0</span>].argmax()]</span><br><span class="line">bins_interval = hist_bins[<span class="number">1</span>][<span class="number">1</span>] - hist_bins[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">upper_h = lower_h + <span class="number">1</span> * bins_interval</span><br><span class="line">lower = np.array([lower_h,<span class="number">43</span>,<span class="number">46</span>])</span><br><span class="line">upper = np.array([upper_h,<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line"></span><br><span class="line">mask = cv2.inRange(blue_photo_hsv, lower,upper)</span><br><span class="line">plt.imshow(mask)</span><br></pre></td></tr></table></figure>

<p>掩膜结果:</p>
<p><img src="/posts/10cdf8fe.html/%E6%8E%A9%E8%86%9C%E7%BB%93%E6%9E%9C.png" alt="&#39;掩膜结果&#39;"></p>
<h3 id="腐蚀和膨胀"><a href="#腐蚀和膨胀" class="headerlink" title="腐蚀和膨胀"></a>腐蚀和膨胀</h3><p>腐蚀的目的是去除分割线周围的噪声,膨胀是填补掩膜结果中的小空白.这里的腐蚀和膨胀的模板都是用的3*3</p>
<p>腐蚀:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 取反</span></span><br><span class="line">mask = <span class="number">255</span> - mask</span><br><span class="line"><span class="comment"># 边长</span></span><br><span class="line">side_len = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">kernel = np.ones((side_len,side_len))</span><br><span class="line">erode_img = cv2.erode(mask,kernel,iterations = <span class="number">1</span>)</span><br><span class="line">erode_img.shape</span><br><span class="line">plt.imshow(erode_img)</span><br></pre></td></tr></table></figure>

<p>腐蚀后结果:</p>
<p><img src="/posts/10cdf8fe.html/%E8%85%90%E8%9A%80%E5%90%8E.png" alt="&#39;腐蚀后结果&#39;"></p>
<p>膨胀:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">side_len =<span class="number">3</span></span><br><span class="line"></span><br><span class="line">kernel = np.ones((side_len,side_len))</span><br><span class="line">dilate_img = cv2.dilate(erode_img,kernel,iterations = <span class="number">1</span>)</span><br><span class="line">plt.imshow(dilate_img)</span><br></pre></td></tr></table></figure>

<p>膨胀后:</p>
<p><img src="/posts/10cdf8fe.html/%E8%86%A8%E8%83%80%E5%90%8E.png" alt="&#39;膨胀后&#39;"></p>
<h3 id="替换背景"><a href="#替换背景" class="headerlink" title="替换背景"></a>替换背景</h3><p>一旦替换模板比较准确,人物背景抠图就比较容易了.下面是背景图:</p>
<p><img src="/posts/10cdf8fe.html/%E8%83%8C%E6%99%AF%E5%9B%BE.png" alt="&#39;背景图&#39;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n_row,n_col = dilate_img.shape</span><br><span class="line"></span><br><span class="line">start_coor = [<span class="number">10</span>,<span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> range(n_row):</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> range(n_col):</span><br><span class="line">        <span class="keyword">if</span> dilate_img[row][col] == <span class="number">255</span>:</span><br><span class="line">            back_img[start_coor[<span class="number">0</span>] + row][start_coor[<span class="number">1</span>] + col] = blue_photo[row][col]</span><br><span class="line"></span><br><span class="line">plt.imshow(back_img)</span><br></pre></td></tr></table></figure>

<p>根据模板替换后:</p>
<p><img src="/posts/10cdf8fe.html/%E6%9B%BF%E6%8D%A2%E7%A4%BA%E4%BE%8B%E5%9B%BE%E7%89%87-1580097685097.png" alt="&#39;人物背景抠图后&#39;"></p>
<p>最后根据原有的图片尺寸切割出结果图像就可以实现替换了.</p>
<h2 id="多图测试"><a href="#多图测试" class="headerlink" title="多图测试"></a>多图测试</h2><p>网上爬取了十张大小不一图像测试,缩放到200*150(如有侵权请告知,谢谢).</p>
<p>原图像:</p>
<p><img src="/posts/10cdf8fe.html/%E6%95%88%E6%9E%9C%E5%8E%9F%E5%9B%BE%E5%83%8F-1580099162567.png" alt></p>
<p>替换后:</p>
<p><img src="/posts/10cdf8fe.html/%E6%95%88%E6%9E%9C%E5%9B%BE-1580099178206.png" alt></p>
]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>Demo</tag>
        <tag>原创</tag>
      </tags>
  </entry>
</search>
