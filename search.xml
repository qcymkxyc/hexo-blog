<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>伤寒论(郝万山)</title>
    <url>/posts/e9892345.html/</url>
    <content><![CDATA[


# 太阳病辩证并治

## 太阳病辩证纲要

太阳之为病，脉浮，头项强痛而恶寒(1)

太阳病，发热，汗出，恶风，脉缓者，名为中风。(2)

太阳病，或已发热，或未发热，必恶寒，体痛，呕逆，脉阴阳俱紧者，名曰伤寒。(3)

太阳病，发热而渴，不恶寒者，为温病。若发汗已，身灼热者，名为风温，风温为病，脉阴阳俱浮，自汗出，身重，多眠睡，鼻息必鼾，语言难出。若被下者，小便不利，直视失溲，若被火者，微发黄色，剧则如惊痫，时瘛疭。若火熏之，一逆尚引日，再逆促命期。(6)

病有发热恶寒者,发于阳也;无热恶寒者,发于阴也.发于阳,七日愈;发于阴,六日愈.以阳数七,阴数六故也.(7)

太阳病,头痛至七日以上自愈者,以行其经近故也.若欲作再经者,针足阳明,使经不传则愈.(8)

太阳病,欲解时,从巳至未上.(9)

风家,表解而不了了者,十二日愈.(10)

伤寒一日,太阳受之,脉若静,为不传;颇欲吐,若燥烦,脉数急者,为传也.(4)

伤寒二三日,阳明,少阳症不见者,为不传也.(5)

## 桂枝汤方

太阳中风,阳浮而阴弱,阳浮者,热自发,阴弱者,汗自出,啬啬恶寒,淅淅恶风,翕翕发热,鼻鸣干呕者,桂枝汤主之.

桂枝三两(去皮) ,芍药三两,甘草二两(灸),生姜三两(切),大枣二十枚(擘)(12)

上五味,（口父）咀三味.以水七升,微火煮取三升,去滓,适温寒,服一升.服已须臾,啜热稀粥一升余,以助药力.温覆令一时许,遍身漐漐,微似有汗者宜佳,不可令如水琉璃,病必不除.若一服汗出病差,停后服,不必尽剂.若不汗更服依前法.又不汗,后服小促其间,半日许,令三服尽.若病重者,一日一夜服,周时观之.服一剂尽,病症犹在者,更作服;若汗不出,乃服至二三剂.禁生冷,粘滑,肉面,五辛,酒酪,臭恶等物.

## 桂枝汤适应症

### 太阳病见汗出

太阳病,头痛,发热,汗出,恶风,桂枝汤主之(13)

### 太阳病兼轻度里虚者

太阳病,外证未解,脉浮弱者,当以汗解,宜桂枝汤.(42)

### 汗下后太阳表证仍在者

太阳病,下之后,其气上冲者,可与桂枝汤,方用前发.若不上冲着,不得与之.(15)

太阳病,先发汗不解,而复下之,脉浮者不愈.浮为在外,而反下之,故令不愈.今脉浮,故在外,当须解外则愈,宜桂枝汤(45)

伤寒发汗已解,半日许复烦,脉浮数者,可更发汗,宜桂枝汤.

### 太阳病兼里实欲先解表者

太阳病,外证未解,不可下也,下之为逆,欲解外者,宜桂枝汤(44)

病常自汗出者,此为荣气和,荣气和者,外不谐,以卫气不共荣气谐和故尔.以荣行脉中,卫行脉外.复发其汗,荣卫和则愈,宜桂枝汤.(53)

病人脏无他病,时发热自汗出而不愈者,此卫气不和也.先其时发汗则愈,宜桂枝汤.(54)

### 病重药轻,治用针药并用

太阳病,初服桂枝汤,反烦不解者,先刺凤池,风府,却与桂枝汤则愈.(24)

## 桂枝汤禁忌

桂枝本为解肌,若其人脉浮紧,发热汗不出者,不可与之也.常须识此,勿令误也.(16下)

若酒客病,不可与桂枝汤,得知则呕,以酒客病不喜甘故也.(17)

凡服桂枝汤吐者,其后必吐脓血也.(19)

## 桂枝汤变方

### 桂枝加葛根汤

太阳病,项背强几几,反汗出恶风者,桂枝加葛根汤主之.(14)

葛根四两 桂枝二两(去皮) 芍药二两 生姜三两(切) 甘草二两(灸) 大枣十二枚(擘)

右七味（口父）咀，以水一斗，先煮麻黄葛根，减二升，去沫，内诸药，煮取三升，去滓，温服一升，复取微似汗，不须啜粥，余如桂枝法将息及禁忌.(臣亿等谨按,仲景本论,太阳中风自汗出用桂枝,伤寒无汗用麻黄,今证云汗出恶风,而方中有麻黄,恐非本意也.第三卷有葛根汤证,云无汗恶风,正与此方同,是合用麻黄也.此云桂枝加葛根汤,恐是桂枝中但加葛根耳)

### 桂枝加厚朴杏子汤

太阳病，下之微喘者，表未解故也，桂枝加厚朴杏子汤主之。（43）

桂枝三两（去皮） 甘草二两（灸） 生姜三两（切） 芍药三两 大枣十二枚（擘） 厚朴二两（灸，去皮） 杏仁五十枚（去皮尖）

上七味，以水七升，微火煮取三升，去滓，温服一升，覆取微似汗。

喘家作桂枝汤，加厚朴，杏子佳。（18）

### 桂枝加附子汤

太阳病，发汗，遂漏不止，其人恶风，小便难，四肢微急，难以屈伸者，桂枝加附子汤主之．(20)

桂枝三两(去皮) 　芍药三两　甘草三两（灸）生姜三两（切）　大枣十二枚（擘）　附子一枚（炮，去皮，破八片）

上六味，以水七升，煮取三升，去滓，温服一升．本云，桂枝汤，今加附子，将息如前法．

### 桂枝去芍药汤证

太阳病，下之后，脉促胸满者，桂枝去芍药汤主之。（21）

桂枝三两（去皮） 甘草二两（灸）	生姜三两（切） 大枣十二枚（擘）

上四味，以水七升，煮取三升，去滓，温服一升。本云，桂枝汤今去芍药。将息如前法。

### 桂枝去芍药加附子汤证

若微寒，桂枝去芍药加附子汤主之。（22）

桂枝三两（去皮） 甘草二两（灸） 生姜三两（切） 大枣十二枚（擘） 附子一枚（炮，去皮，破八片）

上五味，以水七升，煮取三升，去滓，温服一升。本云，桂枝汤今去芍药加附子。将息如前法。

### 桂枝新加汤证

发汗后，身疼痛，脉沉迟者，桂枝加芍药生姜各一两，人参三两，新加汤主之。（62）

桂枝三两（去皮） 芍药四两  甘草二两（灸） 人参三两  大枣十二枚（擘）  生姜四两

上六位，以水一斗二升，煮取三升，去滓，温服一升。本云，桂枝汤，今加芍药、生姜、人参。



## 麻黄汤方



太阳病，头痛，发热，身疼腰痛，骨节疼痛，恶风，无汗而喘者，麻黄汤主之。（35）

麻黄三两（去节） 桂枝三两（去皮） 甘草一两（灸） 杏仁七十个（去皮尖）

上四味，以水九升，先煮麻黄，减二升，去上沫，内诸药，煮取二升半，去滓，温服八合。覆取微似汗，不须啜粥，余如桂枝法将息。

太阳病，十日以去，脉浮细而嗜卧者，外已解也。设胸满肋痛者，与小柴胡汤。脉但浮者，与麻黄汤。（37）

脉浮者，病在表，可发汗，宜麻黄汤。（51）

脉浮而数者，可发汗，宜麻黄汤（52）

## 太阳伤寒衄解

太阳病，脉浮紧，无汗，发热，身疼痛，八九日不解，表证仍在，此当发其汗。服药已微除，其人发烦目暝，剧者必衄，衄乃解。所以然者，阳气重故也。麻黄汤主之。（46）

太阳病，脉浮紧，发热，身无汗，自衄者愈。（47）

伤寒脉浮紧，不发汗，因致衄者，麻黄汤主之。（55）

## 麻黄汤其他适应症

太阳与阳明合病,喘而胸满者,不可下,宜麻黄汤.(36)

## 麻黄九禁

咽喉干燥者,不可发汗.(83)

淋家,不可发汗,发汗必便血.(84)

疮家,虽身疼痛,不可发汗,汗出则痉.(85)

衄家,不可发汗,汗出必额上陷脉紧急,直视不能眴,不得眠.(86)

亡血家，不可发汗，发汗则寒栗而振。（87）

汗家，重发汗，必恍惚心乱，小便已阴痛，与禹余粮丸。（88）

病人有寒，复发汗，胃中冷，必吐蛔。（89）

脉浮数者，法当汗出而愈，若下之，身重心悸者，不可发汗，当自汗出乃解。所以然者，尺中脉微，此里虚，须表里实，津液自和，便自汗出愈。（49）

脉浮紧者,法当身疼痛,宜以汗解之,假令尺中迟者,不可发汗.何以知然?以荣气不足,血少故也.(50)

## 太阳兼症

### 葛根汤方

太阳病,项背强几几,无汗恶风,葛根汤主之.(31)

葛根四两	麻黄三两(去节)	桂枝二两(去皮)	生姜三两(切)	甘草二两(灸)	芍药二两	大枣二十枚(擘)

上七味,以水一斗,先煮麻黄,葛根,减二升,去白沫,内诸药,煮取三升,去滓,温服一升.覆取微似汗,余如桂枝法将息及禁忌.诸汤皆仿此.

### 葛根加半夏汤证

太阳与阳明合病者,必自下利,葛根汤主之.(32)

太阳与阳明合病,不下利但呕者,葛根加半夏汤主之.(33)

葛根四两	麻黄三两(去节)	甘草二两(灸)	芍药二两	桂枝二两(去皮)	生姜二两(切)	半夏半升(洗) 	大枣十二枚(擘)

上八味,以水一升,先煮葛根,麻黄,减二升,去白沫,内诸药,煮取三升,覆取微似汗.

### 大青龙汤证

太阳中风,脉浮紧,发热恶寒,身疼痛,不汗出而烦躁者,大青龙主之.若脉微弱,汗出恶风者,不可服之.服之则厥逆,筋惕肉瞤,此为逆也.(38)

大青龙汤方

麻黄六两(去节)	桂枝二两(去皮)	甘草二两(灸)	杏仁四十枚(去皮尖)	生姜三两(切)	大枣十枚(擘)	石膏如鸡子大(碎)

上七味,以水七升,先煮麻黄,减二升,去上沫,内诸药,煮取三升,去滓,温服一升,取微似汗.汗出多者,温粉粉之.一服汗者,停后服.若复服,汗多亡阳遂虚,恶风烦躁,不得眠也.

伤寒脉浮缓,身不疼但重,乍有轻时,无少阴症者,大青龙汤发之.(39)

### 小青龙汤证

伤寒表不解，心下有水气，干呕发热而咳，或渴，或利，或噎，或小便不利、少腹满，或喘者，小青龙汤主之。（40）

麻黄（去节）	芍药	细辛	干姜	甘草（灸）	桂枝（去皮）	各三两	五味子半升	半夏半升（洗）

上八味，以水一斗，先煮麻黄，减二升，去上沫，内诸药，煮取三升，去滓，温服一升。若渴，去半夏，加栝楼根三两；若微利，去麻黄，加荛花，如一鸡子，熬令赤色；若噎，去麻黄，加附子一枚，炮；若小便不利，少腹满者，去麻黄，加茯苓四两；若喘，去麻黄，加杏仁半升，去皮尖。且荛花不治利，麻黄主喘，今此语反之，宜非仲景意。（臣亿等谨按，小青龙汤，大要治水。又按《本草》，荛花下十二水，若水去，利则止也。又按《千金》形肿者应内麻黄，乃杏仁者，以麻黄发其阳故也。以此证之，岂非仲景意也。）

伤寒新下有水气,咳而微喘,发热不渴.服汤已渴者,此寒去欲解也.小青龙汤主之.(41)
]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
      </tags>
  </entry>
  <entry>
    <title>用YOLO3实现犬种实时检测</title>
    <url>/posts/fa14c502.html/</url>
    <content><![CDATA[
## 效果

利用YOLO v3实现的犬种实时检测的一次记录,下面是检测结果:

### 单个大目标:


        <style>.bbplayer{width: 100%; max-width: 850px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" id="mmedia-keOEZgnN" src="//player.bilibili.com/player.html?aid=86257908&page=1&high_quality=1&danmaku=true" allowfullscreen="no" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        <script>
            document.getElementById("mmedia-keOEZgnN").style.height=document.getElementById("mmedia-keOEZgnN").scrollWidth*0.76+"px";
            window.onresize = function(){
              document.getElementById("mmedia-keOEZgnN").style.height=document.getElementById("mmedia-keOEZgnN").scrollWidth*0.76+"px";
            };
        </script>
        

### 多个小目标:


        <style>.bbplayer{width: 100%; max-width: 850px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" id="mmedia-NdacSFNM" src="//player.bilibili.com/player.html?aid=86258451&page=1&high_quality=1&danmaku=true" allowfullscreen="no" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        <script>
            document.getElementById("mmedia-NdacSFNM").style.height=document.getElementById("mmedia-NdacSFNM").scrollWidth*0.76+"px";
            window.onresize = function(){
              document.getElementById("mmedia-NdacSFNM").style.height=document.getElementById("mmedia-NdacSFNM").scrollWidth*0.76+"px";
            };
        </script>
        

FPS大概12左右(!-_- ,显卡1060)

### 测试集结果:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/combine_image_result.jpg)

上图中蓝色的框表示Ground Truth,红色的框表示Bounding Box

## 数据集

数据来自于ImageNet的[ImageNetDogs](http://vision.stanford.edu/aditya86/ImageNetDogs),共有120个犬种,20580张图片

由于这里仅是用于检测狗,所以我这里把所有的犬种合为一类,也就是说,class仅有dog一个标签,在yolo v3中对应一个logistic

## 环境

* tensorflow-gpu-1.1.3
* keras-2.1.5
* GTX 1060

## 训练

训练模型也是在现有的YOLO v3的基础上做fine-tune,[git仓库地址](https://github.com/qqwweee/keras-yolo3)

### 整理数据

即整理出适合模型的输入形式,以txt文件保存,如下,具体代码不再阐述.

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_4801.jpg  <span class="number">93</span>,<span class="number">145</span>,<span class="number">218</span>,<span class="number">371</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_20429.jpg  <span class="number">205</span>,<span class="number">78</span>,<span class="number">336</span>,<span class="number">323</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_5080.jpg  <span class="number">170</span>,<span class="number">73</span>,<span class="number">370</span>,<span class="number">374</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_19261.jpg  <span class="number">26</span>,<span class="number">16</span>,<span class="number">473</span>,<span class="number">481</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_5732.jpg  <span class="number">96</span>,<span class="number">79</span>,<span class="number">267</span>,<span class="number">442</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_4952.jpg  <span class="number">12</span>,<span class="number">0</span>,<span class="number">499</span>,<span class="number">374</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_5066.jpg  <span class="number">85</span>,<span class="number">0</span>,<span class="number">330</span>,<span class="number">490</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_3817.jpg  <span class="number">121</span>,<span class="number">111</span>,<span class="number">468</span>,<span class="number">330</span>,<span class="number">0</span></span><br><span class="line">data/JEPGImages/n02109961-Eskimo_dog/n02109961_4369.jpg  <span class="number">249</span>,<span class="number">34</span>,<span class="number">499</span>,<span class="number">333</span>,<span class="number">0</span> <span class="number">37</span>,<span class="number">41</span>,<span class="number">291</span>,<span class="number">334</span>,<span class="number">0</span></span><br></pre></td></tr></table></figure>

> 格式为(图片地址 GroundTruth1信息 GroundTruth2信息 ..),每个Ground Truth信息为(x_min,y_min,x_max,y_max,classID),即左上角坐标,右下角坐标以及类别ID

### 修改配置

> 主要修改yolov3.cfg文件中的配置
>
> * 三个不同尺度的Feature Map对应的filter均改为改为18,仅有一类
> * batch改为8(显存限制)
> * random为1.(调整不同尺寸的图片输入,保证效果)

### Anchor Box聚类

(个人认为这是比较重要的一步,后面会说明),通过kmeans对Ground Truth进行kmeans聚类,以此确定Anchor Box的尺寸.所用的衡量标准$1-IOU(ground truth,centroid)$.其中,$centroid$表示聚点的数值,聚类的结果:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">K anchors:</span><br><span class="line"> [[<span class="number">138</span> <span class="number">178</span>]</span><br><span class="line"> [<span class="number">153</span> <span class="number">322</span>]</span><br><span class="line"> [<span class="number">155</span> <span class="number">189</span>]</span><br><span class="line"> [<span class="number">195</span> <span class="number">246</span>]</span><br><span class="line"> [<span class="number">251</span> <span class="number">174</span>]</span><br><span class="line"> [<span class="number">281</span> <span class="number">309</span>]</span><br><span class="line"> [<span class="number">338</span> <span class="number">295</span>]</span><br><span class="line"> [<span class="number">410</span> <span class="number">331</span>]</span><br><span class="line"> [<span class="number">412</span> <span class="number">222</span>]]</span><br><span class="line">Accuracy: <span class="number">91.20</span>%</span><br></pre></td></tr></table></figure>

> 这里的Accuracy是每个Ground Truth和聚点的平均IOU

**对应的9个Anchor Box散点图(没错,这真的是聚类的结果)**

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/AnchorBox聚类.png)

### 训练

在台式机上跑了大概两天.但loss一直降不下来,一直维持在17左右.(我怀疑这可能和图片的质量有关,在测试集的示例可以看到,有些样本是没有标记框的,这可能导致loss降不下来,后面总结部分我会详细说明)

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/val_loss.png)

在训练后期,学习率调小至1e-8,但对loss都没什么影响,最多减小0.5左右

## 问题总结以及改进

### 关于Anchor Box聚类

> 很多博客上说Anchor Box的聚类对最终结果的影响不大,但是在这个数据集上,聚类的效果挺明显的(可能是数据集本身的差异),下面是用源生的yolo3下的Anchor Box(这个应该是VOC数据集的Anchor Box)训练的结果:


        <style>.bbplayer{width: 100%; max-width: 850px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" id="mmedia-UHosnkht" src="//player.bilibili.com/player.html?aid=86258451&page=2&high_quality=1&danmaku=true" allowfullscreen="no" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        <script>
            document.getElementById("mmedia-UHosnkht").style.height=document.getElementById("mmedia-UHosnkht").scrollWidth*0.76+"px";
            window.onresize = function(){
              document.getElementById("mmedia-UHosnkht").style.height=document.getElementById("mmedia-UHosnkht").scrollWidth*0.76+"px";
            };
        </script>
        

> 对比开始的[检测视频](#多个小目标),可以看到改进还是挺明显的.

### 关于模型Loss

模型loss分两个方面.

1. loss下降到一定的数值就难以下降,大概在17左右

> 这可能和数据本身的质量有关,因为数据集本身是针对不同的犬种进行标注,并不是对"狗"这个种类进行标注,所以导致有些图片缺少标记框,比如下面几张图片数据:
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/14.jpg)
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/24.jpg)
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/206.jpg)
>
> 一旦模型检测出没有标记的狗,就相当于训练数据"告诉"模型检测是错误的,所以,loss居高不下.另外,这也反过来影响模型的表现,此时模型已经不知道孰对孰错了.
>
> 所以,要想降低loss,需要对数据进行重新标注,理论上loss应该会下降.

2. 验证集的loss总是低于训练集的loss

> 在训练的过程中,验证集的loss总是低于训练集的loss,不知道是何原因,这个问题至今无法解决.

### 侧面目标效果差

>  侧面目标检测效果很差,很多时候检测不出或者置信度很低(这其实在测试视频中也有所反应):
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/12.jpg)
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/26.jpg)
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/143.jpg)
>
> 可能是由于数据集中侧面图片比较少的关系,需要在原有数据集上对侧面图片做上采样(比如Mix Up,加噪声等).总之,就是增加这类图片的数据量,再放入模型训练.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>Demo</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>藏象</title>
    <url>/posts/6637e8be.html/</url>
    <content><![CDATA[

本篇文章来自于中医经典教材《中医基础理论》第五版以及潘毅的视频，以下是对藏象章节的总结以及一些对于书中所述自己的一些理解。

# 概述

藏象篇主要描述五脏和六腑各自的功能作用，且由于五脏六腑之间功能和作用相互影响，故本篇还说明五脏和六腑之间的关联和影响关系。

## 脏腑对应总述

中医认为脏和腑，五行、在外表现等都有一定的关联，以下是其对应的关系，如表所示：

| 脏   | 五行 | 腑   | 华   | 充   | 志   | 开窍     |
| ---- | ---- | ---- | ---- | ---- | ---- | -------- |
| 心   | 火   | 小肠 | 面   | 血脉 | 喜   | 舌       |
| 肝   | 木   | 胆   | 爪   | 筋   | 悲   | 目       |
| 脾   | 土   | 胃   | 唇   | 肌   | 思   | 口       |
| 肺   | 金   | 大肠 | 毛   | 皮   | 怒   | 鼻       |
| 肾   | 水   | 膀胱 | 发   | 骨   | 恐   | 耳和二阴 |

## 五行八卦

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/3ac79f3df8dcd1009903550b7a8b4710b9122f78.webp" style="zoom:50%;">

# 心

心为离卦（“☲”），属火

## 心主血脉

血脉的运行，依赖于心脏的搏动，若心气受阻，则出现血流不畅

所以在生理上，血液的正常运行的必备条件有三：

* 心气充沛
* 血液充盈
* 脉道通利

所以在生理上，心主血脉的表现为：面色红润（心其华在面），舌色淡红（心开窍于舌），**心中没有感觉**（平时感觉不到心脏的跳动）

> 心主血脉更直观理解的是心气推动血在脉管中走，如果心气弱，则血行不动，遍布全身的血液量不足，自然就面色不华；血虚和心血淤堵同样的道理。

此外，从心其华在面这一点，观察面色主要关注两点：色和泽，其中，**泽比色重要**，泽主要表示人的神。

## 心主血脉的病理

1. 血液不充盈，即血虚

>  血液不充盈可以理解为身体中的血少了，那么从心脏供到全身的血就少，为了达到充足的血液供应量，心脏就会加快收缩，就会出现心悸怔忡等症状。心血不足的症状可分为两大类。一组是以血虚为主，另一组是以心特有的症状为主.

表现为：面色萎黄/苍白，舌淡，脉细，心悸/怔忡，头晕眼花

2. 心气虚

> 心气虚的症状为气虚症状加上心的症状

表现为：神疲乏力，少气懒言，面色萎黄/苍白,脉弱，心悸/怔忡

3. 心血淤堵

> 心血淤堵是淤堵的症状+心的症状

表现为：面色晦暗/青紫,舌瘀斑/淤点，脉涩，心憋闷（平时憋闷，发作时刺痛）

4. 心阳虚

心阳虚表现为：心气虚+形寒制冷

**心阳虚和心气虚均可导致心血瘀阻**

## 心藏神（心主神志）

> 神包括所有的思维意识精神的活动，这个范围很广。通俗的说就是包括，人的思考，人的潜意识，人的情绪，等，都算神。所以，从我的理解，“神”包含两个方面：1. 思维 2. 情绪

**思维**

在中医中，有心和脑很多时候是通用的。例如，“心理学”

所以当心出问题时，就会反过来影响神志。例如当热扰心神时，会出现热盛神昏的现象。也正因为此。

**情绪**

情绪主要指五志。五志（喜怒忧思恐）**并非从五脏发出来的，都是从心而发，只是应于五脏**。所以心为五脏六腑之大主。（**五志唯心所使也**）《黄帝内经》上说“主明则下安，以此养生则寿。主不明，则十二官危”

> 如“怒”从心而发，则肝受怒的影响更大

**关于“神”的补充**

心为离卦，阳中藏阴，即火中藏水。

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/f31fbe096b63f624e92ab7ff8d44ebf81b4ca3d3.png" style="zoom:25%;">

“神”分两类，分“元神”和“识神”

* 元神：先天，属水，存于脑，维持基本的生理活动。即离卦之阴（一般来说，“元”都是来自于先天）
* 识神：主精神意志，思维活动之神，属火，存于心，其活动可干扰元神。即源于意识和先验的思考判断。即离卦之阳

> 从卦象上看，在正常情况下，元神藏于识神之中。当人静下来时，例如打坐，站桩，元神显现，识神藏匿。识神藏匿越多，其五志（识神包括五志）对于元神的干扰就越小，此时入静也就越深。

## 在液为汗

心主血脉，而汗血同源。（血=营气+津液）

## 其华在面

心主血脉，血液运行异常则面色萎黄。

# 肺

肺为兑卦（”☱“），属金，肺是人体气，津液和水谷精微的枢纽。肺为五脏之华盖，故肺主降。

## 肺主气司呼吸

### 肺主一身之气

肺主一身之气，包括两个方面：

* 肺影响气的生成，尤其是宗气：宗气=肺的呼吸之气+脾运化后的水谷精气
* 肺的呼吸即是气的升降出入

### 肺主呼吸之气

​	肺为人体和外界气的交换场所。呼即排出体内的浊气，吸即吸入外界的清气。

​	正常的呼吸为**细慢匀长**

### 呼吸异常基础辨别

* 以吸入为快，偏虚。以呼出为快，偏实（多为气憋于胸中）
* 呼吸困难即为哮喘，喘不一定兼哮，哮一定兼喘
* 哮喘声音偏大偏差为实，声音偏小偏细为虚

## 宣发和肃降

> 肺为津液、气和水谷精微交换的枢纽，这个枢纽有内外相对的，也有人体内部上下相对的

宣发和肃降并不是一对矛盾体，肺作为枢纽和交互的中心，既可以向外向上，也可以向内向下。

下面分三个方面进行总结：

### 气

宣发：

	1. 卫气：将卫气宣发到体表（卫气来源于水谷精微，卫气肥腠理，斯开阖，卫外而为固）
	2. 呼气：呼出体内浊气

肃降：

1. 将吸入清气向下降

### 津液

宣发：输送脾运化的津液（脾主升清），外达皮毛

肃降：将水液向下输送，形成尿液之源（肺为华盖之官）

### 水谷精微

宣发：将脾运化的水谷精微宣发到体表，形成卫气

肃降：将水谷精微向下输送，到达各个脏腑，形成脏腑之精（肺为华盖）

### 其他

肃清肺和呼吸道内的异物

## 肺主行水

肺对外能够将津液外达皮毛，对内能够将津液向下输布，形成尿液之源。若肺主行水功能衰退，则形成痰饮。

**肺为贮痰之器，脾为生痰之源，肾为生痰之本**

> 《内径》说：饮入于胃，游溢精气，上输于脾，脾气散精，上归于肺，通调水道，下输膀胱，水精四布，五经并行。脾主运化，脾不健运则痰生。所以治水湿痰饮从脾着手，比较有代表性的方剂：陈夏六君丸。
>
> 但在明代之后，有流派认为肾主水，痰由水所化，之所以痰生是因为水不归源，所以治肾为治本，治脾为治标。

## 朝百脉主治节

### 朝百脉

全身的血脉经过经络汇聚于肺，在肺进行气体的交换（肺主呼吸），再输送到全身。

若肺气虚，则朝百脉功能受影响，就会影响心（心主血脉）。可能出现怔忡等症状。

### 主治节

治节，即治理和调节。即肺对全身的气血津液有调节作用。

## 肺合皮毛

## 鼻为肺之窍

流涕的基本辩证：

* 浊涕：偏热。
* 清涕：偏寒。一般而言，清涕有两种可能：1. 外感风寒 2. 肺阳虚（肺阳虚容易早上起来流清涕）

## 喉为肺之门户

咽和喉是两个器官，咽为胃的门户，喉胃肺的门户。

* 咽 >> 食道 >> 胃
* 喉 >> 肺

若是实热造成的急性咽炎，应清胃热和肺热。

> 此外，肾经循喉咙,挟舌本，咽痛和肾经相关性比较大

## 在液为涕

在病理上分为干和湿两个方面：

鼻干：

* 肺属秋，秋天干燥
* 肺阴虚
* 肺实热：热盛伤津

鼻湿，也就是鼻涕:

* 清涕
  * 外感风寒
  * 肺阳虚
* 浊涕：外感风热

所以，**风寒和风热均会造成流涕**

# 脾

脾为坤卦（“☷”），为五行之枢纽，坤卦为土象，主厚德载物。

## 脾主运化

运化分为两个部分：运和化

### 运

**运又分为两个方面：运送津液以及运送水谷精微**。运送有两条途径：

1. 脾将津液以及水谷精微直接运往全身的各个脏腑。在各个脏腑的水谷精微变成脏腑之精，从而变成脏腑之气。
2. 脾将津液以及水谷精微上输至肺，肺通过宣发肃降将它们（指津液和水谷精微）输送到全身。（对于脏腑而言是肃降，对于营气和呼吸而言是宣发）。

<pre class="mermaid">graph LR
A[津液以及水谷精微] --升清 --> B[肺]
A --直接运送 --> C[各个脏腑]
B --肃降 --> C
C --脏腑之精生成--> D(脏腑之气)
B --宣发--> F[皮毛]
F --生成--> G(营气卫气)</pre>

### 化

化为消化

## 运化病理

### 运

**运送水谷精微失调**

> 运送水谷津液的失调书中并没有专门提及，书中是和“化”一起归类的，这里我的理解是单纯的运送水谷津液失调应该是气血化生不足。并不会出现消化方面的症状。但似乎不多见。

**运送津液失调**

运送津液失调较为常见，且较为复杂。

津液运送失调关系到湿，津液运送失调，则会出现湿，而根据不同的“湿”的形态，又可以分为“水湿痰饮”，和不同的邪结合又会出现如“寒湿”，“湿热”，“风湿”等。在不同的部位出现又会表现不同的症状，如水寒射肺，湿热下注等。

所以有**诸湿肿满，皆属于脾**，**脾为生痰之源，肺为储痰之器，（肾为生痰之本）**

关于“湿”的症状和病众多，这里只列举目前有一点了解的。

#### 湿热

一般症状：头身困重，舌苔黄腻，脉数，尿黄，爱出汗，大便黏腻，口干，但渴不欲饮。

**湿热在不同的部位会出现不同的症状**

> 我感觉在实际中湿热和阴虚并不是很好分清，因为湿热有时候不会出现湿热的典型症状，如大便黏腻，头身困重。但口干，脉数，尿黄，爱出汗和阴虚发热这些症状其实都是共同的。但阴虚的口干，是想喝水，而湿热由于堵住了，所以并不想喝水。

#### 便秘

痰湿型的便秘的病机是由于湿堵塞津液通道，导致津液运送到大肠受阻，从而引起便秘。**这也需要和阴虚型便秘相鉴别。**

对于痰湿型的便秘，若直接用滋阴药，前几付有效，后面就会无效（吃滋阴药相当于治标）。但如果直接吃健脾祛湿的药治本则见效慢（祛湿一般见效都要慢于其他五淫，何况这里还要补脾气）。所以，这里应该吃健脾祛湿药+滋阴药，标本兼治。

### 化

化的病理则表现为消化系统的失调

完谷不化，腹胀，食欲不振（纳呆），便溏

## 脾统血

脾有统摄，控制血液在脉中正常运行而不溢出脉外的功能

> 脾为气血生化之源，气有固摄的功能

故脾虚可能导致出血，且**下部居多（脾主升清）**如：1. 皮下出血 2.下焦出血

治则：补脾气

## 脾气主升

脾主升清包含两层含义：

1. 脾主升清：脾将水谷精微和津液上升于肺
2. 升举内脏：例如脾气虚引起的胃下垂，肝下垂，肾下垂，脱肛

## 脾气虚

这节是对脾气虚的症状，病理，病机进行总结



# 大肠

大肠与肺互为表里

大肠接收小肠的残渣，吸收水分，形成粪便。故大肠作用有二：

* 主传化糟粕
* 大肠主津

## 大便病理基本判定

* 大便颜色偏深偏热，颜色偏浅偏寒
* 大便臭的偏热，大便腥的偏寒
* 感觉大便拉不完——湿热。此外，湿热大便是黏的

## 便秘

便秘的病因一般分为两大类：

* 伤津：可能是阴虚，也可能是实热伤津
* 气虚：气有推动作用，气血则无力推动

气虚则补气，伤津则补津

实热伤津型便秘：急性用大黄，慢性用蜂蜜，仁类（例如杏仁）+降肺药

> 阴虚型便秘用熟地效果尚可

## 肺和大肠相表里

肺实热：若清热无效，直接用下法（通常伴随着不出汗）。

便秘皮肤不好：大便不通，在大肠，而大肠和肺相表里，故影响肺，肺合皮毛，故影响皮肤
]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>中医</tag>
        <tag>中医基础</tag>
      </tags>
  </entry>
  <entry>
    <title>藏象-肾</title>
    <url>/posts/9f0b914d.html/</url>
    <content><![CDATA[

## 藏精

> 精气是构成人体的基本物质，也是人体生长发育及各种功能活动的物质基础。故《素问.金匮真言论》说：夫经者，生于本也。

### 精气阴阳

上文精气中的精和气是两个概念，气由精所化（气功中有炼精化气）。但在中医中，有时将他们混用。

肾中精气又分为两极：肾阴和肾阳（又称元阴元阳）

* 阳主动，主功能
* 阴主静，主物质

### 精的分类

在精的基础上可分为两种：

#### 先天之精

先天之精是禀受于父母的生殖之精，与生俱来，藏于肾中。

#### 后天之精

> 肾者主水，受五脏六腑之精而藏之

后天之精来源于脾胃运化后的水谷之精，水谷之精生成脏腑之精营养五脏（实际上是以化身津液气血的形式），剩余部分归于肾中，为后天之精。后天之精的生成过程如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20201229190653.png)

#### 两者又互为依存

* “先天之精”有赖于“后天之精”的不断培育和充养。

  即如“后天之精”的来源所述，“先天之精”需要“水谷之精”消耗后的充养。

* “后天之精”的化生，依赖于“先天之精”的活力资助。

  “后天之精”依赖于脾胃的运化，而脾胃的功能强弱依赖于“脾气”，而“脾气”的化生和精气又有密布可分的关系。

### 病例特征



## 主水

 肾对于水主要在于分离浊中之清和浊中之浊。

### 浊中之清





主水主要分为两个方面：蒸腾（维持体内津液代谢）以及控制尿液。

肾中水的来源包括两个方面：

> 1. 小肠的分清别浊
> 2. 肺的肃降

>  当水液输送到肾时，主要有两个去向:
>
> 1. 向下走，至膀胱形成尿液（即排尿）
> 2. 向上走，再次输送到全身，再利用（即蒸腾）

此外，肾的来源

### 水的蒸腾

在蒸腾中，也分为两方面：

* 肾会将小肠排至肾的水液向上蒸腾（即分离出浊中之清）
* 将排至肾的水液再蒸腾

### 排尿





]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>中医</tag>
        <tag>中医基础理论</tag>
      </tags>
  </entry>
  <entry>
    <title>《结网》总结</title>
    <url>/posts/6637e8bf.html/</url>
    <content><![CDATA[
## 整体结构

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/检查与处理.png" style="zoom:50%;">

## 概念

概念即产品的核心：这个产品要解决什么问题，满足用户的什么需求。

> 但我的理解，在构建概念的时候，除了解决满足什么用户需求，还要考虑竞争优势，或者说竞争壁垒。竞争壁垒我的理解对于不同类型的互联网产品侧重点会不同，后面会提到。

<pre class="mermaid">graph LR
A[概念] --- B[满足需求]
A --- C[竞争壁垒]
C --- D[技术壁垒]
C --- E[资源壁垒]</pre>

### 关于抄袭

文中提到，对于产品，抄袭并不是什么不好的事情，我们的目的是做好产品，并不用管这些形式主义。

>  但在抄袭之前，我们应该考虑好我们抄袭的优势是什么，也就是上文提到的竞争优势，竞争壁垒。对手已经占领了高地，其实要从对手手中把高地夺过来并不容易。（用《定位》的话说就是占领了心智）。所以这一点在动手前一定要考虑清楚。

### 关于高频强需求

一般认为高频和强需求的概念才是最理想的概念，即

<pre class="mermaid">graph TD
A[理想需求] --- B[高频]
A --- C[强需求]
A --- D[用户规模]
D --- E[决定产品上限]</pre>

> 实质上，同时满足“高频”和“强需求”的产品少之又少。

> 事实上，我的理解是高频比强需求更加可怕，高频意味着软件将成为平台，例如微信，美团外卖，腾讯QQ等，包括现在的实体手机，小米，华为都是这样的思路。在平台端，要的是客流量（也就是高频），平台甚至可以不赚钱，甚至赔钱，但他后期衍生出的子产品和本身则可以赚钱。

## 概念2.0

概念2.0实质上是web 2.0的衍生，相对于web 1.0，web 2.0更加强调用户的交互.

> web 2.0由于更加强调用户之间的交互，所以导致互联网很多内容实际上是用户产生的，即UGC（User Generate Content）。

### 我对于产品类别的理解

> 在互联网中，我认为通常的互联网产品分为两大类：
>
> 1. 工具型的产品，如天气类，滴答清单
> 2. 社交类，资源类的产品：如淘宝，腾讯QQ都属于此类
>
> 对于工具类产品而言，对于用户的作用只是处理某一功能，如天气类软件一般只是为了看天气，视频剪辑类的软件仅是为了剪辑视频。这类软件相对比较单纯，因为一般而言，工具类软件要的是工具的效果，工具的效果很大程度上决定产品的成败。所以，对于工具类软件，在竞争壁垒上强调更多的是技术壁垒：如果我的软件能做到某一个效果，竞争对手做不到，而这个效果又是用户的硬需求，那么在竞争中我很可能会占领优势（用户体验，用户运营等还是需要的，只是相对较弱）。
>
> 所以，可以说技术壁垒才是工具类软件的核心。所以对于天气类这样的工具类软件，大家都能做，最终的结果是谁也占不了优势。对于算法而言也是同样的道理，算法开发的产品，多是工具型的产品（除了推荐算法外），甚至对于工具而言，算法可以说是产品的核心-技术壁垒，若想在算法上建立技术壁垒，一是靠数据量的支撑，二是靠算法本身的精度。单纯的使用开源模型最终的结果会和天气类软件同样的下场。
>
> 另外一类就是社交类，资源类的产品，相比于工具类产品，这类产品对于技术的要求相对要低一些（例如做一个商城，功能上大家都能实现），对于这类产品我认为更重要的是资源本身。例如淘宝，已经有许多买家在上面买东西了，这就是资源。再如微信，已经形成一个关系网了，对手要再瓦解这个关系网是不容易的。这一类产品实际上是充分利用了UGC。对于这类产品，我认为重点在社群的运营以及UGC的管理上。
>
> 以上两大类产品，一是两者并不是完全对立的，一个产品可以既是工具类又是社交类。二是两者各有优缺点，工具类用户粘性低，但相对单纯，只需提升功能效果体验。社交类，资源类一般都较“重”，技术门槛又比较低，要想发展起来并不容易。

### 蓝海战略

蓝海战略同时追求“低成本”和“差异化”。

> 蓝海战略实际上追求的是市场细分，追求市场细分即是追求差异化，也能降低成本（因为追求市场细分使得自己能够集中所有的资源，把力气使在一点上）

## 过滤

如果概念确认能够做，我们需要从细节去**进一步确认能不能做**

> “概念”我的理解是从道的角度上看问题，而本章的“过滤”是从“术”的角度上看问题。也就是说，从粗到细的分析问题。

过滤一共分为以下几点：

<pre class="mermaid">graph TD
A[过滤] --- B[确定目标用户]
A --- C[满足需求]
A --- D[市场规模]
A --- E[如何接触用户]
A --- F[营收模式]</pre>

### 目标用户和满足需求

目标用户和满足需求在概念部分都已经想好的，这里不再阐述

### 市场规模

市场规模决定了产品的成长空间。

> 但我认为，如果直接在网上查找市场规模的统计报告并不可行，因为对于一个小软件而言，本身满足需求都是见缝插针，要找统计资料并不现实

### 如何接触用户

> 这一部分相当重要，尤其是冷启动时期，它决定了新用户的来源以及规模，但书中仅是蜻蜓点水的提了提，并未深入阐述。但这一部分或许并没有什么固定的方法论，要的是经验以及随机应变。

### 营收模式

这应该是在开始前就应该有计划

## 把概念变成图纸

在确定了“道”和“术”之后，就进入到产品经理的设计阶段。

> 但我对书中的设计的顺序并不太苟同，甚至我认为书中提到的有些表（图）无关紧要。下面列出我的对这个设计流程的理解。

非常重要的一点是：**文档同步更新**

### 功能细分

设计同思维一样，应该是从粗到细的。这样，从分类和后期的分工，甚至人员安排才会条条有理。所以，第一步应该是功能的细分。

在概念和过滤部分，我们已经明确的知道了，目标是什么以及值不值得做。所以，这一步应该是，将目标拆分成功能：要达到这个目标我们需要做些什么功能。

这些功能我们在最开始可以按照头脑风暴的方式把他列出来，然后对功能分门别类，或许有些功能是我们不需要的，但在这一步我们仅需要列出大体的功能和整理即可。

### 设置优先级

在软件开发的初期，我们不可能把上述的每个功能都实现，尤其是很多时候用的是**最小可行产品**的思路，所以我们需要对上述的功能排一个优先级，这个优先级当然是基于核心功能优先。

### 绘制流程图以及细化修改功能

在确定了优先级之后，我们基本上清楚的知道现阶段我们需要做什么功能了，针对每一个功能，我们需要画流程图。这个流程图我的理解是越详细越好，最好细化到每一个子功能，同时，在我的经验中，其实一般的流程图不足以表达功能的流程。因为软件很多情况下涉及到多个组件的交互，一般会把序列图和流程图一起使用。

在画流程图的过程中，我们会发现之前我们头脑风暴的有些功能不够细化，或者在技术上可能并不能实现等等，所以在这过程中，我们需要对功能进行细化，修改等等。如果你对程序代码比较熟悉，在这一步你就能看出技术难点在哪，能不能实现等等。

**这一步需要反复修改斟酌修改，甚至在后期我们在修改功能流程时需要同步更新。甚至在分析功能流程上的缺陷时，这些图会起很大的作用。**

### 人员分配以及排期

实际上这里很大程度上是项目管理的工作

### 产品经理的工作

在产品经理的工作中，依然遵循这个原则：从粗到细。

#### 设计图

**网站结构图**

穷举网站所有的功能和结构（App是一样的道理），生成一个树形结构

**网页描述表**

穷举所有的场景展示

#### 和交互以及设计协作

主要是交互设计。文中建议用手画草图

#### 和研发协作

主要是功能以及效果需求

## 用户体验

用户体验不用多说，是非常重要的一个部分，甚至贯穿整个产品研发和上线运营。

实质上在这一步已经完成产品的研发，在“改错”阶段，已经上线或者即将上线。

书中提出用户体验的三要素：别让我等，别让我想，别让我烦。比较实用

### 别让我等

也就是产品的响应时间，作者总结出几个可以改进的方面

* 减少HTTP请求：在文件大小不变的情况下，请求次数越多，响应时间越长。所以作者建议从几个方面去优化：
  1. 减少不必要的请求
  2. 文件合并。比如将多个CSS文件合并为一个
* CDN
* 压缩网页元素。包括压缩文本和图片两方面
  1. 文本。gzip压缩。一般在服务器软件中可以配置
  2. 图片。利用专门的图片压缩工具缩小图片，不要在CSS中来限制图片大小，图片越大响应时间越长。
* 将CSS引用放在header部分
* **将js文件引用放在最后面**
* 将CSS和js放在外部文件中。这样可以利用缓存机制，减少请求次数
* Ajax缓存

### 别让我想

实质上，这一部分包含了两层意思：

* 标题，界面应该简单粗暴，言简意赅。（其实可以看到小米很多时候都是利用这种原则）
* 方便，简单：大多数情况下体现在功能和流程的简化上

####  标题，广告语

标题应该简单粗暴，言简意赅。最有代表性的例如老白金的广告

#### 界面

简洁，突出重点，简洁才能突出重点。

> 我其实有一点不能理解为何淘宝网的首页会出现密密麻麻的的文字。虽然电商网品类繁多，但如此多如此密的文字，用户很可能不会去看。像亚马逊在这一点上比淘宝网好很多

**控件越大越能突出重点**

#### 方便，简单

> 事实上，很多产品就是利用这一点发展起来的。一个软件做到后面会满足不同用户不同的需求，功能会越来越庞大。这也造成了另外一个问题：上手越来越难。所以，才有轻量级的软件出现来占据一席之地。实际上，轻量级就是利用了这一点：简单。比较有代表性的：美图秀秀和PS，MarkDown和word

### 别让我烦

操作步骤越多，用户越烦

**用户完成任务的难度与步骤平方成正比**

文中有以下原则：

1. 缩短任务用户所需的步骤
2. 增大目标的面积，例如要点击按钮的面积
3. 缩短当前鼠标位置与目标的距离
4. 最好让用户的视线保持在同一直线上

## 网站分析

这一章十分重要，产品由于不会面对客户，所以并不会直接获得问题的反馈。要想发现问题，就需要网站分析。但网站分析是很大一个部分，一章不足以阐述完整，所以书中只是简单的提及。

> 我的理解网站分析包含两方面的内容：1. 找到问题。例如通过观察UV，发现最近一段时间UV下降 2. 分析问题，也就是为何UV会下降。

> 在我见过的数据分析中，很多人是为了画图而画图，实际上他们并不知道画图的目的，是解决什么问题。只是为了图表好看罢了。

> 一般而言，找到问题比较简单，一般是通过对比。比如上文说的UV，通过比较这周和上周的UV，发现UV下滑的问题。
>
> 数据分析的关键在于找到原因。数据分析，其实是为了冲着分析问题，解决问题去的。所以分析，其实有一个目标，上文所说的为画图而画图，其实他们并没有目标，所以就不知所云。
>
> 对于分析，我的理解是细分，然后层层剥离，一个问题有几个影响因素：那么我就去查看这几个影响因素的数据是否有异常，如果其中一个或几个有异常，则说明问题出在这一个或几个上面，层层细分，最终找到问题的源头。

## 拉动

这一节实际上是[如何接触用户](#如何接触用户)的具体实施。本节也极其重要。实质上我的理解，这一节更细分的话属于运营的工作。

拉动分为两大类：平台拉动和口碑拉动

### 平台拉动

> 书中认为：
>
> 总拉动人数 = 平台A活跃用户 $\times$ 平台A转化率 $\times$ 拉动时长 +
>
> = 平台B活跃用户 $\times$ 平台B转化率 $\times$ 拉动时长 +
>
> = 平台C活跃用户 $\times$ 平台A转化率 $\times$ 拉动时长 +
>
>  .....
>
> 但我认为，其实还需要加一个因素——拉动手段，但拉动手段并不好量化

平台的选择：目标用户重叠度高的平台

拉动手段：

* **展示面积**：展示面积越大，越醒目，转化率越高
* **植入**：如爱剪辑
* 融合：[我对于产品类别的理解](#我对于产品类别的理解)中平台类的产品衍生出新产品，形成产品矩阵

### 口碑拉动

口碑拉动主要依靠用户体验，对于算法类产品而言，具体的就是算法效果

## 持续更新

穷则变，变则通，通则久。产品应该螺旋上升，持续改进。

<pre class="mermaid">graph LR
A[现实问题反馈] --产生--> B[解决思路]
B --> C[改良执行]
C --作用于--> A</pre>

文中提到：

1. 为了实现小步快跑，短期验证，提倡敏捷开发
2. 对于功能的更新的取舍，用四象限法则

## Tip

* 用户的历史行为比当前意愿更有价值
* 焦点小组
* 可用性测试
* A/B测试
* 最小化可行产品



]]></content>
      <categories>
        <category>产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>气血津液</title>
    <url>/posts/f05e7890.html/</url>
    <content><![CDATA[

# 精

## 精和气血的关系

精是构成人体的基本物质,也是人体生长发育及各种功能活动的物质基础.**可以说,精是人体一切的基础,是所有的原料**

广义的精就是广义的气，精是所有的原料，其能化生气血，其化生的气主要指元气。

<pre class="mermaid">graph LR
A[精]  -->|化生| B[元气]
A -->|化生| C[血]
B -->|化生| D[神]
C --> |化生| A</pre>

> * 精是所有的原料，若肾精虚弱(精虚一般由于房事过多)，则需要直接补精，补气补血则治标不治本.精虚和气血两虚很像,因为精虚,则元气的来源和血的来源减少,气血自然虚弱,气虚则少气懒言，血虚则面色萎黄,所以很像气血两虚证.
> * 补精适用的方剂——龟鹿二仙胶，龟鹿二仙胶，由鹿角胶，龟板胶，枸杞子，人参四味药组成，鹿角胶和龟板胶补精，人参补元气，标本兼治。

## 精的分类及转化流程

精大体分为先天之精和后天之精两类,如下图所示:

<pre class="mermaid">graph LR
A[精] --- B[先天之精]
A --- C[后天之精]
C --- 水谷之精
C --- 脏腑之精
B --> D[生殖之精]</pre>

* 先天之精禀受于父母之精,来源于先天
* 后天之精实际上来源于脾胃,也就是来源于我们所说的食物中的营养物质,由脾胃的运化功能转化为后天之精,通过脏腑的运化到达各个脏腑变为脏腑之精,多余的形成后天之精,保存于肾中.所以如果先天之精不足,可用后天之精来补充.但临床上,不是什么食物都行的,如果以后天补先天,还是需要针对性的补精的食物,例如上文所述的龟鹿二仙胶,此外还有紫河车,鹿胎
* 生殖之精是由于先天之精由后天之精充养后,不断充盈,转化而来

肾精的转化流程如下图所示:



<pre class="mermaid">graph LR
A[水谷之精] --> |脾胃吸收|B[脏腑之精] 
B--> |多余部分| C[后天之精]
B -->|生成| 脏腑之气
C -->|充养| E[先天之精]
E -->|生成| 元气
E -->|生成| F[生殖之精]</pre>

# 气

气属阳,血属阴,气可以理解为人体的动力,气足则精力充沛,百病不生;气虚较为复杂,在各个脏腑和全身表现不同,后面详细述之,现在先概括气的来源.

## 气的来源

气的来源分为三条途径:

* 来源于精的生成.即由精所化,我们称为元气,**为气的主要组成部分**,我们所说的吃人参补气,即是补元气,事实上,但凡气虚,都是以补元气为主.此外,我们所说的精气,实际上是把精和气混淆,有时候并没有分得很清楚,两者亦能相互转化.所以我们可以看到,龟鹿二仙胶中即有人参又有两胶,实际上是精气双补,为大补之药.但龟鹿二仙胶吃过多会滋腻碍胃,必要时需要加陈皮或砂仁以减少滋腻
* 来源于脾胃.脾胃为后天之本,气血生化之源.后天之本即后天之精.如果我们没有吃饭,就没有力气,就是此来源不足所致.此外,如果此人虚弱,脾胃运化功能不足,不论什么虚,需先补脾胃,否则吃药并没有什么效果.
* 来源于自然界的清气.这主要依靠肺的呼吸功能.



<pre class="mermaid">graph LR
A[气] ---  C[来源于肾精的转化] 
C -.- 元气 
A --- D[来源于脾胃]
D-.- B[脾胃的运化功能]
B --- 行于脉内为营气
B --- 行于脉外为卫气
B --- 由脏腑之精转化为脏腑之气
A --- E[来源于自然界的清气]
E -.- F[肺的呼吸功能] 
F -.- 宗气的一部分</pre>

## 气虚

气虚则少气懒言,易疲倦,觉多,觉醒后少气懒言稍微好转(适量睡觉生气),脉弱,汗多等,这是气虚的基本症状.但少气懒言等前面的症状是气虚到一定程度才会有,若有轻微气虚,是不会有少气懒言这些症状的,或者说这些症状不明显.

此外,气虚表现在各个脏腑差异很大,例如在心,由于心主血脉,心气虚在推动血液无力,出现心慌气短等症状,在脾,则脾失健运,可能出现食少纳呆,水肿等症状.治疗也相差很远,例如肾气丸方(即崔氏八味丸)阴阳双补以达到补肾气的目的.再如脾气下陷用补中益气汤,用黄芪和升麻以助脾气升清.

一般气虚自然补气,补气药中,人参为补气首选,因为人参直接补元气,元气又通过三焦遍布全身.

较为有名的方剂:四君子汤

> 四君子汤:人参,白术,茯苓,甘草
>
> 人参为君,大补元气脾气,白术为臣,与茯苓相配燥湿利水且健脾,帮助中焦运化吸收,甘草作用有二:1,补脾气2,缓和

## 气的功能

* 推动作用:例如气行血,气行津液
* 温煦:类似于阳气的作用
* 防御:即卫气的作用
* 固摄:例如气虚则气不摄血,虚汗多,固摄不住津液
* 气化:即气的转化

## 气的运动

气的运动归纳为升降出入.

正常的气在不同的脏腑运动是不同的,一般来说,在上的降,例如心和肺在上焦,主降.在下的升,如肝和肾,脾胃在中间一升一降.所以人的气的升降在脏腑间是平衡的,如下图所示:

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/2022-02-02 120739.jpg" style="zoom: 25%;">

上图中,肝属春,时辰上属上午,理论上,若肝不升,在上午或春天用药效果会好一些.肺属秋,加强肺的属降功能则应该在秋天或下午用药.

**在腑中,气的运动基本上以降为顺**

## 气机失调

### 气滞

气滞分为两种:虚和实,虚即为气虚型的气滞,理解为气虚推动作用减弱,应当补气行气;实则为气的阻塞,应当用行气药

气滞的表现为胀,不同的是实胀据按,虚胀喜按,由此判定是实证还是虚证

特别需要注意的一点**:若是虚胀,单用行气药,会更加严重**,因为行气药是耗气的,用行气药只会越用越虚.固虚胀应该补气药和行气药一起用.

## 气的分类

气一共分为4类，其中，有三类都与脾中化生的水谷精微有关。

<pre class="mermaid">graph LR
A[气] --- B[卫气]
B --- D[肥腠理,斯开阖,卫外而为固]
A --- C[营气]
C --- E[水谷之精气]
A --- G[宗气]
G --- 自然界之清气+水谷精气结于胸中
A --- I[元气]
I --- 由精所化
D --- F[来源于水谷精气]
E --- F</pre>

我们所说的气虚造成的虚汗证实际上就是卫气虚**,但并非所有的卫气虚造成的虚汗证都用玉屏风散**(黄芪、白术、防风),黄芪和白术主升,主将气向上向外发散,但这个气来源来自于元气,若元气虚亏,用玉屏风散后前几付有效,后来无效,且会造成元气更加虚亏.所以,若此人本就元气虚亏,应是补气药和黄芪白术等药一起用,即补气又提气.

# 血

## 血的来源

血的来源有两种说法,以下是第一种:

* 血=津液+营气

前面说过,营气是水谷精气所化,水谷精气由脾胃运化水谷而来,而营气又是形成血的基本组成元素,所以脾胃的强弱决定了血的来源.此外,津液也来源于饮食,所以,可以说脾胃的强弱决定了血的来源的多少.一旦脾胃虚弱,则血的来源减弱,势必血虚.

来源第二种:

* 精血同源

<pre class="mermaid">graph LR
A[肾藏精] --- D[精生髓]
D --- E[髓化血]
E --- B[精血同源]
C[肝藏血] --- B
B --- F[肝肾同源]</pre>



## 血的功能

* 营养全身,包括面色,肌肉,皮肤,毛发.反过来,血虚则面色不华,毛发干枯,肢体麻木等
* 主神志活动.心主血脉,若气血充盈,则神志清醒.否则,则血虚,血虚则血脉不充,一是出现阴虚一系列症状,失眠多梦,烦躁,等.二是出现神志方面症状(心主血脉,血虚则影响心,心藏神):精神衰退,健忘

## 血的运行

血的运行主要和气有关

* 气推血走,气行血(行血的主要是心气)
* 血在脉管中走而不溢出是因为气的固摄作用

> 我的理解肝和心,对于血而言起着一静一动的作用,肝藏血,为静.心气行血为动.

## 血虚

血虚主要和心和肝有关,前面说道心主血脉,血虚则影响心,心藏神,所以血虚则影响神志;肝藏血,血虚则肝脏藏血不足,出现视物不明,夜盲等症状.下面对血虚的症状进行总结:

### 血虚症状

血虚首先是营养全身的功能失调,出现以下一组症侯:

* 面色不华
* 舌淡
* 脉细
* 毛发不荣
* 头晕眼花

心主血脉,故在心有:

* 心悸:我认为这里心悸的原因还不仅仅是血虚,可能还伴有心气虚或者心阳虚,也就是说有气血两虚之症.因为血能载气,血虚多伴有气虚之症.具体情况还要具体分析,若左寸脉细且无力,或此人少气懒言,或伴有大气下陷之症等,则可加补气药.此外,若此人无心气虚等症状,也可酌情加补心气药,气血相互关联,加行气补气药问题并不大.
* 白天健忘恍惚
* 晚上失眠多梦,烦躁:血属阴,气属阳.血虚会出现阴虚等一系列症侯,例如脉细,五心烦热等

在肝主要是肝藏血不足:

* 两目干涩
* 视物模糊
* 夜盲
* 月经量少
* 肢体麻木甚至抽搐
* 此外,血在肝中起着制约阳气升腾的作用.若血虚,则肝升腾太过,出现肝风内动等症状.

## 血虚的治疗

补血主方:四物汤:熟地,当归,川芎,白芍

> 方中,熟地和当归补血,当归和川芎活血.且川芎除活血外有行气的作用,类似于黄芪,其是把气向上向外提,以对付血虚的头晕眼花
>
> **通常情况下,补血一般要加补气药,气血双补.**用方:八珍汤:人参、白术、白茯苓、当归、川芎、白芍药、熟地黄、甘草.或单加人参和黄芪(这里黄芪的作用同川芎,有提气的作用,以对付血虚中的头晕眼花,且利水消肿,但**绝不可单用黄芪**,因为单加黄芪,反而耗气,人参必用)

> * 四物汤有上火的副作用:酌加生地
> * 当归不同部位作用不同:当归尾活血;当归身补血;当归头止血
> * 若怕地黄滋腻,酌情加陈皮或砂仁
> * 若视物不明酌情加枸杞或女贞子(不可用菊花,菊花清肝瞑目,是对付肝火旺盛的视物不明,而非血虚的视物不明)
> * 肢体麻木不灵活:酌情加疏经活络之药:鸡血藤
> * 心烦失眠多梦:酌情加龙眼肉,龙眼肉补血安神(在张锡纯的治心阳虚心气虚甚至大气下陷方中,龙眼肉为君药).(**不可用龙骨牡蛎**,龙骨牡蛎虽说可以治疗失眠烦躁,但有下坠之力,比如张仲景桂枝龙骨牡蛎汤,有下坠之力则血虚的头晕眼花的症状加重.此外,我的理解是桂枝龙骨牡蛎汤多数时候是对付虚火上冲的失眠烦躁,例如火不归元)
> * 肌肤干燥:酌情加阿胶,阿胶滋阴养血
> * 毛发不荣:酌情加桑寄生,旱莲子

# 津液

津液:津液是一切人体一切**正常**水液的总称.津可理解成纯粹的水分,液可理解成其中的营养物质

## 津液的来源

津液来源于脾胃,更通俗的说就是口渴喝水补充津液.













]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>中医</tag>
        <tag>中医基础理论</tag>
      </tags>
  </entry>
  <entry>
    <title>舌诊总结</title>
    <url>/posts/a3a01f7d.html/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="e8de4007a2b27ea2e9e5eaf58ffd1230784a3797c49d3d22221cc2aa3f0439fa">647bb22ce8122aecc5c04756795cc8db56ece07fc648ca974f9ebff8661cf44d</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">请输入密码</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>中医</tag>
      </tags>
  </entry>
  <entry>
    <title>Marr-Hildreth算子</title>
    <url>/posts/d6a12e0a.html/</url>
    <content><![CDATA[
## 概述

`Marr-Hildreth`算子是边缘检测算子的一种，相比于`Sobel`和`Laplace`这样的算子，其对于大区域，有更好的泛化性。

## 高斯拉普拉斯算子

`Marr`和`Hildreth`认为：像`Sobel`和`Laplace`这样的算法大区域的模糊边缘，一个图像的灰度变化和图像的尺度是相关的。所以对于大的区域，应该用大的算子；对于小的区域，应该用小的算子。满足这个条件的有高斯拉普拉斯算子(`LoG`)。

高斯拉普拉斯算子相当于是对图像先做高斯模糊，再做`Laplacian`变换：

已知二维的高斯函数为：
$$
G(x,y)= exp(-\frac{x^2+y^2}{2\sigma^2})		\tag 1
$$
再做`Laplacian`变换为:
$$
\nabla^2G(x,y)=\frac{\partial^2G(x,y)}{\partial x^2}+\frac{\partial^2G(x,y)}{\partial y^2}	\tag 2
$$
上式可以变换为：
$$
\frac{\partial }{\partial x}
\left( \frac{-x}{\sigma^2} \cdot exp(-\frac{x^2+y^2}{2\sigma^2})  \right)+
\frac{\partial }{\partial y}
\left( \frac{-y}{\sigma^2} \cdot exp(-\frac{x^2+y^2}{2\sigma^2}) \right)
\tag 3
$$
进一步化简为：
$$
\left( \frac{x^2}{\sigma^4} - \frac{1}{\sigma^2}\right) \cdot exp(-\frac{x^2 + y^2}{2\sigma^2})+
\left( \frac{y^2}{\sigma^4} - \frac{1}{\sigma^2}\right) \cdot exp(-\frac{x^2 + y^2}{2\sigma^2})
\tag 4
$$
整理后得：
$$
\nabla^2G(x,y)= \left( \frac{x^2+y^2-2\sigma^2}{\sigma^4} \right) \cdot exp(-\frac{x^2+y^2}{2\sigma^2})		\tag 5
$$
倒立的`LoG`算子入如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/火狐截图_2021-12-10T10-19-27.731Z.png)

其中，图a表示倒立的`LoG`算子。

## 高斯差分算子

对于公式（5），也可以用高斯差分（`DoG`）来代替：
$$
D_G(x,y)=
\frac{1}{2\pi\sigma_1^2} \cdot exp(-\frac{x^2+y^2}{2 \sigma_1^2})-
\frac{1}{2\pi\sigma_2^2} \cdot exp(-\frac{x^2+y^2}{2 \sigma_2^2})
\tag 6
$$
**所以，高斯差分的目的实际上是求边缘**。其中，$\sigma_1$以及$\sigma_2$和式（7）中的$\sigma$有如下对应关系：
$$
\sigma^2=\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2-\sigma_2^2}ln\left[ \frac{\sigma_1^2}{\sigma_2^2} \right]	\tag 7
$$
通常，$\sigma_1$和$\sigma_2$的比例为$1:1.75$和$1:1.6$.

也就是说，在用高斯差分时，先确定`LoG`中的$\sigma$的值，再利用$\sigma_1$和$\sigma_2$的比例计算$\sigma_1$和$\sigma_2$。

## 补充：高斯滤波器的性质

通常在计算二维的高斯滤波器时，不是直接的计算其滤波器，而是将其拆为两个单维的高斯滤波器。这使得其在计算效率上大大提高，下面说明高斯滤波器的性质。

### 可分离性

* 可分离性：即一个二维的高斯滤波可以分拆成两次一维滤波

如我们用滤波器$h(x,y)$对图像$f(x,y)$进行滤波，有：
$$
f(x,y) \ast h(x,y)=f(x,y) \ast h_x(x) \ast h_y(y)	\tag {10}
$$
其中，$h(x,y)=exp(-\frac{x^2+y^2}{2\sigma^2})$,$h_x(x)=exp(-\frac{x^2}{2\sigma^2})$,$h_y(y)=exp(-\frac{y^2}{2\sigma^2})$.

### 可叠加性

* 可叠加性：两个高斯函数的乘积和卷积也是高斯函数

设有两个高斯函数的均值和标准差分别为$m_f,m_g$和$\sigma_f,\sigma_g$

则两个高斯函数乘积所组成的高斯函数的均值和方差为：
$$
\left( 
m_{f \times g}=\frac{m_f\sigma_g^2+m_g\sigma_f^2}{\sigma_f^2+\sigma_g^2}, 
\sigma_{f \times g}= \sqrt{\frac{\sigma_f^2\sigma_g^2}{\sigma_f^2+\sigma_g^2}} 
\right)
$$
两个高斯函数卷积组成的高斯函数的均值和方差为：
$$
\left(
m_{ f\otimes g}=m_f + m_g,
\sigma_{f \otimes g}=\sqrt{\sigma_f^2+\sigma_g^2}
\right)
$$

]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>数字图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>SIFT算法总结</title>
    <url>/posts/a82dd048.html/</url>
    <content><![CDATA[
## 概述

`SITF`全名`Scale-invariant feature transform`,即尺度不变特征变换。实质上，`SIFT`所提取的特征是角点上的特征，且一定程度上保证它的旋转、尺度不变性。所以，`SIFT`本身并非一种匹配算法，`SIFT`实质上只是一种特征，由于`SIFT`提取的特征点比较稳定，我们在实际操作中仅仅是利用这种特征来做特征点匹配而已。

`SIFT`较为复杂，共分为以下几个步骤：

* 建立尺度空间
* 检测局部极值
* 计算关键点方向
* 建立关键点描述子

## 尺度空间

### 高斯金字塔

尺度空间用更通俗的说法就是高斯金字塔，高斯金字塔实际上就是隔点取点，对图像进行多次下采样。每做一次下采样图像的大小就变为了以前的一半，多次下采样之后就形成了一个类似金字塔的形状。如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1337254665_2720.jpg)

但仅仅是图像求高斯金字塔是不够的，我们需要对多次下采样的多个结果图像进行高斯模糊，每幅图的高斯模糊的$\sigma$的值是不同的。下面分别详述。

### 尺度空间

首先，在上述的求金字塔的过程中，需要补充一点:每一次下采样会下采样多张图片。例如，对原图$M \times N$大小的图片进行一次下采样，得到$\frac{M}{2} \times \frac{N}{2} $大小的图片是多张，而非一张。这样的多张图片称为一组（论文中被称为一个`octave`），这里的一组即一次下采样产生的多张图片。每一组的图片称为“层”，那么层的个数就为一组图像中图像的个数。

此时，对于每一组中的每一层图像，之前提到过，我们对他们的高斯模糊的$\sigma$是不同的，所以需要确定$\sigma$的值。

综上，现在对于尺度空间，我们需要确定以下三个数值：

* 尺度空间的组数。也就是下采样的次数
* 每一组的层数。一次下采样产生多少张图片
* 每一层的$\sigma$的值。每张图片高斯模糊的$\sigma$值

#### 尺度空间组数的确定

组数（$O$）：
$$
O=\lfloor log_2(min(M,N)) \rfloor - 	3 \tag {1}
$$
其中，$M$和$N$分别表示图片的长和宽.

#### 尺度空间层数的确定

层数$S$可以表示为：
$$
S = n+ 3 \tag 2
$$
其中，$n$表示需要提取的特征层的层数（后面会讲到）。

#### 高斯滤波参数的确定

每层和每组的$\sigma$之间的关系如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/火狐截图_2021-12-06T11-24-57.869Z.png)

其中，$k=2^{\frac{1}{n}}$,$\sigma_1=\sqrt{1.6^2-0.5^2}=1.52$。

上图中，第一组的第一层的$\sigma$值为$1.52$,第二层就为$k \times 1.52$,第三层就为$k^2 \times 1.52$,以此类推。第二组的起始$\sigma$为$2\sigma_1$也就是$2 \times 1.52$,后面的$\sigma$以$k$倍递增。

至此，我们就得到一个完整的高斯金字塔。

## 检测局部极值

本小节的目的在于选出特征点，也就局部特征点。

在`SIFT`算法中，局部极值点就是角点。在本小节中，共分为3个步骤：

* 找到图像的边缘点
* 求所有的边缘点在$x$,$y$和$\sigma$三个方向上的极值点，并做第一轮的筛选
* 求角点，做第二轮的筛选

### 查找初始关键点

在`SIFT`算法中，初始关键点定义为边缘点。那么，如何获取边缘点呢，我们最容易想到的就是`Canny`边缘检测，`Sobel`,`Laplacian`等。但在 `SIFT`算法中，是采用的高斯差分算法（`DoG`,`Difference of Gauss`）。

**采用高斯差分算法的目的就是边缘检测**,这里实际上是参考了<a href="/posts/d6a12e0a.html/" title="Marr-Hildreth算子">Marr-Hildreth算子</a>的边缘检测。

我们通过高斯差分算法得到了图像在不同尺度下的边缘点。

具体做法如下：

在[尺度空间](#尺度空间)中，我们得到了高斯金字塔，我只需要对相邻的两个层做差，即得到了高斯差分金字塔，示意图如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/火狐截图_2021-12-06T11-16-16.630Z.png)

从上图可以看出，我们已经得到了基本的图像边缘点，也就是图像的初始关键点。

### 改进关键点位置的精度

我们现在得到的是图像的边缘。`SIFT`算法认为一个特征点不仅是在$x$和$y$方向有较高的梯度，而且在$\sigma$方向上也有较高的梯度，也就是在上一节我们提到的“层”上有较高的梯度。我们可以把$\sigma$轴看成$z$轴，然后在$x$,$y$和$z$三个方向上查找极值。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/火狐截图_2021-12-16T10-47-55.229Z.png)

然而，在图像中，$x$,$y$和$\sigma$的值都是离散值，如果利用直接求差分的方式并不准确。所以算法利用了函数拟合的方式，即先用几个点拟合一个函数，再在拟合好的函数中求极值。

对于函数的拟合我们可以利用插值的方式，例如`三次样条插值`，`多项式插值`等。在论文中，作者采用了`泰勒展开式`。

令向量$(x,y,\sigma)$为$s$,由泰勒展开式为：
$$
f(s)=f(s_0)+\frac{\partial f}{\partial s}(s - s_0)+ \frac{1}{2} \cdot \frac{\partial^2f}{\partial s^2}(s - s_0)^2 + R_n(s)		\tag 3
$$
其中，$R_n(s)$为近似量。

令上式的$s_0$为$0$，上式可以近似为：
$$
f(s)=f(0)+\frac{\partial f}{\partial s}s+ \frac{\partial^2f}{\partial s^2}s^2 		\tag 4
$$
其中
$$
\frac{\partial f}{\partial s}=
\nabla f=
\begin{bmatrix}
\frac{\partial f}{\partial x} \\
\frac{\partial f}{\partial y} \\
\frac{\partial f}{\partial \sigma}
\end{bmatrix}
\tag 5
$$
$\frac{\partial^2f}{\partial s^2}$实际上为一个海森矩阵，令 $\frac{\partial^2f}{\partial s^2}$得到的海森矩阵为$H$，则$H$表示为：

$$
H=
\begin{bmatrix}
\partial^2D/\partial x^2 & \partial^2D/\partial x \partial y & \partial^2D/\partial x \partial \sigma \\
 \partial^2D/\partial x \partial y & \partial^2D/\partial y^2  & \partial^2D/\partial y \partial \sigma \\
 \partial^2D/\partial x \partial \sigma &  \partial^2D/\partial y \partial \sigma   & \partial^2D/\partial \sigma^2
\end{bmatrix}
\tag 6
$$
所以，公式（4）可以表示为：
$$
f(s)=f(0)+\nabla f \cdot s+\frac{1}{2}s^THs		\tag 7
$$
对式子（7）求导，并令导数为0，设可求得极值$\hat{s}$为：
$$
\hat{s}=-H^{-1}(\nabla f)		\tag 8
$$
这里得到的极值$\hat{s}$有可能是极大值也可能是极小值，算法中将极值代入$f(s)$中，也就是求$f(\hat{s})$的值，给定一个阈值$t_s$，若有$f(\hat{s}) > t_s$,则保留该点，认为它是关键点；否则删除该点。算法中给出的阈值$t_s$为$0.03$.

至此，我们边缘点的极值做一轮的筛选。

### 消除边缘响应

消除边缘特征相当于仅保留角点，在`SIFT`算法中，这一步基本上是照搬的`Harris`算法。所以，介绍这一部分就是直接介绍`Harris`.

> 对于图像中的一个点，分以为以下三种情况：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/v2-4cb0479e245d307e6b2ffe07f38067fd_720w.jpg)
>
> 即我们说的非边缘点，边缘点，以及角点。
>
> 对于图像中的一点$f(x,y)$,在$x$方向上移动$u$个像素值，在$y$方向上移动$v$个像素值。根据以上三种情况，可以得到数值的三种变化：
>
> * 在非边缘点上。由于像素点的值不怎么变化，则$f(x+u,y+v) - f(x,y)$较小
> * 在边缘点上。像素点只在一个方向上有变换，如上图中中间的小图 ，$f(x+u,y+v) - f(x,y)$大于非边缘点上的值
> * 在角点上。像素点在两个方向上有较大的变化，一般来说$f(x+u,y+v) - f(x,y)$的值最大
>
> 根据以上三种情况，我们由此建模：
> $$
> E(u,v)=\sum_{x,y}[f(x+u,y+v)-f(x,y)]^2			\tag 9
> $$
> 其中，$f(x,y)$表示图中像素点坐标$(x,y)$的值，$f(x+u,y+v)$表示将坐标$(x,y)$向$x$方向平移$u$个点，向$y$方向平移$v$个点的像素值。$[f(x+u,y+v)-f(x,y)]^2$表示$(x,y)$平移$(u,v)$后的差异。
>
> 这里的求和需要说明：这里的求和并非将图像中所有的像素点求和，而是一个过滤器框的求和，类似于`Sobel`这样的过滤器框，对框内所有的点进行求和。
>
> 所以，公式(9)实际上计算的就是对于一个以$(x,y)$为中心的过滤器框，平移了$(u,v)$之后，其像素值的差值$E(u,v)$
>
> 但是，类似于空间核的高斯滤波器，`Harris`在位置上越靠近$(x,y)$的像素点的贡献越大，越远离$(x,y)$的像素点的贡献越小。所以在`Harris`中加入了权重参数，由此，公式（9）演变为：
> $$
> E(u,v)=\sum_{x,y}W(x,y)[f(x+u,y+v)-f(x,y)]^2			\tag {10}
> $$
> 其中，$W(x,y)$表示在位置$(x,y)$上的权重。
>
> 在上式中，计算$E(u,v)$的值会非常慢，所以，在`SIFT`中，用了泰勒展开式来简化计算。我们知道，二维的泰勒展开式为：
> $$
> f(x,y)=
> f(x_a,y_a)+ 
> f_x(x_a,y_a)(x-x_a) +  f_y(x,y)(y-y_a) + \\
> \frac{1}{2!}f_{xx}(x-x_a)^2+\frac{1}{2!}f_{xy}(x-x_a)(y-y_a) + \frac{1}{2!}f_{yx}(x-x_a)(y-y_a) + \\
> \frac{1}{2!}f_{xy}(x-x_a)(y-y_a) + \frac{1}{2!}f_{yy}(y-y_a)^2 + O(n)
> \tag {11}
> $$
> 其中，$f_x$和$f_{xx}$分别表示对$f(x,y)$在$x$方向上的一阶和二阶求导，$y$同理。$O(n)$为一个无穷小量.
>
> 现在我们对$f(x+u,y+v)$进行泰勒一阶展开，如下所示：
> $$
> f(x+u,y+v) \approx f(x,y) + f_x(x,y)u + f_y(x,y)v		\tag {12}
> $$
> 则公式(10)可以化简为：
> $$
> E(u,v)= \sum_{x,y}W(x,y)[f_x(x,y)u + f_y(x,y)v]^2		\tag {13}
> $$
> 我们再次对公式（13）中的$[f_x(x,y)u+f_y(x,y)v]^2$化简，有：
> $$
> [f_x(x,y)u+f_y(x,y)v]^2=
> \begin{bmatrix}
> [f_x(x,y) ,f_y(x,y)]
> \begin{bmatrix}
> u \\
> v
> \end{bmatrix}
> \end{bmatrix}^2
> \\=\begin{bmatrix}
> [f_x(x,y) ,f_y(x,y)]
> \begin{bmatrix}
> u \\
> v
> \end{bmatrix}
> \end{bmatrix}^T
> \begin{bmatrix}
> [f_x(x,y) ,f_y(x,y)]
> \begin{bmatrix}
> u \\
> v
> \end{bmatrix}
> \end{bmatrix} \\
> = [u,v]\begin{bmatrix}
> f_x(x,y)  \\
> f_y(x,y)
> \end{bmatrix}
> [f_x(x,y) ,f_y(x,y)]
> \begin{bmatrix}
> u \\
> v
> \end{bmatrix} \\
> = [u,v] 
> \begin{bmatrix}
> f_x^2(x,y) & f_x(x,y) f_y(x,y) \\
> f_x(x,y) f_y(x,y) & f_y^2(x,y)
> \end{bmatrix}
> \begin{bmatrix}
> u \\
> v
> \end{bmatrix} 
> \tag {14}
> $$
> 令矩阵$\begin{bmatrix}
> f_x^2(x,y) & f_x(x,y) f_y(x,y) \\
> f_x(x,y) f_y(x,y) & f_y^2(x,y)
> \end{bmatrix}$为$M$,实质上$M$就是一个海森矩阵，则公式(13)可以化简为：
> $$
> E(u,v)=\sum_{x,y}W(x,y)[u,v]M
> \begin{bmatrix}
> u \\
> v
> \end{bmatrix}
> \tag {15}
> $$
> 其中，$u$,$v$和$W(x,y)$的值我们都是知道的。
>
> 前面我们说到，如果一个点角点上，其在两个方向上的变化都比较大，现在我们对$M$进行主成分分解（$M$为实对称矩阵，一定存在两个特征向量，且这两个特征向量正交）.设$M$对应的两个特征值分别为$\lambda_1$和$\lambda_2$,其中$\lambda_1> \lambda_2$.分以下三种情况：
>
> * 如果分解的特征值均比较大，即$\lambda_1 \approx  \lambda_2$说明在两个方向上的都有较大的变动，此时说明该点在角点上
> * 如果分解的特征值有一个比较大，且远大于另一个，即$\lambda_1 >> \lambda_2$，则说明该点在边缘上
> * 如果两个特征值都比较小，此时也有$\lambda_1 \approx  \lambda_2$，此时在平坦区域
>
> 所以我们现在要找角点，即找上述的第一种情况，两个特征值都比较大的点
>
> 在`Harris`中，并没有直接求$M$的特征值，因为求$M$的特征值计算速度过慢，而是利用另一种方式筛选第一种情况的点.
>
> 下面补充两条公式：
>
> > 矩阵的迹等于特征值的和,同时，也等于对角线上的元素之和.对于(15)中的$M$,有：
> > $$
> > Tr(M)=\lambda_1  +  \lambda_2=f_x^2(x,y) + f_y^2(x,y)		\tag {16}
> > $$
> > 其中,$Tr(M)$表示矩阵$M$的迹
> >
> > 矩阵的行列式等于特征值之积，有：
> > $$
> > Det(M)= \lambda_1\lambda_2=f_x^2(x,y)f_y^2(x,y)-[f_{xy}(x,y)]^2			\tag {17}
> > $$
> > 其中，$Det(M)$表示矩阵$M$的行列式
>
> 在`Harris`中，是用响应函数$R$来选择第一种情况点,响应函数$R$定义为：
> $$
> R=Det(M)-k \cdot (Tr(M))^2		\tag {18}
> $$
> 其中，$Det(M)$和$Tr(M)$分别表示$M$的行列式和迹，$k$为一个常数，通常取$0.04$到$0.06$.
>
> 响应函数$R$​有三种情况：
>
> * $R$大于0且$|R|$较大，说明该点为角点
> * $R$小于0，说明该点为边缘点
> * $R$大于0且$|R|$较小，说明该点为平坦地方的点
>
> 我们需要选择第一种情况，即$R$大于0且$|R|$较大的点
>
> 下面说明为何会这样判断。
>
> 由式（18），可以变换为：
> $$
> R=\lambda_1 \lambda_2 - k(\lambda_1 + \lambda_2)^2			\\
> =(1 - 2k)\lambda_1 \lambda_2 - k(\lambda_1^2 + \lambda_2^2)
> \tag {19}
> $$
>
> * 若是角点的情况，$\lambda_1$和$\lambda_2$均较大，且$\lambda_1 \approx  \lambda_2$,上式可以改成：
>
> $$
> R \approx (1-2k) \lambda_1^2-2k\lambda_1^2		\\
> =(1-4k) \lambda_1^2
> \tag {20}
> $$
>
> 由式（20）可知，此时$R$较大
>
> * 若是在平坦区域的情况，$\lambda_1$和$\lambda_2$均较小，且$\lambda_1 \approx  \lambda_2$，则式（20），很小
>
> * 若是在边缘部分的情况，$\lambda_1 >> \lambda_2$​，此时$\lambda_2$相比于$\lambda_1$可以忽略不计，式(19)可以改写成：
>   $$
>   R \approx (1-2k) \lambda_1 \lambda_2 - k \lambda_1^2  \\
>   = [(1-k) \lambda_2 - k \lambda_1] \lambda_1
>   \tag {21}
>   $$
>   式（21）中，由于$\lambda_1 >> \lambda_2$，则$(1-k) \lambda_2 - k \lambda_1$必为负数。

## 关键点方向

在得到关键点之后，我们需要计算出关键点的方向。

实际上，确定关键点的方向很简单，我们只要算出该点的梯度方向，即为关键点的方向。但论文中并未只求该点的梯度，而是求该点周围的点的梯度，然后进行统计，频度最高的方向即为该点的方向。

在[改进关键点位置的精度](#改进关键点位置的精度)一节中，我们求得关键点的$\sigma$的值，也就是式（3）泰勒展开式的极值点。首先，我们需要根据$\sigma$的值找出在高斯金字塔中（注意，不是高斯差分金字塔）距离$\sigma$最近的层，设该层为$F$.

在层$F$中，以该关键点为圆心,$1.5 \sigma$为半径划定一个领域，求此领域内所有点的梯度幅值和梯度方向。设领域内的任意一点为$(x^F,y^F)$,则其梯度幅值$M(x^F,y^F)$为：
$$
M(x,y)=[(F(x^F+1,y^F)-F(x^F-1,y^F))^2+(F(x^F,y^F+1)-F(x^F,y^F-1))^2]^{1/2}			\tag {22}
$$
其中，$F(x^F,y^F)$表示在层$F$中坐标$(x^F,y^F)$的像素值。

方向角$\theta(x,y)$表示为：
$$
\theta (x,y)=arctan
\left[
\frac{F(x^F,y^F+1)-F(x^F,y^F-1)}{F(x^F+1,y^F)-F(x^F-1,y^F)}
\right]
\tag {23}
$$
像`HOG`算子一样，我们对梯度方向进行直方图统计，**但进行统计叠加的并不是频数，而是幅度值乘以高斯权重**。

上述幅度值即为式（22）的幅度值，高斯权重是以$1.5 \sigma$为参数的高斯权重。

在得到直方图之后，值最大对应的方向即为该点的方向。若第二大值超过第一大值的$80 \%$,则该关键点有一个副方向。

## 关键点描述子

由于我们需要计算关键点之间的距离，所以我们需要量化关键点，这一步就是量化关键点，更确切的说是将一个关键点变为一个向量，以便计算相互之间的距离。

这里量化的指标还是梯度。同确定[关键点方向](#关键点方向)一样，还是以该关键点为中心，确定一个领域，这里选定的领域为$16 \times 16$的像素点，计算其梯度方向。如下图的左上图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/屏幕截图.png)

上图中$16 \times 16$的领域以$4 \times 4$的子区域为一个单位计算直方图。在此直方图中，以$45^ \circ$为一个bin进行统计，那么共有$8$个bin，以梯度幅值为直方图统计的量，再乘以高斯权重（这里步骤完全同[关键点方向](#关键点方向)，这里不再详细阐述）。如上图右上和右下所示。

那个共有$16$个子区域，每个子区域有$8$个bin,也就是$8$维的向量。所以，一个关键点的描述子为$16 \times 8= 128$维的向量（16代表16个子区域，8代表每个子区域的8维的bin）

为了保证`SIFT`的旋转不变性，这里在计算梯度方向时，**是将方向旋转到关键点的主方向，再进行统计直方图计算的。**（也就是说，以主方向为0角度）

为了降低光照对结果的影响，`SIFT`对描述子的结果进行了归一化，这样线性的光照变换就不会对结果有影响（例如光照增强，像素值同比例增加等）

## 参考资料

* 冈萨雷斯《数字图像处理》第四版
* [B站SIFT讲解(会飞的吴克)](https://www.bilibili.com/video/BV1Qb411W7cK?from=search&seid=2827726263307974389&spm_id_from=333.337.0.0)
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>数字图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>胸痹心痛短气病脉证治</title>
    <url>/posts/562ce80d.html/</url>
    <content><![CDATA[
师曰：夫脉当取太过不及，阳微阴弦，即胸痹而痛，所以然者，责其极虚也。今阳虚知在上焦，所以胸痹、心痛者，以其阴弦故也。

平人无寒热，短气不足以息者，实也。

> 

胸痹之病，喘息咳唾，胸背痛，短气，寸口脉沉而迟，关上小紧数，栝蒌薤白白酒汤主之。

### 栝蒌薤白白酒汤方

栝蒌实一枚(捣)   薤白半斤   白酒七升

右三味,同煮,取二升,分温再服.





胸痹不得卧,心痛彻背者,栝蒌薤白半夏汤主之.



气
]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>中医</tag>
        <tag>金匮要略</tag>
      </tags>
  </entry>
  <entry>
    <title>太阳变证</title>
    <url>/posts/364ada3d.html/</url>
    <content><![CDATA[
## 变证治则

太阳病三日,已发汗,若吐,若下,若温针,仍不解者,此为坏病,桂枝不中与之.观其脉证,知范何逆,随证治之.(16上)

> 坏病并非固定,根据每个人的体质不同而不同,可虚可实,可寒可热.

## 辩寒热真假

病人身大热,反欲得衣者,热在皮肤,寒在骨髓也;身大寒,反不欲近衣者,寒在皮肤,热在骨髓也.(11)

> 内寒外热:阴盛阳浮证
>
> 内热外寒症状包括:
>
> * 胸脯灼热
> * 口渴心烦
> * 舌红苔黄
> * 大便干燥,小便短赤
> * **手足厥冷**(这里的冷并非全身冷)
>
> **这里的内热外寒证实际上是指厥阴病篇的热厥**
]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
        <tag>太阳病</tag>
      </tags>
  </entry>
  <entry>
    <title>奈奎斯特采样定理推导</title>
    <url>/posts/88a0752c.html/</url>
    <content><![CDATA[
奈奎斯特采样定理：信号的采样频率必须大于被测信号最高频率的两倍时，采样之后的数字信号能够完整保留原始信号的信息。

# 傅里叶变换

设一个周期信号为$f(t)$，其[傅里叶变换](https://www.zhangqi2019.top/posts/fb91b52c.html/)可以表示为:
$$
F(\mu)=\xi\lbrace f(t)\rbrace=\int_{-\infty}^{\infty}f(t) \cdot e^{-i \omega t}dt	\tag 1
$$
其中，$\xi$表示对时域信号$f(t)$进行傅里叶变换。$F(\mu)$是变换后的频域函数，且是一个正负方向无限扩展的函数。

下图是一个方波的傅里叶变换的结果：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/972e8186a6266c18b8a19347e2d8d316.jpeg)

但在实际中，$F(\mu )$不会是一个无限扩展的函数，$F(\mu)$会受到模拟信号带宽的限制.即:
$$
F(\mu)=
\begin{cases} 
F(\mu) & \text {if $|\mu| < k$ } \\
0 & \text {others}
\end{cases}
\tag 2
$$

# 冲激函数及冲激串

## 冲激函数及性质

定义冲激函数$\delta(t)$：
$$
\delta(t)=
\begin{cases}
1& \text {if $t=0$ } \\
0 & \text{others}
\end{cases}		
\tag 3
$$
冲激函数具有以下性质：

* $\int_{-\infty}^{\infty}f(t) \cdot \delta(t) dt=f(0)$
* $\int_{-\infty}^{\infty}\delta(t)dt=1$
* $\int_{-\infty}^{\infty}f(t ) \cdot \delta(t- t_0) dt=f(t_0)$

## 冲激函数的傅里叶变换

冲激函数$\delta{(t)}$的傅里叶变换为：
$$
\xi\lbrace \delta(t)\rbrace = F(\mu)=\int_{-\infty}^{\infty}\delta(t)e^{-j2\pi\mu t} dt
$$
根据冲激函数的性质1，有:
$$
\xi\lbrace \delta(t)\rbrace =e^{-j2\pi\mu \cdot 0}=1	\tag 4
$$


下面求$\delta{(t-t_0)}$的傅里叶变换：
$$
\xi\lbrace \delta(t  - t_0)\rbrace = \int_{-\infty}^{\infty}\delta(t-t_0) \cdot e^{-j2\pi\mu t} dt
$$
同理，由冲激函数的性质3，有：
$$
\xi\lbrace \delta(t  - t_0)\rbrace = e^{-j2\pi\mu t_0} 		\tag 5
$$

## 冲激串

当我们用$f(t) \cdot \delta(t)$时，即是对$t=0$时刻的$f(t)$函数采样。但我们希望对$f(t)$的多个时刻采样。现在我们只需要对$\delta(t)$平移，则平移后的函数可以表示为
$$
\delta(t-n\Delta t)
$$
其中，$n \in Z$,$\Delta t$表示偏移。所以$t-n \Delta t$表示以$\Delta t$的$n$偏移

对平移后的函数进行相加，有：
$$
S_{\Delta T}(t)=\sum_{n=-\infty}^{+\infty}\delta(t-n\Delta t)	\tag 6
$$
上式称为冲激串。其函数图像如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/42f71c70646d19ccb0835d9c136078b4.jpeg)

**将$S_{\Delta T}(t)$与$f(t)$相乘则表示以$\Delta t$为间隔采样**

## 冲激串的傅里叶变换

### 补充：傅里叶变换的一个性质

在推导冲激串$S_{\Delta{t}}(t)$的傅里叶变换之前，需要补充一个傅里叶变换的性质：

> 对于信号$f(t)$，有傅里叶变换$F( \mu )$.即：
> $$
> \xi\lbrace f(t)\rbrace = F(\mu)=\int_{-\infty}^{\infty}f(t)e^{-j2\pi\mu t} dt
> $$
> 当我们把$f(t)$进行反傅里叶变换,有：
> $$
> \xi^{-1}\lbrace f(t)\rbrace =\int_{-\infty}^{\infty}f(t)e^{j2\pi\mu t} dt=\int_{-\infty}^{\infty}f(t)e^{-j2\pi\mu \cdot (-t)} dt
> $$
> 可以看到，上面两个等式互为相反数。即有：
> $$
> \xi\lbrace f(-t)\rbrace=\xi^{-1}\lbrace f(t)\rbrace
> $$
> 即，**一个函数的傅里叶变换和反傅里叶变换互为相反数**

### 冲激串的傅里叶级数

由于冲激串$S_{\Delta t}(t)$是一个离散函数我们可以用傅里叶级数对他进行分解，有：
$$
S_{\Delta t}(t)=\sum_{n=-\infty}^{\infty}c_n \cdot e^{\frac{j \cdot 2\pi n}{\Delta T}\cdot t}		\tag 7
$$
其中
$$
c_n=\frac{1}{\Delta t}\int_{-\frac{\Delta t}{2}}^{\frac{\Delta t}{2}}\delta(t) \cdot e^{-j\frac{2 \pi n}{\Delta T}t}dt		\tag 8
$$
根据冲激函数的性质1，有：
$$
c_n=\frac{1}{\Delta t} \cdot e^{-j \frac{2 \pi n}{\Delta t} \cdot 0}=\frac{1}{\Delta t}		\tag 9
$$
故有：
$$
S_{\Delta t}(t)=\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}e^{j \cdot \frac{2 \pi n}{\Delta t} \cdot t}		\tag {10}
$$

### 冲激串的傅里叶变换

对冲激串$S_{\Delta t}(t)$进行傅里叶变换，有：
$$
\xi \lbrace S_{\Delta t}(t) \rbrace = \frac{1}{\Delta t} \sum_{n=-\infty}^{\infty} \xi \lbrace e^{j \cdot \frac{2 \pi n}{\Delta t}t} \rbrace 		\tag {11}
$$

$\xi \lbrace e^{j \cdot \frac{2 \pi n}{\Delta t}t} \rbrace$可以写成$\xi \lbrace e^{-j \cdot 2 \pi \cdot t \cdot (\frac{-n}{\Delta t})  } \rbrace$，由公式（5）可知：
$$
\delta \left( \mu-(\frac{-n}{\Delta t}) \right)=
e^{-j \cdot 2 \pi \cdot t \cdot (\frac{-n}{\Delta t})  }=
\delta \left( \mu+\frac{n}{\Delta t} \right)	\tag {12}
$$
由之前补充的傅里叶变换的性质，有
$$
\xi \lbrace e^{j \cdot \frac{2 \pi n}{\Delta t}t} \rbrace=\delta(-(\mu+\frac{n}{\Delta t}))		\tag {13}
$$
又由于函数$\delta(t)$是一个偶函数，有:
$$
\delta(-(\mu+\frac{n}{\Delta t}))	=\delta(\mu+\frac{n}{\Delta t})	=\xi \lbrace e^{j \cdot \frac{2 \pi n}{\Delta t}t} \rbrace	\tag {14}
$$
综上，可得$e^{j \cdot \frac{2 \pi n}{\Delta t}t}$傅里叶变换的最终结果：
$$
\delta \lbrace e^{-j \cdot 2 \pi \cdot t \cdot (\frac{-n}{\Delta t})  } \rbrace=
\delta \left( \mu+\frac{n}{\Delta t} \right)	\tag {15}
$$

>注：书上(《数字图像处理》（刚萨雷斯版）)直接一步得到如下结果：
>$$
>\xi \lbrace e^{j \cdot \frac{2 \pi n}{\Delta t}t} \rbrace 	= \delta(\mu - \frac{n}{\Delta t})
>$$
>但我这里推了两遍都是式（12）的结果。如果哪位大神能推出这个结果的请告知。

由式（11）得到的冲激串$S_{\Delta t}(t)$的傅里叶变换，可变换为：
$$
\xi \lbrace S_{\Delta t}(t) \rbrace 
=\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty} \xi \lbrace e^{j \cdot \frac{2 \pi n}{\Delta t}t} \rbrace 
=\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}  \delta(\mu + \frac{n}{\Delta t})
\tag {16}
$$
由于$n \in (-\infty,\infty)$,有：
$$
\xi \lbrace S_{\Delta t}(t) \rbrace 
=\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}  \delta(\mu - \frac{n}{\Delta t})		\tag {17}
$$

# 模拟信号采样

## 模拟信号采样的傅里叶变换

现在我们对模拟信号$f(t)$进行采样，如何采样呢？就是用模拟信号$f(t)$乘以冲激串函数$S_{\Delta t}(t)$.下图是一个采样的例子：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/3f3884bf7e9421e12635d8d0aa18d220.jpeg)

我们对采样后的结果进行傅里叶变换，如下：
$$
\xi (f(t) \cdot S_{\Delta t}(t))
$$
根据`卷积定理`,有：
$$
\xi (f(t) \cdot S_{\Delta t}(t))
=\xi \lbrace f(t) \rbrace \ast \xi \lbrace S_{\Delta t}(t) \rbrace 
= F(\mu) \ast \xi \lbrace S_{\Delta t}(t) \rbrace
\tag {18}
$$
其中，$\ast$表示卷积

> 补充：卷积定理
>
> 设有两个信号函数$f_1(t)$和$f_2(t)$,其对应的傅里叶变换为$F_1(\mu)=\xi \lbrace f_1(t) \rbrace$和$F_2(\mu)=\xi \lbrace f_2(t) \rbrace$,则如下等式成立：
> $$
> F_1(\mu) \ast F_2(\mu)=\xi \lbrace f_1(t) \cdot f_2(t) \rbrace		\tag {19}
> $$
>
> $$
> \xi \lbrace f_1(t) \ast f_2(t) \rbrace = F_1(\mu) \cdot F_2(\mu)	\tag {20}
> $$
>
> 其中，$\ast$代表卷积，定义如下：
> $$
> f(t) \ast h(t)=\int_{-\infty}^{\infty}f(\tau)h(t- \tau)d\tau		\tag {21}
> $$
> 也就是说：
>
> * **时域的乘积的傅里叶变换等于频域的卷积**
> * **时域卷积的傅里叶变换等于频域的乘积**

在式（18）中，根据式（21）卷积的定义，有：
$$
F(\mu) \ast \xi \lbrace S_{\Delta t}(t) \rbrace = 
\int_{-\infty}^{\infty}F(\tau) \cdot \frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}  \delta(\mu - \tau - \frac{n}{\Delta t})	dt		\tag {22}
$$

$$
= \frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}\int_{-\infty}^{\infty}F(\tau) \cdot  \delta(\mu - \tau - \frac{n}{\Delta t})	dt		\tag {23}
$$

在式（23）中，由于$\delta(t)$为偶函数，则有：
$$
\delta(\mu - \tau- \frac{n}{\Delta t})
=\delta(-(\mu - \tau - \frac{n}{\Delta t}))
=\delta(\tau-\mu+\frac{n}{\Delta t})
=\delta(\tau-(\mu - \frac{n}{\Delta t}))
\tag {24}
$$
则式（23）可以转换为：
$$
\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}\int_{-\infty}^{\infty}F(\tau) \cdot  \delta(\mu - \tau - \frac{n}{\Delta t})	dt	=
\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}\int_{-\infty}^{\infty}F(\tau) \cdot  \delta(\tau - (\mu - \frac{n}{\Delta t}))	dt	
\tag {25}
$$
根据冲激函数的性质，式（25）可以化为：
$$
\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}\int_{-\infty}^{\infty}F(\tau) \cdot  \delta(\tau - (\mu - \frac{n}{\Delta t}))	dt	=
\frac{1}{\Delta t} \sum_{n=-\infty}^{\infty}F(\mu - \frac{n}{\Delta t})		\tag {26}
$$
**式（26）就是信号$f(t)$采样后的傅里叶变换的最终结果。**

理论上，$F(\mu)$是一个范围无限的函数，但在实际的运用中，由于带宽的限制，$\mu$是有范围的，设设备的带宽上线为$\mu_{max}$,则有：
$$
F(\mu)=
\begin{cases}
F(\mu), & \text {if $|\mu| < \mu_{max}$} \\
0, & \text others
\end{cases}
\tag {27}
$$
![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/iofdsalknfdsaoifadsfoid.png)

这说明$F(\mu)$是一个以$2 \mu_{max}$为长度的函数，而在式（26）中，相当于对$F(\mu)$平移$\frac{n}{\Delta t}（n \in Z）$个单位，再叠加。当$\frac{1}{\Delta t}$小于$2 \mu_{max}$时，式（26）中平移的两个函数就会重叠，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/fodafdassfj.png)

当$\frac{1}{\Delta t}=2 \mu_{max}$时，有：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/fioanlfko.png)

当$\frac{1}{\Delta t}>2 \mu_{max}$时，有：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/fasiofaf.png)

]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>计算机视觉</tag>
        <tag>数字图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLO4总结</title>
    <url>/posts/eae05d4d.html/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>太阳腑症</title>
    <url>/posts/48ccc03b.html/</url>
    <content><![CDATA[
## 太阳蓄水症

> 太阳蓄水症,总体而言分水停中焦和水停下焦两种,水停下焦表现为水停膀胱,膀胱气化失司.津液不能输布上乘.用五苓散方.水停中焦,为水停胃腕,用茯苓甘草汤主之.

### 五苓散方

太阳病,发汗后,大汗出,胃中干,胃中干,烦躁不得眠,欲得饮水者,少少与饮之,令胃气和则愈.若脉浮,小便不利,微热,消渴者,五苓散主之.(71)

猪苓十八铢(去皮)	泽泻一两六铢	白术十八铢	茯苓十八铢	桂枝半两(去皮)

上五味,捣为散,以白饮和服方寸匕,日三服.多饮暖水,汗出愈.如法将息.

发汗已,脉浮数,烦渴者,五苓散主之.(72)

中风发热,六七日不解而烦,有表里证,渴欲饮水,水入则吐者,名曰水逆,五苓散主之.(74)

太阳病,小便利者,以饮水多,必心下悸;小便少者,必苦里急也.(127)

本以下之,故心下痞,与泻心汤,痞不解,其人渴而口燥烦,小便不利者,五苓散主之.(156)

> **胃中津伤**:
>
> 由于太阳病发汗,汗出过多,导致汗出过多伤津,而出现胃中津伤,渴欲饮水.(伤津的部位和素体的体质有关,若肺阴虚则很可能伤肺,胃阴虚则很可能伤胃,以此类推)．
>
> 治少少与饮之**（温水）**

>**太阳蓄水症成因:**
>
>五苓散方的成因共分为两大类:
>
>* 邪气侵犯太阳经,邪气寻经入腑,造成太阳蓄水症
>* 太阳表证期间,正气抗邪于表而不能顾护于里,造成膀胱机能低下,饮水过多,导致水液内留
>
>**主症及病机:**
>
>太阳腑受邪主要是参与水液代谢部分失调,以下是`足太阳膀胱腑`的主要功能:
>
><img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/%E8%B6%B3%E5%A4%AA%E9%98%B3%E8%86%80%E8%83%B1%E8%85%91.png" style="zoom: 50%;">
>
>**主症:**
>
>* 口渴:膀胱受邪,化生津液的能力下降,即肾的蒸腾的能力下降,此时津液不能输布上承,故见口渴
>* 小便不利:膀胱气化失司,排除废水的能力下降,故见小便不利
>
>此外,膀胱气化失司导致水蓄下焦,导致苦里急.<font color="green">(类似于癃闭)</font>
>
>另外,膀胱受邪还导致水邪上逆,其症状**可能**有二:
>
>* 心下痞.是因为下窍不利,水无出路,导致水邪上逆,进而阻遏中焦气机.
>* 水逆症.(渴欲饮水,水入则吐).是因为水邪上逆导致胃气也上逆所致
>
>**临床上,凡是有水邪内结,无论在什么部位,均可用五苓散**

### 茯苓甘草汤

### 总结

| 症候     | 太阳蓄水症                                 | 胃虚水停症   | 胃中津伤症                   |
| -------- | ------------------------------------------ | ------------ | ---------------------------- |
| 口渴情况 | 口渴，消渴，烦渴，渴欲饮水                 | 不渴         | 口渴，消渴，烦渴，渴欲饮水   |
| 小便情况 | 小便不利，小便少                           |              |                              |
| 局部情况 | 少腹苦里急                                 | 心下悸       |                              |
| 其他症状 | （心下痞或水痞，水逆），脉浮或浮数，身微热 | 手足厥冷     | 烦躁不得眠                   |
| 病机     | 理由蓄水，外有表邪                         | 胃虚水停中焦 | 胃中津伤                     |
| 治法     | 外疏内利，表里两解                         | 温中化饮     | 饮水，少少与饮之**（温水）** |
| 用方     | 五苓散                                     | 茯苓甘草汤   | 少少与饮之**（温水）**       |

]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
      </tags>
  </entry>
  <entry>
    <title>Flask的Context机制(转)</title>
    <url>/posts/51b7d257.html/</url>
    <content><![CDATA[
此文转载自[Flask的Context机制](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/)

用过 Flask 做 Web 开发的同学应该不会不记得 App Context 和 Request Context 这两个名字——这两个 Context 算是 Flask 中比较特色的设计。[[1\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id11)

从一个 Flask App 读入配置并启动开始，就进入了 App Context，在其中我们可以访问配置文件、打开资源文件、通过路由规则反向构造 URL。[[2\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id12) 当一个请求进入开始被处理时，就进入了 Request Context，在其中我们可以访问请求携带的信息，比如 HTTP Method、表单域等。[[3\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id13)

所以，这两个 Context 也成了 Flask 框架复杂度比较集中的地方，对此有评价认为 Flask 的这种设计比 Django、Tornado 等框架的设计更为晦涩。[[4\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id14) 我不认同这种评价。对于一个 Web 应用来说，“应用” 和 “请求” 的两级上下文在理念上是现实存在的，如果理解了它们，那么使用 Flask  并不会晦涩；即使是使用 Django、Tornado，理解了它们的 Context 也非常有利于做比官网例子更多的事情（例如编写  Middleware）。

我因为开发 Flask 扩展，对这两个 Context 的具体实现也研究了一番，同时还解决了一些自己之前“知道结论不知道过程”的疑惑，所以撰写本文记录下来。

## Thread Local 的概念

从面向对象设计的角度看，对象是保存“状态”的地方。Python 也是如此，一个对象的状态都被保存在对象携带的一个特殊字典中，可以通过 `vars` 函数拿到它。

Thread Local 则是一种特殊的对象，它的“状态”对线程隔离 —— 也就是说每个线程对一个 Thread Local  对象的修改都不会影响其他线程。这种对象的实现原理也非常简单，只要以线程的 ID 来保存多份状态字典即可，就像按照门牌号隔开的一格一格的信箱。

在 Python 中获得一个这样的 Thread Local 最简单的方法是 `threading.local()`：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> threading</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>storage = threading.local()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>storage.foo = <span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(storage.foo)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">AnotherThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="meta">... </span>        storage.foo = <span class="number">2</span></span><br><span class="line"><span class="meta">... </span>        print(storage.foo)  <span class="comment"># 这这个线程里已经修改了</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>another = AnotherThread()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>another.start()</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(storage.foo)  <span class="comment"># 但是在主线程里并没有修改</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

这样来说，只要能构造出 Thread Local 对象，就能够让同一个对象在多个线程下做到状态隔离。这个“线程”不一定要是系统线程，也可以是用户代码中的其他调度单元，例如 Greenlet。[[5\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id15)

## Werkzeug 实现的 Local Stack 和 Local Proxy

Werkzeug 没有直接使用 `threading.local`，而是自己实现了 `werkzeug.local.Local` 类。后者和前者有一些区别：

- 后者会在 Greenlet 可用的情况下优先使用 Greenlet 的 ID 而不是线程 ID 以支持 Gevent 或 Eventlet 的调度，前者只支持多线程调度；
- 后者实现了 Werkzeug 定义的协议方法 `__release_local__`，可以被 Werkzeug 自己的 release_pool 函数释放（析构）掉当前线程下的状态，前者没有这个能力。

除 Local 外，Werkzeug 还实现了两种数据结构：LocalStack 和 LocalProxy。

LocalStack 是用 Local 实现的栈结构，可以将对象推入、弹出，也可以快速拿到栈顶对象。当然，所有的修改都只在本线程可见。和 Local 一样，LocalStack 也同样实现了支持 release_pool 的接口。

LocalProxy 则是一个典型的代理模式实现，它在构造时接受一个 callable  的参数（比如一个函数），这个参数被调用后的返回值本身应该是一个 Thread Local 对象。对一个 LocalProxy  对象的所有操作，包括属性访问、方法调用（当然方法调用就是属性访问）甚至是二元操作 [[6\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id16) 都会转发到那个 callable 参数返回的 Thread Local 对象上。

LocalProxy 的一个使用场景是 LocalStack 的 `__call__` 方法。比如 `my_local_stack` 是一个 LocalStack 实例，那么 `my_local_stack()` 能返回一个 LocalProxy 对象，这个对象始终指向 `my_local_stack` 的栈顶元素。如果栈顶元素不存在，访问这个 LocalProxy 的时候会抛出 `RuntimeError`。

## Flask 基于 Local Stack 的 Context

Flask 是一个基于 Werkzeug 实现的框架，所以 Flask 的 App Context 和 Request Context 也理所当然地基于 Werkzeug 的 Local Stack 实现。

在概念上，App Context 代表了“应用级别的上下文”，比如配置文件中的数据库连接信息；Request Context 代表了“请求级别的上下文”，比如当前访问的 URL。

这两种上下文对象的类定义在 `flask.ctx` 中，它们的用法是推入 `flask.globals` 中创建的 `_app_ctx_stack` 和 `_request_ctx_stack` 这两个单例 Local Stack 中。因为 Local Stack 的状态是线程隔离的，而 Web 应用中每个线程（或 Greenlet）同时只处理一个请求，所以 App Context 对象和 Request Context 对象也是请求间隔离的。

当 `app = Flask(__name__)` 构造出一个 Flask App 时，App Context 并不会被自动推入 Stack 中。所以此时 Local Stack 的栈顶是空的，`current_app` 也是 unbound 状态。

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> flask.globals <span class="keyword">import</span> _app_ctx_stack, _request_ctx_stack</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>app = Flask(__name__)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_app_ctx_stack.top</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_request_ctx_stack.top</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_app_ctx_stack()</span><br><span class="line">&lt;LocalProxy unbound&gt;</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> flask <span class="keyword">import</span> current_app</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>current_app</span><br><span class="line">&lt;LocalProxy unbound&gt;</span><br></pre></td></tr></table></figure>

这也是一些 Flask 用户可能被坑的地方 —— 比如编写一个离线脚本时，如果直接在一个 Flask-SQLAlchemy 写成的 Model 上调用 `User.query.get(user_id)`，就会遇到 `RuntimeError`。因为此时 App Context 还没被推入栈中，而 Flask-SQLAlchemy 需要数据库连接信息时就会去取 `current_app.config`，current_app 指向的却是 `_app_ctx_stack` 为空的栈顶。

解决的办法是运行脚本正文之前，先将 App 的 App Context 推入栈中，栈顶不为空后 `current_app` 这个 Local Proxy 对象就自然能将“取 config 属性” 的动作转发到当前 App 上了：

Python Shell

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ctx = app.app_context()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ctx.push()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_app_ctx_stack.top</span><br><span class="line">&lt;flask.ctx.AppContext object at <span class="number">0x102eac7d0</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_app_ctx_stack.top <span class="keyword">is</span> ctx</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>current_app</span><br><span class="line">&lt;Flask <span class="string">'__main__'</span>&gt;</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ctx.pop()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_app_ctx_stack.top</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>current_app</span><br><span class="line">&lt;LocalProxy unbound&gt;</span><br></pre></td></tr></table></figure>

那么为什么在应用运行时不需要手动 `app_context().push()` 呢？因为 Flask App 在作为 WSGI Application 运行时，会在每个请求进入的时候将请求上下文推入 `_request_ctx_stack` 中，而请求上下文一定是 App 上下文之中，所以推入部分的逻辑有这样一条：如果发现 `_app_ctx_stack` 为空，则隐式地推入一个 App 上下文。

所以，请求中是不需要手动推上下文入栈的，但是离线脚本需要手动推入 App Context。如果没有什么特殊困难，我更建议用 Flask-Script 来写离线任务。[[7\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id17)

## 两个疑问

到此为止，就出现两个疑问：

- 为什么 App Context 要独立出来：既然在 Web 应用运行时里，App Context 和 Request Context 都是 Thread Local 的，那么为什么还要独立二者？
- 为什么要放在“栈”里：在 Web 应用运行时中，一个线程同时只处理一个请求，那么 `_req_ctx_stack` 和 `_app_ctx_stack` 肯定都是只有一个栈顶元素的。那么为什么还要用“栈”这种结构？

我最初也被这两个疑问困惑过。后来看了一些资料，就明白了 Flask 为何要设计成这样。这两个做法给予我们 **多个 Flask App 共存** 和 **非 Web Runtime 中灵活控制 Context** 的可能性。

我们知道对一个 Flask App 调用 `app.run()`  之后，进程就进入阻塞模式并开始监听请求。此时是不可能再让另一个 Flask App 在主线程运行起来的。那么还有哪些场景需要多个 Flask  App 共存呢？前面提到了，一个 Flask App 实例就是一个 WSGI Application，那么 WSGI Middleware  是允许使用组合模式的，比如：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> werkzeug.wsgi <span class="keyword">import</span> DispatcherMiddleware</span><br><span class="line"><span class="keyword">from</span> biubiu.app <span class="keyword">import</span> create_app</span><br><span class="line"><span class="keyword">from</span> biubiu.admin.app <span class="keyword">import</span> create_app <span class="keyword">as</span> create_admin_app</span><br><span class="line"></span><br><span class="line">application = DispatcherMiddleware(create_app(), &#123;</span><br><span class="line">    <span class="string">'/admin'</span>: create_admin_app()</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

这个例子就利用 Werkzeug 内置的 Middleware 将两个 Flask App 组合成一个一个 WSGI Application。这种情况下两个 App 都同时在运行，只是根据 URL 的不同而将请求分发到不同的 App 上处理。

Note

需要注意的是，这种用法和 Flask 的 Blueprint 是有区别的。Blueprint  虽然和这种用法很类似，但前者自己没有 App Context，只是同一个 Flask App 内部整理资源的一种方式，所以多个  Blueprint 可能共享了同一个 Flask App；后者面向的是所有 WSGI Application，而不仅仅是 Flask  App，即使是把一个 Django App 和一个 Flask App 用这种用法整合起来也是可行的。

如果仅仅在 Web Runtime 中，多个 Flask App 同时工作倒不是问题。毕竟每个请求被处理的时候是身处不同的 Thread  Local 中的。但是 Flask App 不一定仅仅在 Web Runtime 中被使用 —— 有两个典型的场景是在非 Web  环境需要访问上下文代码的，一个是离线脚本（前面提到过），另一个是测试。这两个场景即所谓的“Running code outside of a  request”。

## 在非 Web 环境运行 Flask 关联的代码

离线脚本或者测试这类非 Web 环境和和 Web 环境不同 —— 前者一般只在主线程运行。

设想，一个离线脚本需要操作两个 Flask App 关联的上下文，应该怎么办呢？这时候栈结构的 App Context 优势就发挥出来了。

offline_script.py

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> biubiu.app <span class="keyword">import</span> create_app</span><br><span class="line"><span class="keyword">from</span> biubiu.admin.app <span class="keyword">import</span> create_app <span class="keyword">as</span> create_admin_app</span><br><span class="line"></span><br><span class="line">app = create_app()</span><br><span class="line">admin_app = create_admin_app()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">copy_data</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> app.app_context():</span><br><span class="line">        data = read_data()  <span class="comment"># fake function for demo</span></span><br><span class="line">        <span class="keyword">with</span> admin_app.app_context():</span><br><span class="line">            write_data(data)  <span class="comment"># fake function for demo</span></span><br><span class="line">        mark_data_copied()  <span class="comment"># fake function for demo</span></span><br></pre></td></tr></table></figure>

无论有多少个 App，只要主动去 Push 它的 App Context，Context Stack  中就会累积起来。这样，栈顶永远是当前操作的 App Context。当一个 App Context  结束的时候，相应的栈顶元素也随之出栈。如果在执行过程中抛出了异常，对应的 App Context 中注册的 `teardown` 函数被传入带有异常信息的参数。

这么一来就解释了两个疑问 —— 在这种单线程运行环境中，只有栈结构才能保存多个 Context  并在其中定位出哪个才是“当前”。而离线脚本只需要 App 关联的上下文，不需要构造出请求，所以 App Context 也应该和 Request Context 分离。

另一个手动推入 Context 的场景是测试。测试中我们可能会需要构造一个请求，并验证相关的状态是否符合预期。例如：

tests.py

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_app</span><span class="params">()</span>:</span></span><br><span class="line">    app = create_app()</span><br><span class="line">    client = app.test_client()</span><br><span class="line">    resp = client.get(<span class="string">'/'</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="string">'Home'</span> <span class="keyword">in</span> resp.data</span><br></pre></td></tr></table></figure>

这里调用 `client.get` 时，Request Context 就被推入了。其特点和 App Context 非常类似，这里不再赘述。

## 为何建议使用 App Factory 模式

从官方文档来看，Flask 有 Singleton 和 App Factory 两种用法。前一种用法和其他的一些 Web 框架（如 Bottle、Sinatra）的门面广告很相似，因为代码精简，所以显得非常的“帅”：

app.py

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, render_template</span><br><span class="line"><span class="keyword">from</span> flask.ext.sqlalchemy <span class="keyword">import</span> SQLAlchemy</span><br><span class="line"><span class="keyword">from</span> flask.ext.login <span class="keyword">import</span> LoginManager</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line">db = SQLAlchemy(app)</span><br><span class="line">login_manager = LoginManager()</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">home</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">'home.html'</span>)</span><br></pre></td></tr></table></figure>

但是这种“帅”是有代价的。一个最麻烦的问题就是编写测试的时候：

test_app.py

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestApp</span><span class="params">(unittest.TestCase)</span>:</span></span><br><span class="line"></span><br><span class="line">    DEBUG = <span class="literal">False</span></span><br><span class="line">    TESTING = <span class="literal">True</span></span><br><span class="line">    SQLALCHEMY_DATABASE_URI = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.app = create_app()</span><br><span class="line">        self.app.config.from_object(self)</span><br><span class="line">        self.client = self.app.test_client()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_app</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="meta">        @self.app.route('/test/&lt;int:id_&gt;')</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">my_view</span><span class="params">(id_)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">'#%d'</span> % id_</span><br><span class="line">        resp = self.client.get(<span class="string">'/test/42'</span>)</span><br><span class="line">        self.assertEqual(resp.data, <span class="string">'#42'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_home</span><span class="params">(self)</span>:</span></span><br><span class="line">        resp = self.client.get(<span class="string">'/'</span>)</span><br><span class="line">        self.assertIn(<span class="string">'Welcome'</span>, resp.data)</span><br></pre></td></tr></table></figure>

在上面的例子中，我为了测试给 App 新挂载了一个 View 函数。这是很常见的一个测试需求。但是如果 Flask App 实例是单例的，这种做法就会“弄脏”下一个测试的运行。更加麻烦的是，上述例子中如果 `test_home` 在 `test_app` 之前运行了，Flask 的开发者防御机制会认为这是一个“已经开始处理 Web 请求了，又挂载了视图” [[8\]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id18) 的失误，从而抛出 `RuntimeError`。

所以除非是应用简单到不需要 Web 层测试，否则还是尽量使用 App Factory 模式比较好。况且配合 Blueprint 的情况下，App Factory 还能帮助我们良好地组织应用结构：

happytree/app.py

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> werkzeug.utils <span class="keyword">import</span> import_string</span><br><span class="line"></span><br><span class="line">extensions = [</span><br><span class="line">    <span class="string">'happytree.ext:db'</span>,</span><br><span class="line">    <span class="string">'happytree.ext:login_manager'</span>,</span><br><span class="line">]</span><br><span class="line">blueprints = [</span><br><span class="line">    <span class="string">'happytree.views:bp'</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_app</span><span class="params">()</span>:</span></span><br><span class="line">    app = Flask(__name__)</span><br><span class="line">    <span class="keyword">for</span> ext_name <span class="keyword">in</span> extensions:</span><br><span class="line">        ext = import_string(ext_name)</span><br><span class="line">        ext.init_app(app)</span><br><span class="line">    <span class="keyword">for</span> bp_name <span class="keyword">in</span> blueprints:</span><br><span class="line">        bp = import_string(bp_name)</span><br><span class="line">        app.register_blueprint(bp)</span><br><span class="line">    <span class="keyword">return</span> app</span><br></pre></td></tr></table></figure>

这样就能彻底摆脱 `app.py` 和 View 模块“互相 Import”的纠结了。

好吧其实这一节和 Context 没啥关系……

## 参考

[[1]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id1)	Flask 文档对 [Application Context](http://flask.pocoo.org/docs/appcontext/) 和 [Request Context](http://flask.pocoo.org/docs/reqcontext/) 作出了详尽的解释；
[[2]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id2)	通过访问 flask.current_app；
[[3]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id3)	通过访问 flask.request；
[[4]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id4)	Flask(Werkzeug) 的 Context 基于 Thread Local 和代理模式实现，只要身处 Context 中就能用近似访问全局变量的的方式访问到上下文信息，例如 flask.current_app 和 flask.request；Django 和 Tornado 则将上下文封装在对象中，只有明确获取了相关上下文对象才能访问其中的信息，例如在视图函数中或按照规定模板实现的 Middleware 中；
[[5]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id5)	基于 Flask 的 Web 应用可以在 Gevent 或 Eventlet 异步网络库 patch 过的 Python 环境中正常工作。这二者都使用 Greenlet 而不是系统线程作为调度单元，而 Werkzeug 考虑到了这点，在 Greenlet 可用时用 Greenlet ID 代替线程 ID。
[[6]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id6)	Python 的对象方法是 Descriptior 实现的，所以方法就是一种属性；而 Python 的二元操作可以用双下划线开头和结尾的一系列协议，所以 foo + bar 等同于 foo.__add__(bar)，本质还是属性访问。
[[7]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id7)	[Flask-Script](http://flask-script.readthedocs.org/) 是一个用来写 manage.py 管理脚本的 Flask 扩展，用它运行的任务会在开始前自动推入 App Context。将来这个“运行任务”的功能将被整合到 Flask 内部。
[[8]](https://blog.tonyseek.com/post/the-context-mechanism-of-flask/#id9)	详见 Flask 源码中的 setup_method 装饰器。

Posted by Jiangge Zhang 2014 年 07 月 21 日 Flask Python

]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Haar小波变换</title>
    <url>/posts/4f0e3ed4.html/</url>
    <content><![CDATA[
# 概述

## 傅里叶变换的劣势

关于傅里叶变换，请看[傅里叶级数与傅里叶变换推导](https://www.zhangqi2019.top/posts/fb91b52c.html/)

我们知道,傅里叶级数是将一个波展开成无限个三角函数相叠加。但当一个噪声存在时，傅里叶级数拟合的效果并不佳，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210727145724.jpg)

上图中，是一个存在噪声的信号波。这种噪声表现为某一点不正常变化，而周围是正常的。但当我们用傅里叶级数从时域转频域时，傅里叶级数为了拟合这一噪声的影响，不得不使用高频基波来拟合这一噪声。但由于三角波是全局波，这又会影响其他地方的分解。所以，综上所述，傅里叶对于突变的分解并不会很理想。

**此外，傅里叶级数仅能提供频域信息，不能提供这个噪声发生的时间（也是由于傅里叶级数是全局波）**

## 局部波

局部波即当有一个噪声或扰动局部存在时，影响的仅是一个基波的局部。小波即是局部波，下面介绍Haar小波

# Haar小波

## Haar尺度函数

假设有一个信号波如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210728115405.jpg)

我们现在用很简单的基波去表示它，这个基波非常简单，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210727160954.png)

函数$\phi(x)$表示一个基波函数，在小波中被称为尺度函数，也被称为父小波，$\phi(x)$的取值范围在$(0,1)$,且取值衡为1，用数学公式表示为：
$$
\phi(x)=
\begin{cases} 
1, & \text {if} & 0 \leq x \leq 1 \\
0, & \text {others}
\end{cases}
\tag {1}
$$
对于不在$\phi(x)$返回内的我们可以通过平移以及乘以一个系数得到，这样我们就可以用$\phi(x)$来近似的拟合上图中的信号了。

* 平移的函数我们用$\phi(x-k)$表示，他表示将函数$\phi(x)$向右平移$k$个单位，其中$k \in Z$,当$k<0$时，表示$\phi(x)$向左平移了$k$个单位。 * 乘以一个系数相当于压缩或者拉伸，我们用$a_k\phi(x)$表示，其中$a_k \in r$.当$a_k<1$时，表示将$\phi(x)$压缩；当$a_k>1$时，表示将$\phi(x)$拉伸

综上，我们能够用$\phi(x)$通过平移和拉伸表示$x$轴上的波，用公式可以表示为：
$$
\sum_{k \in Z}a_k \phi(x-k), { a_k \in R}	\tag {2}
$$
从函数空间的角度看，对于一个取值范围为$(a,b),(其中a \in Z 且 b \in Z)$的波，会将其分解成$b-a$个基函数，基函数的坐标为$a_k$.当波的范围为无限时，此时的分解则为无限维的函数空间。换句话说，一个函数可由$\phi(x)$通过平移和拉伸线性张成。

最终我们拟合的效果如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210728135704.jpg)

可以看到，由于尺度函数$\phi(x)$的粒度太“粗”，导致我们拟合的结果存在锯齿状。我们并不能很好的去拟合原始的波。归根结底，还是$\phi(x)$的构造太粗糙，为了解决这个问题，我们完全可以去“精细化”尺度函数$\phi(x)$，从而减弱或消除这种锯齿状。那如何消除呢，其实方法也很简单——减短$\phi(x)$的周期。

* 当我们用$\phi(2x)$时，有尺度函数$\phi(x)$的定义（1）。当$0<2x<1$时，$y=1$,即$0<x<0.5$时，$y=1$ 看到没有，之前的$\phi(x)$在$(0,1)$上的一次取值，我们可以用两次$\phi(2x)$来表示它,即$\phi(2x)$和$\phi(2x - 1)$。这就意味着这种锯齿我们可以少一半，也就是粒度“更细一倍”。 * 当我们用$\phi(4x)$时，有尺度函数$\phi(x)$的定义（1）。当$0<4x<1$时，$y="1$,即$0<x<0.25$时，$y=1$" 当我们用$\phi(8x)$时，有尺度函数$\phi(x)$的定义（1）。当$0<8x<1$时，$y="1$,即$0<x<0.125$时，$y=1$" ... **当随着$x$前面的系数越来越大时，基波表示的粒度也就越来越细，当该系数趋于无限时，这种线性张成方式和原信号的差距将减少为无穷小**。在我们表示原来的信号时，也就越来越像。但这里有一个要求，就是前面的系数必须要为2的倍数，这涉及到一个子空间的概念，这里先不解释为什么，后面会解释。下面我们用数学语言复述一遍。 设$v_0$是所有形如（2）中的函数组成的空间，那么$j$级阶梯函数空间可以表示为$v_j$,他是由函数集 $$ \lbrace...,\phi(2^j + 1),\phi(2^j),\phi(2^j-1),....\rbrace \tag {3} 在实数域上线性张成的。用形如公式（2）的形式就可以表示为： \sum_{k \in z}a_k \phi(2^jx-k), { a_k r 且 j z^+} {4} 由于$j$越大，尺度函数的范围越小，于是有如下关系： v_0 \subset v_1 v_2 v_j v_{j+1} {5} 可以看到,如果公式（4）前面的系数2的倍数，则公式（5）将不成立。换句话说，这种子空间的关系将不成立。这种不成立将影响到后续`haar小波基`的生成。 ## haar小波基函数 现在我们能够用尺度函数$\phi(x)$来线性张成信号波了，但现在还不够。回忆一下傅里叶变换，我们把信号波分解成不同频率的基波的线性张成，再根据我们的需要做各种变换。但现在我们得到的尺度函数$\phi(x)$的“粒度”是一样的，换句话说，我们现在还不能像傅里叶级数那样分离出高频和低频。所以我们下一步要分离出高低频，变换出不同频率的基函数。 在公式（5）中，我们得到了一种子空间的包含关系，而且我们知道，这种层层包含的空间中的基是“从粗到细”。我们这好可以利用这种关系构建分离出高低频的频域空间。**但我们必须满足一个条件：由于基函数（基波）是一个基，我们必须保证基是正交的** 举例来说，我们在$v_0$空间中有$k$个基$\phi(x-k)$,其中$k z$.我们需要在$v_1$找到一个基$\psi(x)$,满足$\psi(x)$和$\phi(x-k)$均正交。用更数学的语言表达就是：在$v_1$空间中找到$v_0$的正交补。> 正交补的定义：
>
> 设$V_0$是内积空间$V$的子空间，$V_0$的正交补，记为$V_0^{\bot}$,是$V$上所有与$V_0$正交的矢量集合，即:
> $$
> V_0^{\bot}=\lbrace v \in V; \langle v,w \rangle = 0, w \in V_0 \rbrace	\tag {6}
> $$
> 其中，$\langle v,w \rangle$表示内积

符合以上两点（正交性以及属于$V_1$空间）最简单的$\psi(x)$为：
$$
\psi(x) = \phi(2x) - \phi(2x - 1)	\tag {7}
$$
其对应的图像为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210729173244.png)

显然，公式（7）中$\psi(x)$ 是$V_1$空间中的元素。下面证明和$V_0$中的基正交：

> 显然$\psi(x)$和$\phi(x -k),k \neq 0$正交，因为$\psi(x)$仅在$(0,1)$范围内取值。
>
> $\psi(x)$和$\phi(x)$的内积可以写成：
> $$
> \int_{-\infty}^{\infty}\phi(x) \psi(x)dx=\int_0^{\frac{1}{2}}1dx-\int_{\frac{1}{2}}^{1}1dx=0
> $$
> 故$\psi(x)$和$V_0$正交。
>
> 故$\psi(x)$可以作为一个小波基。

以上只是在在$V_1$空间中找$V_0$的正交补，下面我们推广到更一般的情况。

对于$V_j$和$V_{j+1}$,我们能找到空间$W_j$,使得$W_j$是$V_{j+1}$中$V_j$的正交补空间，即：
$$
V_{j+1}=V_j \bigoplus W_{j}		\tag {8}
$$
其中，$W_j$是由形如
$$
\sum_{k \in Z} a_k \psi(2^jx-k), a_k \in R		\tag {9}
$$
构成的空间，由$\psi(x)$的定义公式（7），则在$W_j$中的小波基为：
$$
\psi(2^jx)=\phi(2^{j+1}x)-\phi(2^{j+1}-1)	\tag {10}
$$
以此类推：
$$
V_j=V_{0} \bigoplus W_0 \bigoplus W_1 \bigoplus W_2 ...		\tag {11}
$$
从公式（9）中可以看出，$V_j$是可以由$V_0$一步步“叠加”上来的，随着空间$W_i$中$i$值的增大，空间就"越来越细"(见公式10)，我们在这些空间中取基就足以将波分为高频和低频。

# 小波的分解和重构
本节主要讲小波的应用，包括分解和重构，在开始之前我们需要简单的推导两个式子，便于后续计算.

有公式（7）有$\psi(x) = \phi(2x) - \phi(2x - 1)$，有：
$$
[\psi(x)+\phi(x)]/2=[\phi(2x) - \phi(2x - 1) + \phi(x)]=[\phi(2x) - \phi(2x - 1) + \phi(2x) + \phi(2x - 1)] = 2\phi(2x)
$$
则：
$$
\phi(2x)=[\psi(x)+\phi(x)] / 2	\tag {12}
$$
同理利用公式（7），可推得：
$$
\phi(2x-1)= [\phi(x) - \psi(x)]/2	\tag{13}
$$
更一般的，对于所有的$x \in R$,下列关系成立：
$$
\phi(2^jx)=[\psi(2^{j-1}x)+\phi(2^{j-1}x)]/2	\tag {14}
$$

$$
\phi(2^{j}x-1)=[\phi(2^{j-1}x)-\psi(2^{j-1}x)]/2 	\tag {15}
$$

## 分解

下面是一个小波分解的例子：

假设一个信号波可由`Haar`尺度函数表示为：
$$
f(x)=2\phi(4x)+2\phi(4x-1)+\phi(4x-2)-\phi(4x-3)
$$
下面将以上信号波分解成小波表示形式。

我们将每一个加法部分分开计算，由公式（14）和公式（15）：
$$
2 \cdot \phi(4x)=2 \cdot [\psi(2x)+\phi(2x)]/2 = \psi(2x)+\phi(2x)
$$

$$
2 \cdot \phi(4x-1)=2 \cdot [\phi(2x) - \phi(2x)] /2 = \phi(2x) - \phi(2x)
$$

$$
\phi(4x-2)=\phi[2(2x-1)]=[\psi(2x-1) + \phi(2x-1)]/2
$$

$$
\phi(4x-3)=\phi[2(2x-1)-1]=[\phi(2x-1)- \psi(2x-1)]/2
$$

以上四个式子合并，有：
$$
f(x) =  \psi(2x-1)+2\phi(2x)
$$
下面再对$2\phi(2x)$进行拆解：
$$
2 \cdot \phi(2x)=2 \cdot [\psi(x)+\phi(x)] / 2= \psi(x)+\phi(x)
$$
故最终的$f(x)$可以分解为：
$$
f(x)=\psi(2x-1)+\psi(x)+\phi(x)
$$


## 重构以及应用

重构实际上就是基波的加权，在`傅里叶变换`中,我们称为反傅里叶变换。更一般的说，就是频域转时域。

**通常在运用中，重构的参数不会完全使用分解时的参数，多数情况下，会少一部分，否则先分解再重构就没有意义**

* 如果在重构时仅加权“细粒度"的`Haar波`,那么就仅提取变化较大的波。即低通滤波器
* 如果在重构时仅加权“粗粒度"的`Haar波`,那么就仅提取变化较小的波。即高通滤波器

此外，在信号传输中，若只保留低频信号，可以仅传输分解后的权值，且仅传输低频的权值，接收方在收到权值后再重构成信号。这样即能够滤波，也能够极大的保证传输速度。





</2x<1$时，$y=1$,即$0<x<0.5$时，$y=1$></0$时，表示$\phi(x)$向左平移了$k$个单位。>]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>数字图像处理</tag>
        <tag>信号处理</tag>
      </tags>
  </entry>
  <entry>
    <title>《卓有成效的管理者》总结</title>
    <url>/posts/396e7675.html/</url>
    <content><![CDATA[
## 第一章 卓有成效是可以学会的

### 何为管理者

管理者的定义:管理者即为决策者.也就是说大到组织,小到自身事情,只要你是决策者,即是管理者.

> 本书虽说是在说组织的管理者,但小到自身,道理是一样的.相比而言,我认为管理自身的难度会小于组织的管理,因为自己是完全可控的,而他人不一定完全可控.换句话说,自身管理不当,绝不可能管理好一个组织.

具体到公司(组织)中,包含两方面:

* 企业的掌舵者(总决策者)
* 工作的组织者(细化的决策者)

> 一个公司的管理者应该包含至少上述一个方面.若是细分,即一部分人担任掌舵者,另一部分人担任组织者,这种属于有点规模的公司.CEO和COO分离就是很好的例子.若是两者合一则是较小的公司.

### 管理者如何有成效

第一章是所有的全书的总纲,开篇点明卓有成效是可以通过后天训练取得的,并包含以下五个方面:

* 时间管理:顾名思义,系统的管理时间
* 精确目标:以结果为导向
* 扬长避短
* 要事第一
* 决断能力:决策

在后面的章节中,分点论述.

## 第二章 掌握自己的时间

### 如何解决浪费时间

* 问题:由于我们时间的不当管理,导致工作效率低下

* 找到具体原因:通过记录自己的时间,得到时间日志,再根据时间日志得出自己浪费时间在什么地方.

* 解决问题:杜绝浪费自己时间而对自己理想结果而没有帮助的事.

> 通常而言,一个问题的到来我们有三种处理方式:
>
> * 解决问题
> * 推给别人解决问题
> * 不解决问题
>
> 显然,最后一种是下下之策,这里不谈.在后面一小节中都是以解决问题的方式,也就是第一种处理方式.对于第二种处理方式,我认为在工作中是可行的且是必要的.

### 工作中易浪费时间之事

作者在文中列出了工作中易浪费时间的事:

* 工作被打断:若工作被打断,则你可能需要更多的时间去完成这项任务,且结果还不理想
* 协调时间:组织越大,花在协调上的时间也就越多
* 对解决问题无益之事.(所做之事都是为了解决问题)
* 无效会议
* 策划不足
* 零碎时间做事(即**一件事分为零碎的多段,反而更费时间,故在时间规划时这一点应该特别注意**)

]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>太阳兼症</title>
    <url>/posts/dd3d2345.html/</url>
    <content><![CDATA[
提示:

* <font color="blue">蓝色</font>表示未理解
* <font color="red">红色</font>或**加粗**表示重要部分
* <font color="green">绿色</font>表示我自己的理解

## 葛根汤证

太阳病,项背强几几,无汗恶风,葛根汤主之.(31)

葛根四两	麻黄三两(去节)	桂枝二两(去皮)	生姜三两(切)	甘草二两(灸)	芍药二两	大枣二十枚(擘)

上七味,以水一斗,先煮麻黄,葛根,减二升,去白沫,内诸药,煮取三升,去滓,温服一升.覆取微似汗,余如桂枝法将息及禁忌.诸汤皆仿此.

> 葛根汤=桂枝汤+麻黄+葛根

## 葛根加半夏汤证

太阳与阳明合病者,必自下利,葛根汤主之.(32)

太阳与阳明合病,不下利但呕者,葛根加半夏汤主之.(33)

葛根四两	麻黄三两(去节)	甘草二两(灸)	芍药二两	桂枝二两(去皮)	生姜二两(切)	半夏半升(洗) 	大枣十二枚(擘)

上八味,以水一升,先煮葛根,麻黄,减二升,去白沫,内诸药,煮取三升,覆取微似汗.

>
>
>![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/%E5%A4%AA%E9%98%B3%E8%A1%A8%E5%AE%9E%E5%85%BC%E9%98%B3%E6%98%8E%E8%A1%A8%E8%AF%81.png)

## 大青龙汤症

太阳中风,脉浮紧,发热恶寒,身疼痛,不汗出而烦躁者,大青龙主之.若脉微弱,汗出恶风者,不可服之.服之则厥逆,筋惕肉瞤,此为逆也.(38)

大青龙汤方

麻黄六两(去节)	桂枝二两(去皮)	甘草二两(灸)	杏仁四十枚(去皮尖)	生姜三两(切)	大枣十枚(擘)	石膏如鸡子大(碎)

上七味,以水七升,先煮麻黄,减二升,去上沫,内诸药,煮取三升,去滓,温服一升,取微似汗.汗出多者,温粉粉之.一服汗者,停后服.若复服,汗多亡阳遂虚,恶风烦躁,不得眠也.

> 寒邪**闭表(大青龙汤的基本前提)**，致使阳气郁遏而不得宣泄，进而化热，郁热扰心，而生烦躁。**此为阳盛造成的烦躁**
>
> 但若为肾阳虚，虚弱的阳气和阴寒相争，争而不胜时，出现肢体躁动不宁（**阴盛则烦**）（**脉微弱很好的验证了阳虚的特点**），此外，汗出恶风为肾阳虚衰，表阳不顾，温煦失司的特征
>
> “阳盛则噪，阴盛则烦”，**大青龙汤仅能用于阳盛造成的心烦，不可用于阴盛造成的噪烦，否则大青龙汤会造成过汗亡阳**
>
> 服之则厥逆,筋惕肉瞤：表示阴盛情况下服大青龙汤的后果，手足厥逆，肌肉跳动。<font color="green">这里的肌肉跳动应该是汗出过多，筋脉失濡所致</font>

> **大青龙汤见汗出决不可再用，否则过汗亡阳**

伤寒脉浮缓,身不疼但重,乍有轻时,无少阴症者,大青龙汤发之.(39)

> 伤寒浮缓脉和身重提示湿郁肌表（**缓脉营虚卫有余，或风或湿或脾虚**），乍有轻时提示湿欲向里，故时轻时重。
>
> 无少阴证者：提示无少阴肾阳虚衰的烦躁（**需重点鉴别阳盛阴盛，否则过汗亡阳**），少阴寒化症也会出现不汗出而烦躁的症状（少阴病，欲吐不吐，心烦，但欲寐）

## 小青龙汤证

伤寒表不解，心下有水气，干呕发热而咳，或渴，或利，或噎，或小便不利、少腹满，或喘者，小青龙汤主之。（40）

麻黄（去节）	芍药	细辛	干姜	甘草（灸）	桂枝（去皮）	各三两	五味子半升	半夏半升（洗）

上八味，以水一斗，先煮麻黄，减二升，去上沫，内诸药，煮取三升，去滓，温服一升。若渴，去半夏，加栝楼根三两；若微利，去麻黄，加荛花，如一鸡子，熬令赤色；若噎，去麻黄，加附子一枚，炮；若小便不利，少腹满者，去麻黄，加茯苓四两；若喘，去麻黄，加杏仁半升，去皮尖。且荛花不治利，麻黄主喘，今此语反之，宜非仲景意。（臣亿等谨按，小青龙汤，大要治水。又按《本草》，荛花下十二水，若水去，利则止也。又按《千金》形肿者应内麻黄，乃杏仁者，以麻黄发其阳故也。以此证之，岂非仲景意也。）

> 本症是**风寒袭表,内有水饮**,内外邪气相结合而形成
>
> 伤寒表不解，心下有水气:伤寒兼内有停饮.

> 水饮内盛的症状:
>
> * 面部庞肿 - 水气
> * 面部发黑(发黄) - 水色
> * 面部色素增多 - 水斑

> 干呕发热而咳：干呕是因为水邪犯胃，胃气上逆。发热是因为外有表邪。咳或喘是小青龙汤的主症，这是因为外寒引动内饮，内外合邪，为水寒，水寒射肺。从而导致肺失宣降，最终导致咳喘
>
> 补充:
>
> 水寒射肺的症状：咳,吐大量的白色泡沫痰,落盂成水.兼有面部庞肿

> 或渴,或利,或噎,或小便不利,少腹满:水饮内停,津液不化,故渴;水寒邪气㓎渍肠道,故利;水寒邪气阻滞胸中气机,故噎;水邪下流膀胱,导致膀胱气化不利,故小便不利,少腹满

> 现代临床经常应用小青龙汤治疗慢性支气管炎,支气管哮喘属寒饮射肺或表寒内饮者.**但该方辛温燥烈之性较强,仅适用于水寒射肺的急性期使用,善后可用苓桂剂(如苓桂术甘汤,苓桂枣甘汤,茯苓甘草汤,苓桂甘草汤)**

伤寒新下有水气,咳而微喘,发热不渴.服汤已渴者,此寒去欲解也.小青龙汤主之.(41)

> 不渴:寒饮内盛,阳气不运.(<font color="green">水饮内挺渴和不渴都可能出现,这取决于内停的位置</font>)
>
> 服汤已渴:小青龙汤属阳热药,阳热药伤津耗液,津液一时不足,故口渴

> **若用在小青龙汤中兼见郁热扰心的心烦,也可在小青龙汤中加石膏,即小青龙汤中加石膏汤.**
>
> 方中,细辛中含有黄樟醚,为致癌成分,故不能常用小青龙汤.



]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
        <tag>太阳病</tag>
      </tags>
  </entry>
  <entry>
    <title>傅里叶级数与傅里叶变换推导</title>
    <url>/posts/fb91b52c.html/</url>
    <content><![CDATA[
本篇博客来自于`DR_CAN`的[傅里叶函数推导](https://www.bilibili.com/video/BV1Et411R78v)，加上自己的一些理解，感谢大神的分享。

# 三角函数系

有三角函数系：
$$
[sin(0x),cos(0x),sinx,cosx,sin2x,cos2x,...,sin(nx),cos(nx)] \tag	1
$$

> * 三角函数系，实质上是一组互不相关的基。在数学中这被称为基函数,即一个函数空间中最基本的组成元素.在信号中则被称为基波.
>
> * 任意一个周期函数可以理解成在一个函数空间中的元素，为了表征这个元素，就需要基本元素通过加权和来得到它，这个基本元素就是基，对于函数空间而言，这个基被称为基函数。用数学术语叫做线性张成。
>
> * 类似于欧几里得空间中的基向量，每一个基函数不能由其他基函数表征，否则这个基函数将没有存在的意义。这类似于线性空间中的线性无关。
>
> * 级数的其中一个应用就是基的加权，无穷级数就是无限维情况下基的加权。有的情况下有的基的权重太小，删除这些维，就得到这个值的近似值。

可以证明，三角函数的所有基必正交：
$$
\int_{-\pi}^{\pi}sin(nx)cos(mx)dx=0,其中(m\neq{n})	\tag 2
$$

$$
\int_{-\pi}^{\pi}sin(nx)sin(mx)dx=0,其中(m\neq{n})	\tag 3
$$

$$
\int_{-\pi}^{\pi}cos(nx)cos(mx)dx=0,其中(m\neq{n})	\tag 4
$$

当$m=n$ 时，有：
$$
\int_{-\pi}^{\pi}cos(mx)cos(mx)dx=\pi	\tag 5
$$

以上被称为三角函数的正交性

# 三角级数

对于一个以周期为$2\pi$的周期函数$f(x)$(即$f(x)=f(x+2\pi)$),可以展开为三角级数：
$$
f(x) =\sum_{n=0}^{\infty}a_n{cos(nx)}+\sum_{n=0}^{\infty}b_n{sin(nx)}	\tag 6
$$

------

下面计算$a_n$和$b_n$，第一步先求$a_0$

经过变换，有：


$$
f(x)=a_0cos(0x)+b_0sin(0x)+\sum_{n=1}^{\infty}a_ncos(nx)+b_nsin(nx)	\tag 7
$$

$$
f(x)=a_0+\sum_{n=1}^{\infty}a_ncos(nx)+b_nsin(nx)	\tag 8
$$

两边同时积分，有：
$$
\int_{-\pi}^{\pi}f(x)dx=\int_{-\pi}^{\pi}a_0dx+\int_{-\pi}^{\pi}\sum_{n=1}^{\infty}{a_ncos(nx)}dx+\int_{-\pi}^{\pi}\sum_{n=1}^{\infty}{b_nsin(nx)}dx	\tag 9
$$

$$
\int_{-\pi}^{\pi}f(x)dx=\int_{-\pi}^{\pi}a_0dx+\int_{-\pi}^{\pi}\sum_{n=1}^{\infty}{ a_n \times 1 \times cos(nx)}dx+\int_{-\pi}^{\pi}\sum_{n=1}^{\infty}{b_n \times 1 \times sin(nx)}dx	\tag {10}
$$

根据三角函数的正交性，有：
$$
\int_{-\pi}^{\pi}f(x)dx=\int_{-\pi}^{\pi}a_0dx	\tag {11}
$$
则：
$$
a_0=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)dx	\tag {12}
$$

------

下面求$a_n$,在（6）中两边同时乘以$cos(mx)$,再积分（$m\in Z$），有：
$$
\int_{-\pi}^{\pi}f(x)cos(mx)dx=\int_{\pi}^{\pi}a_0cos(mx)dx+\int_{\pi}^{\pi}\sum_{n=1}^{\infty}cos(nx) \times a_n \times cos(mx)dx+\int_{\pi}^{\pi}\sum_{n=1}^{\infty}sin(nx) \times b_n \times cos(mx)dx	\tag {13}
$$
根据三角级数的性质可得：
$$
\int_{-\pi}^{\pi}f(x)cos(mx)dx=\int_{\pi}^{\pi}a_m(cos^2(mx))dx=a_m\pi	\tag {14}
$$
则：
$$
a_n=\frac{1}{\pi}\int_{\pi}^{\pi}f(x)cos(nx)dx	\tag {15}
$$
同理可得：
$$
b_n=\frac{1}{\pi}\int_{\pi}^{\pi}f(x)sin(nx)dx	\tag {16}
$$

# 傅里叶级数

在很多情况下，周期函数的周期不为$2\pi$,对于周期不为$2\pi$的周期函数，将其压缩为$2\pi$，再对其进行三角级数的变换。设存在一个周期函数$f(t)$，其周期为$2L$,有：
$$
f(t)=f(t+2L)	\tag {17}
$$
将函数$f(t)$压缩为$(0,2\pi)$的函数为：
$$
x=\frac{t}{2L} \times 2\pi	\tag {18}
$$
可得：
$$
x=\frac{\pi}{L} \times t	\tag {19}
$$

$$
t = \frac{L}{\pi}x	\tag {20}
$$

对函数$f(t)$换元，有：
$$
f(t)=f(\frac{L}{\pi}x)=g(x)	\tag {21}
$$
此时，函数$g(x)$为以$2\pi$为周期的周期函数,有：
$$
g(x)=\frac{a_0}{2}+\sum_{n=1}^{\infty}[a_ncos(nx)+b_nsin(nx)]	\tag {22}
$$


当$x=-\pi$时，有$t=-L$;当$x=\pi$时，有$t=L$.且$x$在$(-\pi,\pi)$范围内单调递增。由公式（16）~(18),有：
$$
a_0=\frac{1}{\pi}\int_{-\pi}^{\pi}g(x)dx=\frac{1}{\pi}\int_{-L}^{L}f(t)d(\frac{\pi}{L}t)=\frac{1}{\pi}\frac{\pi}{L}\int_{-L}^{L}f(t)dt=\frac{1}{L}\int_{-L}^{L}f(t)dt	\tag {23}
$$

同理，有：
$$
a_n = \frac{1}{L}\int_{-L}^{L}f(t)cos(\frac{n\pi}{L}t)dt	\tag {24}
$$

$$
b_n = \frac{1}{L}\int_{-L}^{L}f(t)sin(\frac{n\pi}{L}t)dt	\tag {25}
$$

------

在工程中，$t$是从$0$开始，则$t$的取值范围为$(0,2L)$,令$T=2L$,并令$\omega=\frac{\pi}{L}$,（$\omega$被称为基频率，实质上就是周期的倒数）即在式（19）中$x=\omega \times t$,即$\omega$为$x$和$t$的比例。则式（22）可以替换为：
$$
f(t)=\frac{a_0}{2}+\sum_{n=1}^{\infty}[a_ncos(n \omega t) + b_nsin(n \omega t)]		\tag {26}
$$
则式（23）可以变为：
$$
a_0=\frac{1}{T/2}\int_{0}^{T}f(t)dt=\frac{2}{T}\int_{0}^{T}f(t)dt	\tag {27}
$$
式(24)可变为：
$$
a_n = \frac{1}{L}\int_{-L}^{L}f(t)cos(\frac{n\pi}{L}t)dt=\frac{2}{T}\int_{0}^{T}f(t)cos(n \omega t)dt	\tag {28}
$$
式（25）可以变为：
$$
b_n = \frac{1}{L}\int_{-L}^{L}f(t)sin(\frac{n\pi}{L}t)dt=\frac{2}{T}\int_{0}^{T}f(t)sin(n \omega t)dt	\tag {29}
$$

# 傅里叶级数的复数表达形式

欧拉公式：
$$
e^{i\theta}=cos\theta+isin\theta	\tag {30}
$$
则由欧拉公式(29)可得：
$$
cos\theta = \frac{1}{2}(e^{i\theta}+e^{-i\theta})	\tag {31}
$$

$$
sin\theta = \frac{1}{2}i(e^{i\theta}-e^{-i\theta})	\tag {32}
$$

则式（26）可由欧拉公式表示为：
$$
f(t)=\frac{a_0}{2}+\sum_{n=1}^{\infty}[a_n \cdot \frac{1}{2}(e^{in \omega t} + e^{-in \omega t}) -  \frac{1}{2}i \cdot b_n \cdot (e^{in \omega t} - e ^{-in \omega t})]	\tag {33}
$$
化简为：
$$
f(t)=\frac{a_0}{2}+\sum_{n=1}^{\infty}\frac{a_n - ib_n}{2}e^{in \omega t} + \sum_{n=1}^{\infty}\frac{a_n + ib_n}{2}e^{-in \omega t}	\tag {34}
$$

再化简为：
$$
f(t) = \sum_{n=0}^{0}\frac{a_0}{2} \cdot e^{i n \omega t}+\sum_{n=1}^{\infty}\frac{a_{n-1}b_n}{2} \cdot e^{in \omega t}+\sum_{n=-\infty}^{-1}\frac{a_{-n}+ib_{-n}}{2} \cdot e^{in \omega t}	\tag {35}
$$
**上式合并**，有：
$$
f(t)= \sum_{n=-\infty}^{\infty}C_n \cdot e^{in \omega t}	\tag {36}
$$
其中：

<!--
$$
C_n= \begin{cases}
	\frac{a0}{2}, & \text {n=0} \\
	\frac{a_n-ib_n}{2}, & \text {n=1,2,3,4,....}	\\
	\frac{a_{-n}+ib_{-n}}{2} & \text {n=-1,-2,-3,-4,....}
\end{cases}
$$
-->

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mi>C</mi>
    <mi>n</mi>
  </msub>
  <mo>=</mo>
  <mrow>
    <mo>{</mo>
    <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
      <mtr>
        <mtd>
          <mfrac>
            <mrow>
              <mi>a</mi>
              <mn>0</mn>
            </mrow>
            <mn>2</mn>
          </mfrac>
          <mo>,</mo>
        </mtd>
        <mtd>
          <mtext>n=0</mtext>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mfrac>
            <mrow>
              <msub>
                <mi>a</mi>
                <mi>n</mi>
              </msub>
              <mo>&#x2212;<!-- − --></mo>
              <mi>i</mi>
              <msub>
                <mi>b</mi>
                <mi>n</mi>
              </msub>
            </mrow>
            <mn>2</mn>
          </mfrac>
          <mo>,</mo>
        </mtd>
        <mtd>
          <mtext>n=1,2,3,4,....</mtext>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mfrac>
            <mrow>
              <msub>
                <mi>a</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo>+</mo>
              <mi>i</mi>
              <msub>
                <mi>b</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>n</mi>
                </mrow>
              </msub>
            </mrow>
            <mn>2</mn>
          </mfrac>
        </mtd>
        <mtd>
          <mtext>n=-1,-2,-3,-4,....</mtext>
        </mtd>
      </mtr>
    </mtable>
    <mo fence="true" stretchy="true" symmetric="true"></mo>
  </mrow>
</math>



------

下面计算$C_n$，当$n=0$时，由式（27），有：
$$
C_0=\frac{1}{2} \cdot \frac{2}{T} \int_{0}^{T}f(t)dt=\frac{1}{T} \int_{0}^{T}f(t)dt	\tag {37}
$$
当$n$为正整数时，将式（28）和式（29）代入，化简，得：
$$
C_n=\frac{1}{T}\int_{0}^{T}f(t) \cdot e^{-in \omega t}dt  \; \; \text {,n=(1,2,3,4,....)}	\tag {38}
$$
同理，可得：
$$
C_n=\frac{1}{T}\int_{0}^{T}f(t)e^{-in \omega t}dt \text{ n=-1,-2,-3,-4,...}	\tag {39}
$$
通过上式，可以发现，式（37）~（39）可以统一为一个式子,即：
$$
C_n=\frac{1}{T}\int_0^{T}f(t) \cdot e^{-in \omega t}dt	\tag {40}
$$

------

结合式（36）和式（40），我们得到**傅里叶级数最终的复数表达形式**：
$$
f(t)= \sum_{n=-\infty}^{\infty}C_n \cdot e^{in \omega t}	\tag {41}
$$
其中：
$$
C_n=\frac{1}{T}\int_0^{T}f(t) \cdot e^{-in \omega t}dt
$$

# 傅里叶变换

补充，**频谱图**：

> 傅里叶级数是将一个周期函数$f(t)$展开成多个三角级数相加，从图上看，就如下图所示：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210709114728.jpg)
>
> 上图实际上少了傅里叶变换结果的值，也就是$C_n$的值。我们现在从另外一个方向（频域）看上图，得到的图可能是如下：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210709115517.jpeg)
>
> 上图中，横轴是频域的频率（更确切的说是三角级数的基函数$e^{in \omega t}$本身，这里只是用频率$\omega$来指代基函数）,纵轴是线性张成的权重，即上式$C_n$,也是傅里叶变换的结果$F(t)$。**(并非$f(t)$).**.需要注意的是，$C_n$也可能是一个复数，此时，上图就是一个三维平面。

傅里叶级数成立的条件是$f(t)$必须是一个周期为$L$的周期函数，但在工程中很多时候，$f(t)$不一定是周期函数，自然而然就不能用傅里叶级数。**对于一个非周期函数，令$L \to \infty$,也就是说，令周期趋近于无穷大，此时$f(t)$可以看成一个周期为正无穷的周期函数，对于该周期函数，就可以用傅里叶级数分解**。从而演变成傅里叶变换。

对于以$T$为周期的周期函数$f_T(t)=f_T(t+T)$,由之前的推导，有：
$$
f_T(t)= \sum_{n=-\infty}^{\infty}C_n \cdot e^{in \omega_0 t}	\tag {42}
$$
其中
$$
C_n=\frac{1}{T}\int_{-\frac{T}{2}}^{\frac{T}{2}}f_T(t) \cdot e^{-in \omega_0 t}dt	\tag {43}
$$
上式为傅里叶级数的一般形式，

当$T\to \infty$时，此时的周期$T$可以忽略不计，有：
$$
\lim_{T \to \infty}f_T(t)=f(t)	\tag {44}
$$
$\Delta \omega$表示在频域上两个相邻基频率的差距，有：
$$
\Delta \omega=(n+1) \omega_0 - n \omega_0= \omega_0 = \frac{2 \pi}{T}	\tag {45}
$$
当$T \to \infty$时，有$\Delta \omega \to 0$，即此时基频率之间会无限接近。换句话说，**此时的傅里叶级数由离散转为连续**。

现在将式（42）代入式（41）中 ，有：
$$
f(t)= \sum_{n= - \infty}^{\infty} \left[ \frac{1}{T}\int_{-\frac{T}{2}}^{\frac{T}{2}}f(t) \cdot e^{-in \omega_0 t}dt \right] \cdot e^{in \omega_0 t} \tag {46}
$$
由于$\Delta \omega=\frac{2 \pi}{T}$,则有$T=\frac{2 \pi}{\Delta \omega}$,代入式（46）中，有：
$$
f(t)= \sum_{n= - \infty}^{\infty} \left[ \frac{\Delta \omega}{2 \pi}\int_{-\frac{T}{2}}^{\frac{T}{2}}f(t) \cdot e^{-in \omega_0 t}dt \right] \cdot e^{in \omega_0 t} \tag {47}
$$
当$T \to \infty$时，有

* $\sum_{n = -\infty}^{\infty} \Delta \omega=\int_{-\infty}^{\infty}d \omega$(即从离散形式变为连续形式)

则，
$$
f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(t) \cdot e^{-i \omega t}dt \cdot e^{i \omega t}d \omega	\tag {48}
$$
令$F(t)=\int_{-\infty}^{\infty}f(t)e^{-i \omega t}dt$,则上式等于：
$$
f(t)=\frac{1}{2 \pi}\int_{-\infty}^{\infty}F(t)e^{i \omega t}d \omega	\tag {49}
$$
其中
$$
F(t)=\int_{-\infty}^{\infty}f(t)e^{-i \omega t}dt	\tag {50}
$$
式（50）称为傅里叶变换（FT），也就是$f(t)$在频域的分量，式（49）称为傅里叶变换的逆变换，是一个从频域反向合成时域函数的过程。

至此，傅里叶变换推导完毕。]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>数字图像处理</tag>
        <tag>信号处理</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD模型</title>
    <url>/posts/719cc2e5.html/</url>
    <content><![CDATA[
# 概述

`SSD`全称`Single Shot MultiBox Detector`，是一个`One-Stage`的目标检测模型，以下是`SSD`和`YOLO`以及`Faster RCNN`的对比结果图。可以看到`SSD`比`YOLO`和`Faster RCNN`强很多（无论是速度上还是精度上）。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210506134247.jpg)

# 主要改进点

实质上,`SSD`在`YOLO`的基础上就仅进行了三点改进，一下分别阐述：

## 多尺度特征图检测
`YOLO`对于小目标的检测效果不好，所以在`SSD`中，用多尺度特征图来解决小目标的问题，下图是`SSD`模型和`YOLO`模型的对比，如图所示：
![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210512145819.png)

从上图可以看出：

* `SSD`的主干网络是`VGG16`,`SSD`的第一个`Feature Map`是`VGG`中的`Conv5_3`,也就是`VGG16`第5个阶段的第3个卷积层
* 对于`VGG16`后两层全连接层，`SSD`利用$3 \times 3$的卷积层和$1 \times 1$的卷积层实现
* `SSD`模型有6个`Feature Map`对应的输出，每一个输出加入$3 \times 3$ 的卷积层得到最终结果
* 在`Conv6`中的$3 \times 3$的卷积并不是普通的卷积，而是用的`Dilation Conv`（带孔卷积）
* 在`Conv5_3` 之后（也就是第一个输出`Feature Map`）接一个`L2 Normalization`,`L2 Normalization`不同于`Batch Normalization`，`Batch Normalization`是在[batch_size,width,height]三个维度上做归一化，而`L2 Normalization`是在**`Channel`**的维度上做归一化

### Dilation Conv

`Dilation Conv`的目的是扩大卷积的视野，如下图：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210512150349.png)

图中，(a)是普通的卷积层，(b)的扩张率为2，此时视野变成$7 \times 7$,（c）扩张率为4,此时视野变成$15 \times 15$

## Default Box

`Default Box`基本上等同于`Faster RCNN`中的`Anchor Box`，其数量上稍有不同，这里不再详述。

# Loss函数

由于`SSD`模型采用了`Default box`,所以，`loss`函数和`Faster RCNN`大同小异，但需要值得注意的是，在`SSD`中并没有`confidence`这一概念，在`SSD`中会在`class`部分多添加一类表示背景.所以,`SSD`的`loss`仅有两部分。一下是`SSD`模型的总体`loss`:
$$
L(x,c,l,g) = \frac{1}{N}(L_{conf}(x,c)+ \alpha L_{loc}(x,l,g)) \tag 1
$$

### 位置Loss

位置`loss`基本上完全同`Faster RCNN`,也是预测`Anchor Box`和`Ground Truth`的偏差，其内部所用的`loss`也是`smooth L1`

## 分类Loss

分类`loss`用`Cross Entropy`

# 参考

* [目标检测|SSD原理与实现](https://zhuanlan.zhihu.com/p/33544892)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>麻黄汤方</title>
    <url>/posts/13f147b0.html/</url>
    <content><![CDATA[
## 太阳表实证的一般适应证

太阳病，头痛，发热，身疼腰痛，骨节疼痛，恶风，无汗而喘者，麻黄汤主之。（35）

麻黄三两（去节） 桂枝三两（去皮） 甘草一两（灸） 杏仁七十个（去皮尖）

上四味，以水九升，先煮麻黄，减二升，去上沫，内诸药，煮取二升半，去滓，温服八合。覆取微似汗，不须啜粥，余如桂枝法将息。

太阳病，十日以去，脉浮细而嗜卧者，外已解也。设胸满肋痛者，与小柴胡汤。脉但浮者，与麻黄汤。（37）

脉浮者，病在表，可发汗，宜麻黄汤。（51）

脉浮而数者，可发汗，宜麻黄汤（52）

> 麻黄汤的适应证总结为麻黄八证，实质上是三组症状：
>
> 1. 发热，恶寒，恶风（或已发热，或未发热，必恶寒）
> 2. 头痛，身痛，腰疼，骨节疼痛
> 3. 无汗而喘

> 主病及病机：
>
> *  寒邪袭表，寒主收引，导致卫阳郁遏，所以见发热恶寒（太阳表实证多数情况下是卫阳郁遏导致的发热，卫阳抗邪于这种情况也有，但多数情况下的解释是第一种）。
> * 寒主痛，太阳经从头到脚，经过后背颈项，所以见头痛，腰疼，身痛。
> * **肺合皮毛，寒邪闭表导致肺的宣发肃降失调，从而导致肺窍不利，故无汗而喘**
>
> 补充：
>
> * 肺的宣发：将体内的浊气排除体外
> * 肺的肃降：将吸入的清气向下散布

>  服麻黄汤后，结果总结如下所示：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210514145646.png)
>
> 脉浮细而嗜卧：根据《黄帝内经》的解释，脉由粗变细是邪气退却的表现（**大则病进小则平**）（而由细变粗反而是恶病的征兆，所以临床上突然见脉大有力不一定是好现象）
>
> 熊满肋痛：提示邪传少阳，小柴胡汤主之
>
> 脉浮表病在表，麻黄为辛温燥烈之药，数脉不可用麻黄，所以见浮数脉，用桂枝汤

## 太阳伤寒衄解

太阳病，脉浮紧，无汗，发热，身疼痛，八九日不解，表证仍在，此当发其汗。服药已微除，其人发烦目暝，剧者必衄，衄乃解。所以然者，阳气重故也。麻黄汤主之。（46）

太阳病，脉浮紧，发热，身无汗，自衄者愈。（47）

伤寒脉浮紧，不发汗，因致衄者，麻黄汤主之。（55）

>  太阳和衄解有以下三种情况:
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210520102411.png)

> `太阳病，脉浮紧，无汗，发热，身疼痛`这是典型的太阳伤寒证,八九日未解，此时阳气郁遏已久,营中的邪气来不及从汗而解，于是从鼻衄而解。（因为肺合皮毛，而太阳主表，所以**太阳表症一般通过鼻衄而解**，其他经上的热不能通过鼻衄来解，比如阳明里热）
>
> **麻黄汤症一定要脉浮,若脉不浮,表示正气不能抗邪于表,不可发汗,汗出则更伤阴伤阳**
>
> **若衄血不止,高热不退,提示寒邪入里化热,内入营血,破血妄行,用犀角地黄汤**
>
> ****

> 补充：汗血同源
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210520103507.jpg)
>
> 汗血同源的实质是津液和血同源

## 麻黄汤其他适应症

太阳与阳明合病,喘而胸满者,不可下,宜麻黄汤.(36)

>   这里的阳明病表示**阳明经表证**(若是阳明里热里实,用桂枝汤(太阳病,外证未解,不可下也,下之为逆,欲解外者,宜桂枝汤)).

> <<医宗金鉴 * 伤寒心法要诀>>中对于阳明表证的论述:葛根浮长表阳明,缘缘面赤额头痛,发热恶寒身无汗,目痛鼻干卧不宁.
>
> * 葛根:葛根汤
> * 浮长:脉浮弦脉(弦脉端直以长)
>
> 阳明表证很像太阳表实证,发热,恶寒,无汗,但**由于阳明经脉走头面,所以阳明经脉会有额头通**

> 喘而胸满:表示太阳病重于阳明病(麻黄汤症中,有无汗而喘,为寒邪闭表,肺气宣发肃降失调,故无汗而喘).(若是阳明病重于太阳病,则下利或呕)

## 麻黄九禁

咽喉干燥者,不可发汗.(83)

> **咽通于胃,喉通于肺**,咽喉为肺胃之门户.且足少阴肾经也通于喉(肾经循喉咙,挟舌本).故喉干和肺胃肾都可能有关系.干燥提示阴液不足,发汗更伤津液.

淋家,不可发汗,发汗必便血.(84)

> 中医六淋多属下焦阴虚而热结膀胱所致,而此时用辛温发汗之药,会以热助热,更伤津液.若迫血妄行,则会出现便血.

> 另:中医淋病多由下焦亏虚,暗生内热所致.或与湿热两热互结于膀胱之腑(除寒淋外),也就是说,淋病多由阴虚内热于膀胱腑所致.
>
> 癃闭较淋病为复杂,共分以下几类:
>
> * 阳虚:气弱则不能宣通.治用宣阳堂
> * 阴虚:阴虚有热,则小便不利.治用济阴汤.
> * 阴阳两虚:脉数者阴分虚也，无力者阳分虚也.以上两方并用,轮流换服
> * 湿热壅滞:治用白茅根汤
> * 下焦受寒:治用温通汤
>
> 人之水饮，非阳气不能宣通。上焦阳虚者，水饮停于膈上。中焦阳虚者，水饮停于脾胃。下焦阳虚者，水饮停于膀胱.癃闭之症,还是多数由于阳虚导致水饮停于下焦所引起的.(至于湿热下注和寒邪引起的癃闭,较好辨别).若水饮停于上焦,用小青龙汤方.
>
> (参考张锡纯<<医学衷中参西录>>)

疮家,虽身疼痛,不可发汗,汗出则痉.(85)

> 久患疮家之人,既有毒热内盛,又因脓血流失而气血两伤.麻黄为辛温发表之剂,用一则更助毒热,二则汗出则阴阳俱伤,气血更虚.

衄家,不可发汗,汗出必额上陷脉紧急,直视不能眴,不得眠.(86)

>  衄家，多阴血亏虚。误用麻黄发汗，营阴被伤，可致阴血更加亏虚，筋脉失去濡养，故太阳穴处筋脉弦急（此为脱水之征），目睛转动不灵活，不能闭目静息。

亡血家，不可发汗，发汗则寒栗而振。（87）

> 有慢性失血性疾病的人，不可发汗，发汗则寒战

> 亡血家则气血两虚，汗血同源，出汗阴阳两伤，必至气血更虚

汗家，重发汗，必恍惚心乱，小便已阴痛，与禹余粮丸。（88）

> 恍惚心乱：汗为心之液，汗出过多，则心失所养，心神无主，神气浮越，故恍惚而心乱。
>
> 小便已阴痛：重发汗，则阴津受伤，阴中涩滞，故小便后尿道有疼痛
>
> 注：禹余粮丸方已佚

病人有寒，复发汗，胃中冷，必吐蛔。（89）

脉浮数者，法当汗出而愈，若下之，身重心悸者，不可发汗，当自汗出乃解。所以然者，尺中脉微，此里虚，须表里实，津液自和，便自汗出愈。（49）

> 脉浮数,理当用麻黄汤发汗,若用下法,则里虚,阳虚则身重,营血虚则见心悸.尺脉微,表示阳虚.(**在伤寒论中,尺脉微表阳虚,尺脉出现迟脉,表营血不足**).需待表里正气充实,气血充沛,自汗出则愈.

脉浮紧者,法当身疼痛,宜以汗解之,假令尺中迟者,不可发汗.何以知然?以荣气不足,血少故也.(50)

> 脉浮紧,当以麻黄汤发汗,尺脉迟滞,在伤寒论中主营血不足,本证当属里虚加外感.汗血同源,发汗更伤营血.

### 麻黄九禁总结

凡阴,阳,气,血,表,里诸不足,或湿热,毒热,虚热内盛者,皆当禁用或慎用**辛温发汗**

</医学衷中参西录></医宗金鉴>]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
        <tag>太阳病</tag>
      </tags>
  </entry>
  <entry>
    <title>桂枝汤方及其变方</title>
    <url>/posts/dd3c2345.html/</url>
    <content><![CDATA[
提示:

* <font color="blue">蓝色</font>表示未理解
* <font color="red">红色</font>或**加粗**表示重要部分
* <font color="green">绿色</font>表示我自己的理解

## 桂枝汤方

太阳中风,阳浮而阴弱,阳浮者,热自发,阴弱者,汗自出,啬啬恶寒,淅淅恶风,翕翕发热,鼻鸣干呕者,桂枝汤主之.

> 太阳中风,阳浮而阴弱:太阳中风症,卫阳抗邪于外所以阳浮.汗出则伤营阴(之所以汗出原因有二:1. 风邪轻扬开泄,故汗出2. 卫阳的特点是肥腠理,司开合,卫外而为固.卫阳被伤,则司开合的功能不足,所以导致营阴外越).
>
> 阳浮者,热自发:风邪袭表,卫阳抗邪于外,所以见病理性的发热
>
> 阴弱者,汗自出:汗出导致营阴被伤.这里应该反过来理解
>
> 啬啬恶寒,淅淅恶风,翕翕发热:太阳伤寒的特点是发热,汗出,恶风,脉缓.太阳病的基本特征是脉浮,头项强痛,而恶寒.所以这里讲的是太阳中风的症状.
>
> 鼻鸣干呕者:**这里讲的是太阳中风的兼症**.风邪袭表,而肺合皮毛,故见鼻鸣.正气抗邪于外而不能顾护于里,故见干呕(这里的病机同伤寒的呕逆)

桂枝三两(去皮) ,芍药三两,甘草二两(灸),生姜三两(切),大枣二十枚(擘)(12)

上五味,（口父）咀三味.以水七升,微火煮取三升,去滓,适温寒,服一升.服已须臾,啜热稀粥一升余,以助药力.温覆令一时许,遍身漐漐,微似有汗者宜佳,不可令如水琉璃,病必不除.若一服汗出病差,停后服,不必尽剂.若不汗更服依前法.又不汗,后服小促其间,半日许,令三服尽.若病重者,一日一夜服,周时观之.服一剂尽,病症犹在者,更作服;若汗不出,乃服至二三剂.禁生冷,粘滑,肉面,五辛,酒酪,臭恶等物.

> 太阳中风的风邪袭表,卫强营弱,营卫失和.故用桂枝汤的治则为**解肌祛风,调和营卫**.<font color="green">(太阳中风中的卫强并非真的卫强,而是卫气抗邪于表出现病理性的亢奋.中风症应该是营卫皆伤,故在桂枝方中既有辛甘化阳的药也有酸甘化阴的药,化阳药助卫阳以祛除风邪,化阴药以补营阴)</font>
>
> <font color="green"> 在桂枝方中,养营阴的力度大于发汗的力度(也就是助卫阳的力度),或许是因为中风症伤阴大于伤阳,故养正大于发汗</font>
>
> <font color="red">桂枝汤:养正力大,发汗力弱,驱邪而不伤正,养营血而不留邪.在外解肌和营卫,在内化气调阴阳</font>

> 桂枝汤中既有辛甘化阳的药,又有酸甘化阴的药,所以桂枝汤有调和阴阳之功.
>
> 辛甘化阳:桂枝,干姜 => 助卫阳,祛风散寒
>
> 酸甘化阴:芍药,大枣=>养营阴,敛汗液
>
> 甘草起调和作用

> 服已须臾,啜热稀粥一升余,以助药力: 药后服粥有两重原因:1. 太阳中风营阴被伤,服粥以补营阴 2. 桂枝汤方养正力大,发汗力弱,服热粥助胃阳,以鼓舞卫阳,使卫阳能够抗邪于表,加强发汗力量(卫出下焦,卫出中焦,卫出上焦,这里实际上是让卫阳补充于中焦)
>
> 温覆令一时许,遍身漐漐,微似有汗者宜佳,不可令如水琉璃,病必不除:加盖衣被保温发汗,遍身微似有汗为佳,切忌大汗淋漓.因为汗多伤正,正气被伤,邪反不去,病必不除.
>
> 停后服,不必尽剂:若见汗出病愈,就当停服.因为汗出过多反而伤正.
>
> 若不汗更服依前法.又不汗,后服小促其间,半日许,令三服尽:**太阳病的关键在于汗法**,如一服无汗,继而后服,半日内将三服药服完

## 桂枝汤适应症

### 太阳病见汗出

太阳病,头痛,发热,汗出,恶风,桂枝汤主之(13)

> **汗出则用桂枝汤**

###  太阳病兼轻度里虚者

太阳病,外证未解,脉浮弱者,当以汗解,宜桂枝汤.(42)

> 外证未解,脉浮弱:**表示正气还有能力抗邪于表**,但脉已见弱象,说明里气已经不足.
>
> 此时,应该用桂枝汤,而不能用麻黄汤.因为麻黄汤发汗力强,汗出过多伤正,所以宜桂枝汤.

### 汗下后太阳表证仍在者

太阳病,下之后,其气上冲者,可与桂枝汤,方用前发.若不上冲着,不得与之.(15)

> 太阳病,误用下法,正气尚能抗邪于表(见浮脉),可用桂枝汤.若未见浮脉,**禁用桂枝汤**

太阳病,先发汗不解,而复下之,脉浮者不愈.浮为在外,而反下之,故令不愈.今脉浮,故在外,当须解外则愈,宜桂枝汤(45)

> 同上,太阳病误用下法,再用桂枝汤的关键是看是否有浮脉.

伤寒发汗已解,半日许复烦,脉浮数者,可更发汗,宜桂枝汤.

> 半日许复烦是因为余邪未尽,出现**脉浮数**,可用桂枝汤.
>
> 注:**这里是在太阳伤寒用麻黄汤已经发汗的情况下**

> **汗法或下法,若见浮脉,均可用桂枝汤.**

### 太阳病兼里实欲先解表者

太阳病,外证未解,不可下也,下之为逆,欲解外者,宜桂枝汤(44)

> **病在表者,理当汗解;病属里实,法当攻下.**表证兼里实,因先遵循**先表后里**的原则.宜桂枝汤.
>
> 不能用麻黄汤是因为汗法伤津,更助里热.

病常自汗出者,此为荣气和,荣气和者,外不谐,以卫气不共荣气谐和故尔.以荣行脉中,卫行脉外.复发其汗,荣卫和则愈,宜桂枝汤.(53)

病人脏无他病,时发热自汗出而不愈者,此卫气不和也.先其时发汗则愈,宜桂枝汤.(54)

> 此为荣气和,荣气和者,外不谐,以卫气不共荣气谐和故尔:荣气即营气,这里的"外"指卫气.脏无他病而自汗出为营卫不和所致,这里桂枝汤有调和营卫之功.
>
> 先其时发汗:**需在病症发作之前或发作间隙用药**

### 病重药轻,治用针药并用

太阳病,初服桂枝汤,反烦不解者,先刺凤池,风府,却与桂枝汤则愈.(24)

> 反烦不解者是因为药力不足,不足以祛除病邪,反而激惹邪气,从而导致烦热不解.

### 总结

桂枝汤适应症如下:

* 太阳病见汗出
* 太阳病见浮弱脉(无论是否误下)
* 太阳病余邪未尽(若病重,刺风府,大椎,凤池)
  * **太阳伤寒用麻黄汤已经发汗**
  * 太阳中风
* 表证兼里实
* 营卫不和

## 桂枝汤禁忌证

### 太阳伤寒不可用桂枝汤

桂枝本为解肌,若其人脉浮紧,发热汗不出者,不可与之也.常须识此,勿令误也.(16下)

> 脉浮紧和不汗出表示太阳伤寒,太阳伤寒理应用纯辛温麻黄汤解表.由于**芍药有敛汗的作用**,导致寒邪闭表更加严重.

> <font color="green">我的理解这里用桂枝汤和麻黄的关键在于发汗与否,若用桂枝汤能够发汗(可另加上一些外界刺激,比如运动,捂被子),就不会出太大问题.</font>
>
> <font color="green">此外,如张仲景所说,对于虚弱或者身体素弱的病人,最好用桂枝汤(在能够发汗的情况下)</font>

### 湿热内盛不可用桂枝汤

若酒客病,不可与桂枝汤,得知则呕,以酒客病不喜甘故也.(17)

> 嗜酒之人,多湿热内盛,阻遏营卫气血,而见**烦热,多汗,周身酸楚,头痛**类似中风症的症状(**无恶寒**).桂枝汤本为辛甘之剂,辛甘助热,酸甘助湿,这就导致湿热壅滞更加严重,导致胃气上逆.凡**湿热内盛不可用桂枝汤**
>
> 对于**酒客病有人建议去芍药和大枣,另加醒酒药(例如葛花,枳椇子)**

### 毒热壅盛禁用桂枝汤

凡服桂枝汤吐者,其后必吐脓血也.(19)

> 病人能吐脓血,必是原有内痈.原有内痈,其人素体热毒壅盛,因此可见发热,多汗,身痛等类似太阳中风的症状.若误用桂枝汤,则辛甘助热,发汗伤津,必然导致病情恶化.

### 总结

桂枝汤禁忌症如下:

* 太阳伤寒,寒邪闭表
* 有湿热或毒热者(**桂枝下咽,阳盛则毙,承气入胃,阴盛以亡**)

## 桂枝汤变方

### 桂枝加葛根汤

太阳病,项背强几几,反汗出恶风者,桂枝加葛根汤主之.(14)

葛根四两 桂枝二两(去皮) 芍药二两 生姜三两(切) 甘草二两(灸) 大枣十二枚(擘)

右七味（口父）咀，以水一斗，先煮麻黄葛根，减二升，去沫，内诸药，煮取三升，去滓，温服一升，复取微似汗，不须啜粥，余如桂枝法将息及禁忌.(臣亿等谨按,仲景本论,太阳中风自汗出用桂枝,伤寒无汗用麻黄,今证云汗出恶风,而方中有麻黄,恐非本意也.第三卷有葛根汤证,云无汗恶风,正与此方同,是合用麻黄也.此云桂枝加葛根汤,恐是桂枝中但加葛根耳)

> 项强连及背部,加葛根.
>
> 加葛根的治法为:解肌祛风,生津舒津
>
> 加葛根原因有三:1. 升阳发表,助桂枝汤发表解肌. 2. 疏通经脉 3.**升津液,起阴气**,鼓舞阳明津液的布达,滋津润燥,缓解经脉的痉挛.<font color="blue">(为何是阳明经)</font>

> **衍生方:**
>
> 灸甘草 6-10克,桂枝10克,白芍30克,威灵仙10克,秦艽10克,鸡血藤30克,葛根20-30克
>
> **治颈肩肌肉痉挛**

### 桂枝加厚朴杏子汤

太阳病，下之微喘者，表未解故也，桂枝加厚朴杏子汤主之。（43）

桂枝三两（去皮） 甘草二两（灸） 生姜三两（切） 芍药三两 大枣十二枚（擘） 厚朴二两（灸，去皮） 杏仁五十枚（去皮尖）

上七味，以水七升，微火煮取三升，去滓，温服一升，覆取微似汗。

喘家作桂枝汤，加厚朴，杏子佳。（18）

> 太阳表证,误下伤里气,表邪乘虚内陷而成表证兼喘.用桂枝加厚朴杏子汤.

> 太阳病误下总结:
>
> 1. 太阳病误下后,其气上冲者,桂枝汤
> 2. 太阳病误下后,微喘者,桂枝加厚朴杏子汤

### 桂枝加附子汤

太阳病，发汗，遂漏不止，其人恶风，小便难，四肢微急，难以屈伸者，桂枝加附子汤主之．(20)

桂枝三两(去皮) 　芍药三两　甘草三两（灸）生姜三两（切）　大枣十二枚（擘）　附子一枚（炮，去皮，破八片）

上六味，以水七升，煮取三升，去滓，温服一升．本云，桂枝汤，今加附子，将息如前法．

> 太阳中风出汗太多导致阴阳两伤**（汗生于阴而出于阳）**。
>
> 小便难：1.是因为阳气被伤，膀胱气化无力（膀胱者，州都之官，气化则能出）2是因为汗出伤阴，津液亏少，化源不足。
>
> 四肢微急：四肢微急也有两方面原因：1.阳虚导致四肢经脉失温 2. 阴液被伤，四肢筋脉失去阴液濡养。

> 本证阴阳两虚，张仲景采用固阳以摄阴的方式。（津伤而阳不亡者，其津自能再生，阳亡而津不伤者，其津亦无后继）

### 桂枝去芍药汤证

太阳病，下之后，脉促胸满者，桂枝去芍药汤主之。（21）

桂枝三两（去皮） 甘草二两（灸）	生姜三两（切） 大枣十二枚（擘）

上四味，以水七升，煮取三升，去滓，温服一升。本云，桂枝汤今去芍药。将息如前法。

> 太阳病，误下后，胸闷者，这是因为心胸阳气不振，邪陷胸中，当是**脉搏急促无力**，这是心中阳气不足，但尚能与邪抗争而出现的虚性代偿现象。
>
> 在桂枝汤中，芍药有敛汗的作用，此时在表已经没有自汗出的症状。此外，芍药有收敛之性，用芍药有碍于宣通胸中阳气。**张仲景凡见胸满者不用芍药**

### 桂枝去芍药加附子汤证

若微寒，桂枝去芍药加附子汤主之。（22）

桂枝三两（去皮） 甘草二两（灸） 生姜三两（切） 大枣十二枚（擘） 附子一枚（炮，去皮，破八片）

上五味，以水七升，煮取三升，去滓，温服一升。本云，桂枝汤今去芍药加附子。将息如前法。

> 若见微寒，应兼补肾阳，加附子。

### 桂枝新加汤证

发汗后，身疼痛，脉沉迟者，桂枝加芍药生姜各一两，人参三两，新加汤主之。（62）

桂枝三两（去皮） 芍药四两  甘草二两（灸） 人参三两  大枣十二枚（擘）  生姜四两

上六位，以水一斗二升，煮取三升，去滓，温服一升。本云，桂枝汤，今加芍药、生姜、人参。

> 发汗后，汗出过多，营血被伤，肌肤失养，而出现身疼痛。
>
> **这里的沉迟脉主营血不足，并非里阳虚**

## 总结

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210506112854.png)]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
        <tag>太阳病</tag>
      </tags>
  </entry>
  <entry>
    <title>HMM总结</title>
    <url>/posts/6d15840a.html/</url>
    <content><![CDATA[


![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210324172511.jpg)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>U-Net总结</title>
    <url>/posts/37a338a6.html/</url>
    <content><![CDATA[
## Question

* [U-Net的大体结构如何](#网络架构)
* [U-Net用哪几层从下采样向上采样复制](#网络架构)
* [U-Net的整体Loss是怎样的](#整体loss)
* [U-Net的权重如何计算](#权重参数)

## 概述

> `U-Net` 网络是一个图像分割的网络，主要用于医学图像的分割。

## 网络架构

`U-Net`的结构非常简单，分为下采样和上采样两部分，即先对图像进项下采样，再对结果进行上采样。由于下采样和上采样是对称的，类似于一个U型网络，所以称为`U-Net`。其网络模型如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210322111509.png)

* 可以注意到，每进行一次下采样，其通道数$\times 2$,每一次上采样，其通道数$\div2$.
* **`U-Net`的会将下采样的最后两层复制到上采样的最开始两层**
* 所有的`Conv`层都是采用`unpad`模式（即不填充模式）
* 可以注意到，`U-Net`的输出2通道，是因为文中用了`softmax`作为分类的结果，由于仅有前景和背景两类，所以`softmax`的结果数为2，故通道数为2。

## Loss函数

### 整体loss

`U-Net`的`Loss Function`如下所示：
$$
E=\sum_{x\in{\Omega}}w(x)log(p_{\iota(x)}(x))	\tag 1
$$
 其中，$\Omega$表示像素点的集合，即若一张图为$w\times h\times c$,则$\Omega$表示$w \times h$.$x$则表示每一个像素点（不包含通道）

$p_{\iota(x)}$表示在$x$位置上的第$\iota(x)$个通道。由于在`U-Net`中每一个像素点对应一个`softmax`输出，所以在模型的输出中，一个通道可以看成是`softmax`的一个结果，`softmax`有$n$个结果就有$n$个通道。所以$\iota(x)$表示$x$位置上对应`softmax`的第$\iota(x)$个结果。

$w(x)$表示权重，这使得`U-Net`更加注重边缘信息，后面会详细阐述。

从上面公式可以看出，`U-Net`的`loss`函数并不是一个标准的`Cross-Entropy`，而是用$w(x)$代替$p_{\iota(x)}(x)$,其目的是让模型更加注重边缘信息。原文如下：

> force the network to learn the small separation borders that we introduce between touching cells.

### 权重参数

权重公式如下：
$$
w(x)=w_c(x)+ w_0 \times exp(-\frac{(d_1(x)+d_2(x))^2}{2\sigma^2})	\tag 2
$$
其中，$w_c(x)$为平衡参数。$w_0$和$\sigma$为超参数。$d_1(x)$表示该像素点离最近边缘的距离，$d_2(x)$表示对次最近边缘的距离。从上式可以看出，如果一个像素点离边缘的越远，$d_1(x)$和$d_2(x)$越大，其获得的权重越低。反之，其权重则越高。文中取超参数$w_0=10$，$\sigma \approx 5$.

以下是文中权重的一个结果，c图表示边缘，d图表示计算出的边缘权重，可以看出边缘的权重明显高于中间区域。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210322141140.png)

## 参考

> [U-Net论文](https://arxiv.org/pdf/1505.04597.pdf)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>图像分割</tag>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title>双边滤波</title>
    <url>/posts/7be0ab31.html/</url>
    <content><![CDATA[
## Question

* [双边滤波的作用](#概述)
* [双边滤波的原理](#原理)

## 概述

双边滤波是一个非线性滤波器，**他能做到既平滑降噪，又保持边缘信息**，在实际运用中很有用

## 原理

考虑高斯滤波，高斯滤波是利用空间域来达到平滑的效果。设在一个以$q$ 为中心的窗口中，某一点$p$的高斯滤波权重为：
$$
G_{\sigma}(||p - q||) = \frac{1}{2\pi\sigma^2}e^{-\frac{||p-q||^2}{2\sigma^2}}
$$
则当前像素点$q$的滤波结果可以表示为：
$$
GF(I)_{q}=\sum_{p \in S}{G_{\sigma}{(||p - q||)}I_{q}}
$$
其中，$S$表示以$q$为中心的窗口的所有像素点。

而双边滤波不仅考虑空间的位置信息，还考虑颜色上的距离：
$$
BF[I]_q=\frac{1}{W_p}\sum_{p\in{S}}G_{\sigma_s}(||p - q||)G_{\sigma_r}(|I_p-I_q|)I_q
$$
其中，$\frac{1}{W_p}$为归一化因子，$G_{\sigma_s}(||p-q||)$表示空间位置上的差距，即普通的高斯滤波核。$G_{\sigma_r}$表示颜色上的差距，其也是用高斯核，但其输入已经改为两个像素值。

下面考虑两种情况：

1. 该像素值位于一个区域的中间时
2. 该像素值位于一个区域的边缘时

当一个像素值位于区域中间时，由于该区域的颜色颜色相差不大，所以，$|I_p - I_q|$较小，这导致$G_{\sigma_r}$较大，甚至接近1，此时核函数就相当于高斯核，起到区域内平滑的效果。

当一个像素点位于区域的边缘时，由于该区域的颜色相差较大，此时，$|I_p-I_q|$较大，这导致$G_{\sigma_{r}}$反而较小。这导致了$q$点的权重较小，通过加权就会产生很明显的“断崖”效果。如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210319102529.png)



## 参考

* [Bilateral Filters（双边滤波算法）原理及实现](https://blog.csdn.net/u013066730/article/details/87859184)





]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>太阳病辩证纲要</title>
    <url>/posts/dd3c5678.html/</url>
    <content><![CDATA[
# 概说

太阳经包括`足太阳膀胱经`以及`手太阳小肠经`,在`<<伤寒论>>`中,仅涉及到`足太阳膀胱经`的病变,而没有`手太阳小肠经`的病变,所以太阳病是以`足太阳膀胱`为主线论述.

**提示:**

* <font color="blue">蓝色</font>表示未理解
* <font color="red">红色</font>表示重要部分
* <font color="green">绿色</font>表示我自己的理解

## 问题

* [太阳病的病位涉及到哪些](#太阳病的病位)
* [太阳经和哪些脏腑(经络)相连](#足太阳膀胱经)
* [太阳经阳气的来源](#足太阳膀胱经)
* [膀胱在什么作用下化生阳气](#足太阳膀胱腑)
* [膀胱的阳气通过什么途径向体表输布](#足太阳膀胱腑)
* [膀胱腑有什么生理特性](#足太阳膀胱腑)
* [太阳经阳气的生理特性](＃太阳阳气的生理特征)
* [太阳主一身之表和卫气有什么区别和联系](#太阳阳气主一身之表)
* [卫气的特点是什么](#太阳阳气主一身之表)
* [外寒伤表是否伤及营气,依据是什么](#统营卫)
* [风寒和风温分别始于什么经](#风寒和温热邪气的区别)

## 太阳病的病位

太阳病涉及到`足太阳膀胱经`以及`足太阳膀胱腑`.由于太阳主表,而肺主皮毛,所以外寒邪气伤阳则会伤`手太阴肺`,所以太阳病病位主要涉及到三个部位:

* 足太阳膀胱经
* 足太阳膀胱腑
* 手太阴肺

## 太阳病成因

* 外感风寒

  太阳主一身之表阳,风寒阴邪侵犯人体首先伤表阳,所以先伤太阳经.

* 少阴病外传

  足太阳膀胱经和足少阴肾经互为表里,当足少阴肾经阳气恢复,阴病出阳,脏邪还腑,邪气外出**膀胱腑**

## 太阳的生理特征

### 足太阳膀胱经

* 足太阳膀胱经上连风府和督脉相连,下络腰肾和肾相通.由于督脉主一身之阳气,且肾藏元阴元阳,故足太阳膀胱经可借助督脉的阳气和肾中的元阳主一身之表阳.

  由于人体表面广,所需阳气量大(这样才能防御外邪),所以太阳经所需阳气是三阳中最大的,所以,太阳又称为"巨阳"

* 由于足太阳膀胱经散布于心,所以,太阳病同样可见有关`心`的症状(心主神明)

### 足太阳膀胱腑

足太阳膀胱的生理特性主要在司气化

* 化生阳气.

  在肾阳的温煦作用下,化生阳气,并通过`膀胱经`和`三焦`向体表输布.**(三焦膀胱者,腠理毫毛其应也)**

* 参与输液代谢

  * 排除废水

    **膀胱者,州都之官,气化则能出**

  * 化生津液

    即肾的蒸腾作用

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/%E8%B6%B3%E5%A4%AA%E9%98%B3%E8%86%80%E8%83%B1%E8%85%91.png" style="zoom:50%;">

### 太阳阳气

**太阳主表为统营卫**

#### 太阳阳气主一身之表

> 肥腠理，司开合，卫外而为固

#### 统营卫

营行脉中,卫行脉外,营为卫之守,卫为営之使.营卫相将而不相离.由于营卫相关性甚大,所以外邪伤表阳,自然而然也会伤及营气.

### 太阳阳气生成和输布图

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/%E5%A4%AA%E9%98%B3%E9%98%B3%E6%B0%94%E7%9A%84%E5%8C%96%E7%94%9F%E5%92%8C%E8%BF%90%E9%80%81.png" style="zoom: 50%;">

## 杂项

### 风寒和温热邪气的区别

* 太阳经主一身之表阳，外感风寒属阴邪而易伤表阳，故风寒外袭始于足太阳
* 体表的阴液靠肺来宣发，温热邪气为阳邪而易伤阴，故温热邪气外袭始于手太阴(温邪上受,首先犯肺,逆传心包)

### 对太阳经之表阳的一些粗浅理解

* 老年人冬天爱蜷卧于床上,因为阳气不足(阳不足则畏寒肢冷).更进一步说,是肾阳不足(肾为元阴元阳之本).
* 依上条,太阳经的阳气的来源之一是肾中的元阳,若像以上爱蜷卧于床,则表示肾阳不足,导致太阳经阳气不足.如果此人阳气实在素弱,则会导致寒邪直中少阴,导致少阴寒化症,此时病情就相当严重.所以,这种老年人需要时不时补肾阳,至于效果如何,还要取决于中焦的脾胃如何.(据我所知,艾灸对于补阳补气有较好的效果,补肾阳通常灸太溪,复溜,关元和足三里)
* 从反面看,年轻人身体好则不恶寒,是因为阳气足,能够抵御寒邪.

# 太阳病的分类提纲

## 问题

* [浮脉的特点](#太阳病提纲)
* [寒邪的特点](#太阳病提纲)
* [风邪的特点](#太阳中风症)
* [太阳中风证的特点](#太阳中风症)
* [太阳中风症逐条解释](#太阳中风症)
* [太阳伤寒症逐条解释](#太阳伤寒证)
* [太阳主症有哪些区别](#太阳病主症区别)
* [温病和风温](#温病和风温)
* [为何温病会身重、多眠睡](#温病和风温)

## 太阳病提纲

1. 太阳之为病，脉浮，头项强痛而恶寒(1)

> * 脉浮：外邪袭表，正气抗邪而浮盛于外，此时气血必浮盛于表。（浮脉主表）
>
>   浮脉的特点：**轻取即得，举之有余，按之少力，如水漂木**
>
> * 头项强痛：足太阳经通过颈项上连头部。寒为阴邪，易伤阳气，当寒邪伤表，先伤太阳经。寒主收引，所以太阳会出现经痉挛拘急，所以见颈项强痛。
>
>   寒邪的特点：**寒为阴邪，易伤阳气。寒主凝滞，寒主收引，寒主痛**（但痛不一定为寒邪所致，痛则不通）。
>
> * 恶寒：卫阳被伤，温煦失司（卫气的特征为：肥腠理，司开合，卫外而为固），所以恶寒
>
> **以上三个症状同时存在，才可以诊断为太阳表症**

## 太阳病分类提纲

### 太阳中风症

2. 太阳病，发热，汗出，恶风，脉缓者，名为中风。(2)

> 发热：风为阳邪，风邪袭表，风阳伤卫阳，两阳相争，卫阳浮盛于表，见病理性的发热，所以见发热
>
> 汗出：汗出有两方面原因：1. 由于卫气的特点是“费腠理，司开合，卫外而为固”，卫阳被伤，卫外失固，故汗出。2. 风邪的特点是**风为阳邪，轻扬开泄，善动不居，易袭阳位**，所以风主疏泄，所以汗出。
>
> 恶风：被风邪所伤，所以恶风
>
> 脉缓：在太阳的前提下脉浮缓。由于汗出营阴被伤，脉道空虚，所以见脉缓。（浮缓脉主风邪）
>
> 太阳中风症的特点为：**风邪袭表，卫强营弱，营卫失和**（我的理解这里的“卫强营弱”并非卫阳强于营阴，这里的“强”应该是病理性的亢奋，否则在`桂枝汤`中不会用辛甘化阳的药）

### 太阳伤寒证

3. 太阳病，或已发热，或未发热，必恶寒，体痛，呕逆，脉阴阳俱紧者，名曰伤寒。(3)

> 发热或未发热：寒邪袭表卫阳抗邪于表，故见发热。未发热是由于卫阳郁遏，或由于体质素弱，卫阳没有及时达表，所以暂时未见发热。**但最终都会见发热的**
>
> 必恶寒：寒邪袭表，温煦失司，故恶寒。
>
> 体痛：**寒主凝滞，寒主收引，寒主痛**，故见身痛。且由于寒主收引的特性，伤寒也表现为**无汗**
>
> 呕逆：这是由于**卫阳抗邪于表而不能顾护于里**，同时也可见**食欲不振，下利，不大便等**
>
> 脉阴阳俱紧：脉寸关尺三部俱浮紧。由于寒主收引，故见紧脉
>
> 太阳伤寒的特点为：**寒邪袭表，卫闭营郁**

> 卫阳抗邪于表而不能顾护于里的更深一层理解:
>
> 感冒后,不能吃过多的食物或者难以消化的食物.因为此时卫气想抗邪于表,而消化过多的食物也需要消耗的胃阳,使得体内的阳气内外不兼顾,会拖长感冒的病程.
>
> 从另一方面讲,吃过饱会消耗过多的胃阳,使得`正气顾护于里而不能抗邪于表`,更易得感冒.

### 温病和风温

4. 太阳病，发热而渴，不恶寒者，为温病。若发汗已，身灼热者，名为风温，风温为病，脉阴阳俱浮，自汗出，身重，多眠睡，鼻息必鼾，语言难出。若被下者，小便不利，直视失溲，若被火者，微发黄色，剧则如惊痫，时瘛疭。若火熏之，一逆尚引日，再逆促命期。(6)

> 该条讲火（热）邪侵犯人体的表现。火邪的特性为：**火为阳邪，其性上炎，耗血伤津，生风动血，易扰心神，易致疮痈**。
>
> 由于火为阳邪，易伤阴液，体表的阴液靠肺来宣发，所以温热邪气伤人始于手太阴肺经（<font color="red">温邪上受，首先犯肺,逆传心包</font>）。由于始于手太阴肺经，严格的说，该条不属于太阳病。

> 发热而渴：由于温病为火邪，火邪耗血伤津 ，故发热而渴。
>
> 不恶寒：温邪主要伤体表的津液而不会伤体表的阳气，所以不恶寒。
>
> 所以**发热而渴，不恶寒是温病的基本特征**
>
> 脉阴阳俱浮：**这里的浮脉并非主表，而主邪热**。由于邪热鼓动气血，气血涌盛，血脉贲张，所以寸关尺三部均见浮数之象。但和主表的浮脉不同的是：主表的浮脉是`轻取即得，重按少力`，而主热的浮脉是`轻取即得，重按滑数有力`（因为有热症就会有数脉出现，其实不难鉴别）
>
> 自汗出：热邪逼迫津液外越（和`迫血旺行`一个道理）
>
> 身重，多眠睡：1. 由于`少火生气，壮火食气`，故见身倦体重。2. 由于<font color="blue">热邪壅滞经脉，经脉气机不利</font>，也可引起身倦体重。
>
> 鼻息必鼾：1. 由于**热邪壅滞气机**，肺主气，故见肺窍不利。2. 由于`热为阳邪，其性炎上`，肺在上焦，所以热邪侵犯肺。
>
> 语言难出：热扰心神，热盛神昏，心主神志，故语言难出。
>
> 若被下者：若用下法
>
> 小便不利：热邪伤津，故尿少
>
> 直视失溲：下法导致肝肾阴津被伤，而肝开窍于目，肝阴被伤而不能上荣于目，故直视；<font color="blue">失溲：热盛神昏，膀胱失约，关门不固所致</font>
>
> 若被火者，微发黄色：火疗则全身微发黄。本受火邪，误用火疗，以火助热，热伤津，热伤营血，营血被伤，所以营气不布，故见身发黄。
>
> 剧则如惊痫，时瘛疭：<font color="blue">水不涵木而动风</font>，热极生风。
>
> 若火熏之，一逆尚引日，再逆促命期：如果用火熏法，一次误疗病人尚可延长几日，一而再再而三的误治，则是促进病人死亡。

> <font color="green">温病,若用火疗,则以热助热,大忌</font>

### 太阳病主症区别

* 太阳中风：脉浮缓，发热，有汗，恶风（恶寒），头项强痛
* 太阳伤寒：脉浮紧，发热，无汗，恶寒，体痛，头项强痛
* 温病：发热而渴，不恶寒者，脉浮（重按滑数有力）
* 风温：高热，汗出而热不退，脉浮（重按滑数有力）

#  太阳病欲解时

病有发热恶寒者,发于阳也;无热恶寒者,发于阴也.发于阳,七日愈;发于阴,六日愈.以阳数七,阴数六故也.(7)

> 病有发热恶寒者,发于阳也;无热恶寒者,发于阴也: 这里的"阴"和"阳"分别指太阳病中的伤寒以及中风(风为阳邪,寒为阴邪).太阳中风的特点是`发热,汗出,恶风,脉缓`.所以,发热恶寒者,发于阳也;太阳伤寒的特点是`恶寒,体痛,呕逆,脉紧`.所以无热恶寒,者,发于阴也.
>
> 发于阳,七日愈;发于阴,六日愈.以阳数七,阴数六故也:**在不传其他经的情况下(这个是前提条件)**,太阳中风七日痊愈.太阳伤寒六日愈.<font color="green">(太阳中风,发热汗出,所以营卫皆伤,而太阳伤寒仅是卫闭营郁,营阴并未被伤.故一般而言中风会重于伤寒,故中风的病程会长于伤寒)</font>

太阳病,头痛至七日以上自愈者,以行其经近故也.若欲作再经者,针足阳明,使经不传则愈.(8)

太阳病,欲解时,从巳至未上.(9)

风家,表解而不了了者,十二日愈.(10)

> 太阳病,头痛至七日以上自愈者,以行其经近故也:太阳病,头痛至七天以上自愈的,是因为自然病程的结束.**说明太阳病的自然病程是七天**
>
> 欲作再经:表示太阳本经将进入第二个病程或病传他经(不一定传阳明)
>
> 针足阳明,使经不传则愈:针灸阳明经,以截断病程(通常情况下,针灸阳明经中的**足三里穴**)
>
> 太阳病,欲解时,从巳至未上:太阳病欲解时是在巳时至未时(即上午的9点只下午3点间)(<font color="green">太阳经为三阳中阳气最盛阳经,其对应的应当在正午前后,因为午时阳气最盛</font>)
>
> 风家,表解而不了了者,十二日愈:体质素弱,容易患太阳中风的人,十二日痊愈.(体质素弱者,七天表邪解除后,正气难以完全恢复,需要继续调养五日,五脏正气复原,才可以痊愈)

> 附:六经病欲解时
>
> <img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/9fd2f66d958837a72d77b52f7456f992.jpg" style="zoom:50%;">

# 辨太阳病传经与否

伤寒一日,太阳受之,脉若静,为不传;颇欲吐,若燥烦,脉数急者,为传也.(4)

伤寒二三日,阳明,少阳症不见者,为不传也.(5)

> 伤寒一日,太阳受之:外感邪气伤表,则病在太阳(太阳主一身之表而统营卫)
>
> 脉若静,为不传:如果脉症相符,则表示不传经(脉浮,头项强痛而恶寒).
>
> 颇欲吐:颇欲吐表示很想吐,此时<font color="red">邪传少阳,胆火范胃,胃气上逆</font>.提示邪已经传入少阳
>
> 若燥烦:若燥烦表示邪传阳明,此时<font color="red">邪传阳明,里热里实,上扰心神</font>
>
> 脉数急者,为传也:提示脉已经发生变化(太阳病应当是浮缓脉或浮紧脉),此时表示已经传经.
>
> 伤寒二三日,阳明,少阳症不见者,为不传也:伤寒二三日,并没有看见阳明(烦躁)和少阳(胃气上逆)的症状(或已经不是浮脉),则表示并没有传其他经.

> 这表示**传经与否与患病长短没有关系,应该从脉和症上去判断**

# 参考

* 郝万山伤寒论讲稿





</伤寒论>]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
        <tag>太阳病</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster-RCNN总结</title>
    <url>/posts/dd3c4258.html/</url>
    <content><![CDATA[

## Question

* [RCNN大体流程](#RCNN)
* [Fast RCNN大体流程](#Fast RCNN)
* [Fast RCNN在RCNN的基础上有哪些优化](#整体流程)
* [RPN的整体流程如何](#整体流程)
* [RPN中有几个1 x1​的卷积](#1x1卷积)
* [Anchro Box是在哪一步生成的](#补充：Anchor Box)
* [RPN模型的输出是什么](#补充：Anchor Box)
* [如何利用RPN生成Bounding Box,Bounding Box和Anchor Box又是什么关系](#目标位置生成)
* [RPN如何训练](#训练)

## 概述

Two Steps的目标检测是由RCNN到Fast RCNN再到Faster RCNN。

### RCNN

`RCNN`的大体流程如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20201229151231.png)

上图中，由于`RCNN`的`CNN`提取特征部分是对每一个`Region Proposal`用CNN网络进行特征提取，较为耗时。

### Fast RCNN

`Fast RCNN`基本上是在`RCNN`的后半部分做修改，修改如下：

1. 用`CNN`整体图像进行特征提取，并建立`Feature Map`和原图像的映射关系。这样对于所有的`Region Proposal`就可以只提取一次
2. 由于在`Fast RCNN`仅建立`Feature Map`和原图的映射关系，并没有对每一个`Region Proposal`做拉伸（在`RCNN`中被称为`warp`），所以在Fast RCNN中使用`SPP layer`，以保证在后续的全连接的输入一致性。即`Fast RCNN`中的`ROI Pooling`层
3. 用`softmax`代替`SVM`，并且`loss`采用`L1`。所以`Faster RCNN`的输出为两个：`Bounding Box`的位置信息和`Softmax`的分类信息

`Fast RCNN`的大体流程图如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20201229155337.png)

`Faster RCNN`主要在Two Steps的前半段做文章。发现在`Fast RCNN`中，最耗时的是`Selective Search`部分（后半段的经过`Fast RCNN`的修改已经很快).所以，`Faster RCNN`主要基于`Selective Search`做修改，一是为了提高速度（`Selective Search用时大约2秒左右`）；二是由于有`Selective Search`组件，`Fast RCNN`还不完全算是一个end-to-end的模型。

## 整体流程

`Faster RCNN`的主要用`RPN`网路来代替`Selective Search`来给出`Region Proposal`，大体流程如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20201229161129.jpg)

从上图中可以看到，给出`Region Proposal`也可以分为两个部分：图像特征提取的`Conv层`和`RPN`。通常`Conv层`都采用成熟的图像模型，论文中是用的`VGG16`。更详细的整体流程图如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20201229162606.png)

`Conv层`不再阐述，下节主要讲`RPN`网络

## RPN网络

`RPN`网络的目的是给出`Region Proposal`。RPN的流程如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210105100025.png)

`RPN`的大体步骤如下：

1. `Sliding Window`层特征提取：利用`Sliding Window`层进行特征提取（实际上`Sliding Window`就是一个$3\times3$的卷积层，$filter$的个数为256，所以输出的维数是256维）
2. $1 \times 1$卷积：对1中的结果做$1\times1$的卷积操作（$1\times1$的卷积相当于全连接层）
3. `RPN`输出：对于2中的结果有两个输出：1-目标的坐标输出，2-是否是目标的分数输出。分别为$4k$个和$2k$个。其中$k$表示`Anchor Box`的个数。

由于3中会涉及到`Anchor Box`，且过程相对复杂，所以第3步的具体过程在下面详述。

### 1x1卷积

$1 \times 1$的卷积操作相当于全连接层，但需要注意的是，由于`RPN`网络有两个输出，**所以$1 \times 1$的卷积也有两个，分别对应目标的坐标以及目标的分数**。$filter$的个数分别为$4k$和$2k$

### RPN的输出

在介绍`RPN`之前，不得不提到`Anchor Box`，这里先补充`Anchor Box`的知识。

#### 补充：Anchor Box

> 我们知道，实际上在`Feature Map`中的一点对应原图中一个区域（也就是感受野的概念），那么在`RPN`中的$1 \times 1$的卷积层之中的一个像素点可以表示原图中的一个区域。对于`$1 \times 1$卷积层的结果，就可以表示$w \times h$个原图中的区域（$w \times h$表示$1 \times 1$卷积层的结果大小）。
>
> 如果有目标存在，则目标必定在这些感受野之中（虽然感受野不一定完全框中）。既然通过感受野不一定框中目标，那么我们可以在感受野的基础上添加形变，多几个框，那么我们框中目标的几率肯定会大大增加（虽然也不一定百分百框中），这便是`Anchor Box`的由来。`Anchor Box`如下图所示：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210106101329.png)
>
> 从上图可以看到，`Anchor Box`包含三种比例的长宽比，分别为$1:1$,$1:2$和$2:1$，且包含三种不同大小的框，所以一共$9$种。
>
> 例如，我们需要检测一个行人，行人的`Ground Truth`是一个长的矩形，如果用`Anchor Box`中$2:1$的框，此时框中的几率会大大增加。实际上，我们可以看到`Anchor Box`的三种规格框实际上就是针对不同比例的目标。

> 对于`RPN`中的两个输出：目标位置和目标分数。这里先介绍目标位置，再介绍目标的分类（也就是分类）

首先，在经过$1 \times 1$的卷积后，有一个$w \times h$长宽的结果，我们通过`Anchor Box`可以找到在原图中$w \times h \times k$个框，其中，$k$表示`Anchor Box`的个数。

并且，经过$1 \times 1$的卷积，该层会产生$w \times h \times 4 \times k$个预测结果（这里的结果算上$Channel$）。其中$4$表示位置的四个参数，$k$表示`Anchor Box`的个数。**（注意，这个预测结果表示的是`Anchor Box`和`Ground Truth `的偏差）**

既然在`RPN`中预测的是两者之间的偏差，那么在训练时对应的标签也应该是两者之间的偏差。下面介绍偏差的生成过程。

#### 目标位置生成

我们知道，生成的`Anchor Box`和`Ground Truth`是有差距的，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210107104422.jpg)

图中，红色为`Anchor Box`的结果，而绿色为`Ground Truth`的结果。

要想从`Anchor Box`到`Ground Truth`，只需要对`Anchor Box`做平移和拉伸即可，所以在`Faster RCNN`中，平移和和拉伸作为衡量两者间的差距的指标。

设代表一个`Anchor Box`的四个参数为$A=(x_a,y_a,w_a,h_a)$,分别表示其中心点坐标和长宽。其对应的`Ground Truth`为$GT=(x,y,w,h)$,则两者间的平移可以表示为(**平移的单位为长或宽的比例**)：


$$
x \approx w_a .t_x + x_a	\tag 1
$$

$$
y \approx h_a .t_y + y_a   \tag 2
$$

缩放关系可以表示为：
$$
w \approx w_a . exp(t_w)	\tag 3
$$

$$
h \approx h_a . exp(t_h)	\tag 4
$$

上式中，$d_*(A)$为需要求的未知数。通过变换可以表示为：
$$
t_x = \frac{x - x_a}{w_a}	\tag	5
$$

$$
t_y = \frac{y - y_a}{h_a}	\tag	6
$$

$$
t_w=\log{(w/w_a)}		\tag	7
$$

$$
t_h=\log{(h/h_a)}		\tag	8
$$

同理，设预测的`RPN`网路预测的结果为$(x^{\ast},y^{\ast},w^{\ast},h^{\ast})$,则预测框和`Anchor Box`的四个坐标的差距可以表示为：
$$
t_x^{\ast} = \frac{x^{\ast} - x_a}{w_a}	\tag	9
$$

$$
t_y^{\ast} = \frac{y^{\ast} - y_a}{h_a}	\tag	{10}
$$

$$
t_w^{\ast}=\log{(w^{\ast}/w_a)}		\tag	{11}
$$

$$
t_h^{\ast}=\log{(h^{\ast}/h_a)}		\tag	{12}
$$

也就是说，我们`RPN`网络需要预测的实际上是$t_{\ast}^{\ast}$(下标的 * 表示$x,y,w,h$,上标的 * 表示预测框)，也就是`Predict Box`和`Anchor Box`的差距。我们也可以通过`Ground Truth`和`Anchor Box`计算得到标签，这样神经网络就能够训练了。

总结一下目标位置的过程：

1. $1 \times 1$的卷积
2. 生成`Anchor Box`
3. 利用`RPN`网络得到预测值，也就是生成偏差
4. 再利用这个偏差还原成`Bounding Box`

#### 目标分数

> 目标分数就是我们所说的$confidence$,即模型认为是目标的置信度。

相对于目标位置，目标分数较为简单，下面直接总结这条线的流程：

1. $1 \times 1$的卷积
2. 利用$softmax$分类（注意这里论文中是用的$softmax$，所以分数的结果有$w \times h \times 2 \times k$个）

### Loss Function

了解了`RPN`的流程，我们再来看看RPN的`loss Function`，`RPN`中一个 `Mini Batch` 的$loss$如下所示：
$$
loss(p_i,G_i)=\frac{1}{N_{cls}}\sum_{i}L_{cls}(p_i,p_i^{\ast})+ \lambda \frac{1}{N_{reg}}\sum_ip_i^{\ast}L_{reg}(t_i,t_i^{\ast})	\tag	{13}
$$
上式(13)中,可以看到前半部分为分类的$loss$,即普通的`cross Entropy`，$p_i$表示预测是目标的概率，而$p_i^{\ast}$表示的是label，当有目标时为1，无目标时为0。

而后半部分为位置的$loss$，其中$L_{reg}$为`smooth L1 loss​`。有：
$$
L_{reg}(t_i,t_i^{\ast})=\sum_{i\in\{x,y,p,t\}}smooth_{L1}(ti-t_i^{\ast})
$$
其中：

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>s</mi>
  <mi>m</mi>
  <mi>o</mi>
  <mi>o</mi>
  <mi>t</mi>
  <msub>
    <mi>h</mi>
    <mrow class="MJX-TeXAtom-ORD">
      <mi>L</mi>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mrow>
    <mo>{</mo>
    <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
      <mtr>
        <mtd>
          <mn>0.5</mn>
          <msup>
            <mi>x</mi>
            <mn>2</mn>
          </msup>
        </mtd>
        <mtd>
          <mrow>
            <mtext>if&#xA0;</mtext>
            <mrow class="MJX-TeXAtom-ORD">
              <mrow class="MJX-TeXAtom-ORD">
                <mo stretchy="false">|</mo>
              </mrow>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mo stretchy="false">|</mo>
              </mrow>
              <mo>&lt;</mo>
              <mn>1</mn>
            </mrow>
          </mrow>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mrow class="MJX-TeXAtom-ORD">
            <mo stretchy="false">|</mo>
          </mrow>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo stretchy="false">|</mo>
          </mrow>
          <mo>&#x2212;<!-- − --></mo>
          <mn>0.5</mn>
        </mtd>
        <mtd>
          <mtext>otherwise</mtext>
        </mtd>
      </mtr>
    </mtable>
    <mo fence="true" stretchy="true" symmetric="true"></mo>
  </mrow>
</math>

<!--
$$
smooth_{L1}(x)=\begin{cases}
0.5x^2 & \text{if $ |x|<1 $}\\
|x|-0.5 & \text{otherwise}
\end{cases}
$$
-->

$\lambda$平衡是用于两者差的一个参数，为10

### 训练

在训练时，不会将所有的生成的`Anchor Box`拿去训练，在生成的`Anchor Box`中，首先会筛选`Anchor`与`GT`的$IOU>0.7$的作为正样本，`Anchor`与`GT`的$IOU<0.3$作为负样本，其他的不要。 其次，为了保证样本的平衡性，在上述步骤生成的正负样本中个各选择128个送进网络中进行训练。 ## 整体训练 在`faster rcnn`中，分为训练`rpn`和`fast rcnn`两部分。步骤如下： 1. 训练`rpn`网络（这是训练`rpn`的第一轮） 2. 利用训练好的`rpn`网络收集`region proposals` 3. 利用2中的`region proposal`训练`fast rcnn`(训练`fast rcnn`的第一轮) 4. 训练`rpn`网络（这是训练`rpn`的第二轮） 5. 6. rcnn`的第二轮) 思考 ### 对anchor box使用的疑惑 在`anchor box`中，让我疑惑的是，为何不直接让`predict box`和`ground truth`的偏差做回归，在中间又夹一个`anchor box`。论文中中的解释是由于在`r-cnn`和`fast rcnn`中用了`roi-pooling`,由于`roi-pooling`的缘故可以武断的用共享权值（[1] 和[2]分别表示`spp net`和`fast rcnn`两个模型的论文）>  In [1],[2], bounding-box regression is performed on features pooled from arbitrarily sized RoIs, and the regression weights are shared by all region sizes.  

但由于在`RPN`中仅是用$3 \times 3$的卷积形成`Feature Map`,而目标的大小和位置多变的（没有用`ROI Pooling`），所以这里用了$k$个不共享权值的回归器，并且这$k$个回归器不共享权值。（$k$个预测可能，答对的可能性也大一些）

> In our formulation, the features used for regression are of the same spatial size (3 × 3) on the feature maps. To account for varying sizes, a set of k bounding-box regressors are learned. Each regressor is responsible for one scale and one aspect ratio, and the k regressors do not share weights. As such, it is still possible to predict boxes of various sizes even though the features are of a fixed size/scale, thanks to the design of anchors.  

但文中并没有解释为何引入`Anchor Box`能够让`Predict Box`准确的预测出`Ground Truth`，相较于`Predict Box`和`Ground Truth`直接回归的优势是什么。对于以上的$k$，完全可以训练`Predict Box`和`Ground Truth`的$k$个回归器，能够达到同样的效果

对于以上，我的理解是$3 \times 3$形成的感受野，在原图中对应的区域是有局限性的，一旦目标目标超出这个感受野，则效果不佳。所以引入了`Anchor Box`,

## 参考

* [RPN(区域生成网络)](https://www.cnblogs.com/Terrypython/p/10584384.html)
* [一文读懂Faster RCNN](https://zhuanlan.zhihu.com/p/31426458)
* [RPN网络](https://blog.csdn.net/qq_30815237/article/details/93596163)

</0.3$作为负样本，其他的不要。>]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分割（一）：基于边缘突变的分割</title>
    <url>/posts/d2113c07.html/</url>
    <content><![CDATA[
## Question

* [一阶差分和二阶差分求边缘各有什么优缺点](#一阶差分和二阶差分衡量边缘突变比较)
* [在边缘检测前一般要做什么](#边缘模型)
* [Prewitt算子的解释](#基本的检测模型)
* [Sobel算子相比于Prewitt算子的优势是什么](#基本的检测模型)

## 梯度和差分基础

基于边缘突变的分割思想十分简单，如果一个像素点在分割的边缘上，那么，该像素点在某个方向上必定是突变的（这个方向不仅限于$x$和$y$）。鉴于以上思想，基于边缘的分割可以分割点、线甚至边缘。

衡量某个像素在某个方向上是否是突变的，我们最容易想到的是梯度，梯度向量的方向表示变换最大的方向，而梯度的幅值表示变换的大小。

图像在$x$和$y$两个方向上的梯度即为差分，可以表示为：
$$
\frac{\partial{f}}{\partial{x}}=f'(x)=f(x+1)-f(x)	\tag{1}
$$

$$
\frac{\partial{f}}{\partial{y}}=f'(y)=f(y+1)-f(y)	\tag{2}
$$

图像在$x$和$y$上的二阶差分为（二阶差分同样可以衡量突变）：
$$
\frac{\partial^2{f}}{\partial{x^2}}=f'(x+1) - f'(x)=f(x+2)-2f(x+1)+f(x)	\tag{3}
$$


$$
\frac{\partial^2{f}}{\partial{y^2}}=f'(y+1) - f'(y)=f(y+2)-2f(y+1)+f(y)	\tag{4}
$$

## 一阶差分和二阶差分衡量边缘突变比较

设有图像在$x$方向如下图表所示，则其一阶导数和二阶导数的结果如下：

| 编号     | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   | 14   | 15   | 16   | 17   | 18   | 19   |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 原始数据 | 5    | 5    | 4    | 3    | 2    | 1    | 0    | 0    | 0    | 0    | 6    | 0    | 0    | 0    | 1    | 3    | 1    | 0    | 0    | 0    |
| 一阶差分 |      | 0    | -1   | -1   | -1   | -1   | -1   | 0    | 0    | 0    | 6    | -6   | 0    | 0    | 1    | 2    | -2   | -1   | 0    | 0    |
| 二阶差分 |      |      | -1   | 0    | 0    | 0    | 0    | 1    | 0    | 0    | 6    | -12  | 6    | 0    | 1    | 1    | -4   | 1    | 1    | 0    |

其对应的图像如下：

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/图像差分.png" style="zoom:80%;">

通过观察以上图像可以得出以下几点特性：

* 二阶导数对平缓的像素变化不敏感（例如编号从1到6的像素，一阶差分为-1，而二阶差分为0）
* 二阶导数在斜坡的开始处和结束处均不为0，而一阶导数仅有开始处不为0
* 二阶导数在斜坡的开始处和结束处的符号相反，这表示二阶导对光线从暗到亮和从亮到暗比较敏感，而一阶导数无此性质

由此可以得出以下结论：

> * 对于缓慢变化的边缘，一阶导（差分）更敏感
> * 对于突变的边缘，二阶导更敏感，且二阶导可以分辨光线的明亮变化

## 孤立点检测

通常孤立点同时在两个方向上变化均比较剧烈，所以根据前文所述，二阶差分对于突变更加敏感，所以二阶差分更适合孤立点检测。

所以，这里会用到拉普拉斯算子（拉普拉斯算子即是二阶差分在图像中一种应用）.

>**补充：拉普拉斯算子**
>
>拉普拉斯算子定义为：
>$$
>\nabla^2f(x,y)=\frac{\partial^2f}{\partial{x^2}} + \frac{\partial^2f}{\partial{y^2}}	\tag{5}
>$$
>也就是说，拉普拉斯算子为$x$和$y$两个方向上的二阶差分之和，也即$x$和$y$的变化程度之和。
>
>由前面的二阶差分展开公式，可得拉普拉斯算子为：
>$$
>\nabla^2f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)
>$$
>实际上，拉普拉斯算子就是一个滤波器，上式的滤波模板可表示为：
>
>| 0    | 1    | 0    |
>| ---- | ---- | ---- |
>| 1    | -4   | 1    |
>| 0    | 1    | 0    |
>
>但上式实际上仅考虑了$x$和$y$的两个方向上的变化，对于正反$45^.$的变化并未考虑，所以，通常情况下，会加上45度角的检测，此时的拉普拉斯算子的滤波模板为：
>
>| 1    | 1    | 1    |
>| ---- | ---- | ---- |
>| 1    | -8   | 1    |
>| 1    | 1    | 1    |
>
>以上模板即检测四个方向变化的模板。

用以上模板对图像进行滤波，设滤波后的某一个点的结果为$R(x,y)$，若：


$$
g(x,y)=\begin{cases} 1,&\text{ |R(x,y)|} \geq T \\ 0,  &\text{other} \end{cases}	\tag{6}
$$
在结果$g(x,y)$中，为1的点即为孤立点。

### Demo

下面是孤立点检测的Demo。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/孤立点检测.png)

上图中，图一为原图片，图二为通过拉普拉斯变换后的结果，图三为通过阈值筛选后的结果，阈值取百分之99的分位数。

## 线检测

对于线的检测，同样用拉普拉斯变换，但前文提到，由于拉普拉斯的检测结果有`双边性`,也就是说检测的结果有两个边缘，此时需要保留其中一个边缘，另一个略去。如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/线检测.png)

上图中，图一是原始图像，图二是经过拉普拉斯模板过滤后的图像，图三是图二取绝对值的结果，图四为取图二取正值的结果。

## 基本的检测模型

**由于一阶导数和二阶导数对噪声都较为敏感，所以通常情况下，在进行边缘检测之前要滤波处理**

实际上，由上面可知，一阶导数和二阶导数实现边缘检测，但又各有优势和劣势，所以对于检测一个物体的边缘，一阶导和二阶导都是可以的。这里先介绍一阶导。介绍一阶导的边缘提取通常需要用`Sobel`算子。

> **补充：Sobel算子以及Prewitt算子**
>
> 如公式（1）和公式（2），要用一阶导的模板过滤图像仅用两个窗格即可：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/一阶导边缘梯度模板.png)
>
> 但以上模板对于中心点对称的边缘计算不是很有用。所以一阶的模板通常也采用$3\times3$的模板，$3\times3$的模板定义如下：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/3X3模板.png)
>
> $3\times3$的模板满足中心对称，以下是`Prewitt`算子：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/prewitt模板.png)
>
> 其中，左上图表示$y$方向上的检测，右上图表示$x$方向上的检测。从检测算子中可以看出，实际上`Prewitt`算子并非计算两个相邻像素之间的差分，而是跳过一行（列）来计算差分，以此来保证中心对称性。其公式表示为：
> $$
> g_x=\frac{\partial{f}}{\partial{x}}=(z_7+z_8+z_9)-(z_1+z_2+z_3)	\tag{7}
> $$
>
> $$
> g_y=\frac{\partial{f}}{\partial{y}}=(z_3+z_6+z_9)-(z_1+z_4+z_7)	\tag{8}
> $$
>
> 此外，就是`Sobel`算子，`Sobel`是在`Prewitt`算子的基础上进行改进，其模板如下：
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/Sobel算子模板.png)
>
> **`Sobel`算子相较于`Prewitt`算子可以平滑图像，所以通常对于一维的边缘提取，我们用`Sobel`算子**

从`Sobel`算子可以看出，实际上`Sobel`算子仅能检测单个方向的边缘，要想综合两个方向的边缘，最容易想到的是类似于求梯度值的方式，即相加求平方根，求平方根太过费时，书上采用求绝对值再求和的方式：
$$
M(x,y)\approx|g_x|+|g_y|	\tag{9}
$$

### Demo

以下是通过`Sobel`进行边缘检测的Demo：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20201104162047.png)

上图中，图一为原图像，图二为$x$方向的梯度的绝对值，图三为$y$方向上的梯度的绝对值，图四为两个方向绝对值之和。

**通常情况下，在进行边缘检测之前需要对图像进行平滑处理，以减少噪声对边缘检测的影响**。下图是先用均值滤波对原图像进行处理，再用`Sobel`进行边缘检测的结果。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20201104162051.png)

可以看到，在经过平滑处理后的结果明显好于没有平滑处理的。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>区域的表示和描述</title>
    <url>/posts/d4747641.html/</url>
    <content><![CDATA[
## Question

* 边界追踪的目的
* 表示和描述一般用在图像处理的什么地方
* Moore边界追踪的大体流程
* 链码的主体思想
* 标记图的作用
* 标记图的主体思想
* 标记图如何解决旋转不变性
* 标记图解决缩放有哪两种方式，分别是什么，各自的优缺点是什么
* 形状数的目的
* 致密度如何计算
* 圆度率如何计算
* 何为区域的拓扑特性
* 拓扑特性有些什么，如何计算



# 图像（区域）的表示和描述

所有Demo见：https://github.com/qcymkxyc/Image-Process/blob/master/notebooks/%E5%9B%BE%E5%83%8F%E8%A1%A8%E7%A4%BA%E4%B8%8E%E6%8F%8F%E8%BF%B0.ipynb

* 表示：顾名思义，如何表示这一个区域。需要说明的是，像素仅是表示一个区域 的一种方式。（比如对于一个矩形，可以用另一种表示方式：四条线段）
* 描述：如何表示该区域的特性，例如纹理，梯度等

**该流程是在图像分割之后，对分割后的单元（区域）进一步处理的流程**

## 表示

### 边界追踪（Moore边界追踪）

Moore边界追踪是最基本的像素级的表示方式

> 边界追踪的目的是找一个物体（区域）的外边缘，或提取孔洞的外边缘

Moore边界追踪的步骤如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/边界追踪.png)

### 链码

链码是以线段为单位来表示区域的外边界，相比于边界追踪，其泛化性更好，鲁棒性也更高。

链码又叫**弗雷曼链码**

> 链码的主旨思想是将多个像素组成的线段根据方向进行分类，这样，一个封闭曲线就由一系列方向化的线段表示。

#### 详细步骤

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/链码1.png)

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/链码2.png)

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/链码3.png)

#### 算法代码实现

Freeman链码提取实现的代码较多，见https://github.com/qcymkxyc/Image-Process/blob/master/src/chapter11/freeman_code.py

#### Demo

**提取原图像：**

Demo的任务是给定一个封闭曲线，给出其对应的Freeman链码，原图像如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/Freeman原图像.png)

**原图像二值化：**

对其进行均值滤波，并用$OTSU$算法进行二值化后

主要代码：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tmp_img = cv2.blur(img,(<span class="number">9</span>,<span class="number">9</span>))</span><br><span class="line">th,tmp_img = cv2.threshold(tmp_img,<span class="number">0</span>,<span class="number">255</span>,cv2.THRESH_BINARY + cv2.THRESH_OTSU)</span><br><span class="line">plt.imshow(tmp_img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

二值化后的图像为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/Freeman二值化后的图片.png)

**构建Freeman链码**

主要代码如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">black_img = np.zeros_like(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.imshow(cv2.findContours(black_img,contours,1,[255,255,255],2))</span></span><br><span class="line"></span><br><span class="line">tmp_img = cv2.blur(img, (<span class="number">9</span>, <span class="number">9</span>))</span><br><span class="line">th, tmp_img = cv2.threshold(</span><br><span class="line">    tmp_img, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_BINARY + cv2.THRESH_OTSU)</span><br><span class="line">image, contours, hierarchy = cv2.findContours(</span><br><span class="line">    tmp_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)</span><br><span class="line">contour = contours[<span class="number">-1</span>]</span><br><span class="line">contour = np.reshape(contour, (contour.shape[<span class="number">0</span>], contour.shape[<span class="number">-1</span>]))</span><br><span class="line">x = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> contour]</span><br><span class="line">y = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> contour]</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">r = freeman_code.get_freeman_coordination(tmp_img, contour)</span><br><span class="line"></span><br><span class="line">x = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> r]</span><br><span class="line">y = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> r]</span><br><span class="line"></span><br><span class="line">plt.plot(x,y)</span><br></pre></td></tr></table></figure>

获取其外边框，且该外边框上的像素点必须是连续的，所以在调用opencv的$findContours$方法时必须用cv2.CHAIN_APPROX_NONE​,该参数表示提取的边缘是严格8连接的，提取的外边框如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/freeman外边框.png)

在获取外边框后，对外边框进行Freeman编码，编码的结果为一系列在Freeman网格中的坐标，部分如下所示：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[(<span class="number">4</span>, <span class="number">1</span>),</span><br><span class="line"> (<span class="number">4</span>, <span class="number">1</span>),</span><br><span class="line"> (<span class="number">4</span>, <span class="number">1</span>),</span><br><span class="line"> (<span class="number">4</span>, <span class="number">1</span>),</span><br><span class="line"> (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line"> (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line"> (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line"> (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line"> (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>

对Freeman坐标进行画图，结果为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/Freeman结果.png)

### 标记图

> 标记图可用来识别不同形状的闭合区域。例如可用来识别矩形和三角形

#### 主要过程

标记图较为简单，主要分为两步：

* 找到该区域的质心（质心等于该区域所有的点的平均）
* 计算质心到每一个边界点的距离以及角度（即以质心为圆心旋转$360^\circ$查看该质心到边界的距离）

最终会形成一个**标记图**，如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/标记图.png)

如果该区域是一个四边形，会出现四个波峰；如果是三角形，则会出现三个波峰，由此我们可以判定该区域的形状。

#### 标记图旋转不变性

在标记图中解决旋转不变性较为容易，即选择离质心最远的点作为起始点，那么反应到标记图中则是起始点为最高的波峰。

#### 标记图缩放解决

书中解决缩放问题有两种方式：

1. 归一化
   $$
   \frac{距离}{max(距离) - min(距离)}
   $$

**该方式的缺点是对噪声敏感**

2. 样本/方差
   $$
   \frac{样本}{方差}
   $$
   

**相比于归一化，该方式更加的稳定**



### 骨架

骨架见[这篇博客](http://blog.zhangqi2019.top/posts/311496b5.html/)

## 边界描述

边界描述实际上是对区域边缘的描述，这种描述有粗有细，也就是说有泛化的描述也有精确的描述，他们各有各用途。

* 泛化描述：形状数
* 细致描述：
  * 边界像素个数
  * 统计矩

### 形状数

> 形状数的目的：保证Freeman链码的旋转不变性

形状数是在Freeman链码的基础上做两步事情：

* 差分（这里的差分并非数学上的差分）
* 差分结果排序（这里也非单纯的排序，后面会详细说明）



## 区域描述

### 偏心率

* 边界的直径：封闭曲线内的最大直径（长轴）
* 短轴：垂直于长轴的轴

长轴和短轴组成可包住区域的边框
$$
偏心率=\frac{短轴}{长轴}
$$

**偏心率可以表示为总体形状的描述子**

### 致密度描述子

影响致密度的两个因素为：

* 区域的形状
* 区域是否有孔洞

#### 致密度

致密度的公式为：
$$
致密度 = \frac{周长^2}{面积}
$$

#### 圆度率

圆度率：一个区域的面积与具有相同周长的一个圆（最致密的形状，也就是说没有孔洞）的面积之比。

圆度率$R_c$可以表示为：
$$
R_c=\frac{4\pi A}{P^2}
$$
其中，$A$表示区域面积，$P$表示其对应的周长

###  拓扑描述子

拓扑特性定义：未受任何变形影响的图形的性质

拓扑描述子包括以下几个：

* 孔洞数
* 连通分量数
* 欧拉数。欧拉数=连通分量数-孔洞数



### 纹理描述

]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>Demo</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>ELMO、BERT以及GPT</title>
    <url>/posts/3a513c16.html/</url>
    <content><![CDATA[

## Question

### ELMO

* ELMO的主旨思想
* ELMO的流程
* 在多层情况下，ELMO的权值如何确定
* 在多层情况下，ELMO的最终结果如何得到

## ELMO

### 概述

> 在word2vec中任何一个词对应一个Word Embedding，但同一个词在不同的语境下表示的含义可能是不同的，所以ELMO认为相同的词在不同的语境下有不同的Embedding

### 算法流程

ELMO的流程较为简单，总体用一个Bi-Directional RNN来拟合。正向和反向部分结构一样，这里以正向为例。

> 正向部分类似于Seq-to-Seq的Encoder，但输出是Many-To-Many的形式，每一个RNN的输出对应一个词的Embedding。

将正向和反向的Embedding stack到一起即为一层对于一个词的Embedding。如下图所示。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-fa8c31b80704cc40.png)

但通常情况下会有多层输出，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-de0f3386271083e3.png)

对于一个词的Embedding取哪一层是一个问题。而ELMO的做法是**都要**，他将两层的结果进行加权，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-a92f25557abd193f.png)

但权值的确定有两种：

* 要么靠人为设定
* 要么网络自己学习

ELMO选择后者（通常神经网络都会选择让算法自己学习）。

但需要学习，必定要输出才行。所以，ELMO的做法是：**在特定的任务下学习权值。**]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>自然语言处理</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;&lt;伤寒论&gt;&gt;方歌</title>
    <url>/posts/e9897890.html/</url>
    <content><![CDATA[
## 1．桂枝汤类方歌（二十一首）

一、桂枝汤：桂枝汤方桂芍草，佐用生姜和大枣。啜粥温服取微汗，调和营卫解肌表。

二、桂枝加葛根汤：桂加葛根走经输，项背几几反汗濡。解肌驱风滋经脉，用治柔痉理不殊。

三、桂枝加附子汤：桂加附子治有三，风寒肢痛脉迟弦。汗漏不止恶风甚，肌肤麻木卫阳寒。

四、桂枝去芍药汤：桂枝去芍意何居，胸满心悸膻中虚。若见咳逆和短气，桂甘姜枣治无遗。

五、桂枝去芍药加附子汤：桂枝去芍避阴寒，加附助阳理固然。脉促无力舌质淡，胸痹治法非等闲。

六、桂枝麻黄各半汤：桂加麻杏名各半，肌表小邪不得散。面有热色身亦痒，两方合用发小汗。

七、桂枝二麻黄一汤：桂二麻一名合方，寒热如疟治法良。大汗之后表未解，祛邪同时正亦匡。

八、桂枝二越婢一汤：桂加麻膏量要轻，热多寒少脉不丰。小汗法中兼清热，桂二越一记心中。

九、桂枝去桂加茯苓白术汤：桂枝汤中去桂枝，苓术加来利水湿。小便不利心下满，颈项强痛热翕翕。

十、桂枝加厚朴杏子汤：桂加厚朴杏子仁，喘家中风妙如神。如今肺炎求治法，媲美麻杏说与君。

十一、桂枝加芍药生姜各一两人参三两新加汤：桂枝加参新加汤，增姜加芍效力彰。身疼脉沉非表证，血虚营弱汗多伤。

十二、桂枝甘草汤：桂枝甘草补心虚，两手叉冒已浇漓。汗多亡液心阳弱，药少力专不须疑。

十三、小建中汤：桂加饴糖小建中，倍加芍药方奏功。虚劳里急心烦悸，伤寒尺迟梦失精。

十四、桂枝去芍药加蜀漆牡蛎龙骨救逆汤：桂枝去芍恐助阴，痰水犯心狂躁纷。龙牡安神桂枝助，蜀漆涤饮有奇勋。

十五、桂枝加桂汤：桂枝加桂剂量增，奔豚冲心来势凶。平冲降逆解外寒，补心代肾立奇功。

十六、桂枝甘草龙骨牡蛎汤：桂枝甘草组成方，龙牡加入安神良。心悸同时兼烦躁，补阳宁心效果彰。

十七、桂枝附子汤：桂枝附子寒痹痛，去芍加附量要重。扶阳散寒应兼顾，脉浮虚涩是其应。

十八、去桂加白术汤：去桂加术大便硬，寒湿相搏身疼痛。术附姜枣加甘草，三阴都尽冒始应。

十九、桂枝加芍药汤：桂枝加芍腹痛诊，此病原来属太阴。慢性菌痢久不已，脉沉弦缓是指针。

二十、桂枝加大黄汤：桂枝大黄治腹痛，太阴阳明表里病。调和气血泻结滞，胃弱之人宜慎用。

二十一、桂枝人参汤：人参汤方即理中，加桂后煎力方增。痞利不解中寒甚，温中解表建奇功。

## 2．麻黄汤类方歌（八首）

一、麻黄汤：麻黄汤治太阳寒，麻桂杏草四味联。表实无汗头身疼，脉紧气喘更恶寒。

二、大青龙汤：大青麻杏石膏枣，桂姜相加七味好。不汗焦躁身疼痛，饮流四肢肿胀讨。

三、小青龙汤：小青龙汤用麻黄，桂芍辛味与干姜。半夏炙草同剂量，表寒里饮病为殃。

四、麻黄杏仁甘草石膏汤：麻杏石甘四味施，汗出而喘肺热居。身热脉数证方是，不恶寒兮别桂枝。

五、麻黄连翘赤小豆汤：麻黄连翘赤豆汤，湿热兼表身发黄。麻翘姜辛梓皮枣，杏仁赤豆煮潦浆。

六、麻黄细辛附子汤：麻黄细辛附子汤，太少两感用此方。发热恶寒脉不起，温经解表有特长。

七、麻黄附子甘草汤：麻黄附子甘草汤，伤寒两感阳气伤。此方本来无里症，助阳发汗保康乐。

八、麻黄升麻汤：麻黄升桂汤芍姜，知膏天冬苓术黄。归蕤炙草十四味，寒热并用和阴阳。

## 3．葛根汤类方歌（三首）

一、葛根汤：葛根桂枝加葛黄，无汗项背几几强。二阳合病下利治，刚痉无汗角弓张。

二、葛根加半夏汤：葛根加夏病二阳，下利呕逆表邪强。疏表解肌利肠胃，合病治法好思忖。

三、葛根黄芩黄连汤：葛根芩连加甘草，协热下利喘汗宝。清热生津解表里，葛根用至八钱好。

#### 4．抵当汤类方歌（三首）

一、桃核承气汤：桃核承气硝黄草，桃仁桂枝五药讨。太阳蓄血腹痛急，其人如狂成效好。

二、抵当汤：抵当汤顶事大黄，虻虫桃蛭力最强。少腹硬满小方便，攻瘀逐热治发狂。

三、抵当丸：抵当丸即抵当汤，捣药成丸煮水浆。连渣服之只一颗，缓攻瘀血正不伤。

## 5．栀子豉汤类方歌（七首）

一、栀子豉汤：栀子豉汤治虚烦，懊憹倒置不得眠。呕吐少气加姜草，胸窒结痛药不添。

二、栀子甘草豉汤：见栀子豉汤方歌内

三、栀子生姜豉汤：见栀子豉汤方歌内

四、栀子厚朴汤：栀子厚朴药有三，栀子厚朴枳实煎。心烦腹满分上下，清烦泻满两证兼。

五、栀子干姜汤：栀子干姜治心烦，身热不去泻又添。寒热并用分上下，清热温寒一方肩。

六、枳实栀子豉汤：枳实枝豉劳复宝，食后再加大黄好。酒疸心热且懊憹，栀子大黄力能讨。

七、栀子柏皮汤：栀子柏皮湿热黄，发热尿赤量不长。栀子黄柏兼甘草，清热祛湿好思忖。

## 6．陷胸汤类方歌（六首）

一、大陷胸丸：大陷胸丸法最超，半升葶苈杏硝调。项强如痉君须记，大黄甘遂下之消。

二、大陷胸汤：大陷胸汤遂硝黄，心下硬痛脉紧强。热气内陷水热结，小有潮热要参详。

三、十枣汤：十枣汤治胁下水，心下痞硬胁痛锐。甘遂芫戟研细末，枣汤煮浓服钱匕。

四、小陷胸汤：小陷胸汤大瓜蒌，半夏黄连三药投。痰热胶结心下痛，利痰清热服之廖。

五、白散：白散三物巴桔贝，寒实结胸此方贵。或吐或利分上下，中病即止莫伤胃。

六、瓜蒂散：瓜蒂散是涌吐方，胸中痞硬痰邪猖。气冲咽喉不得息，蒂豆研散调豉汤。

## 7．泻心汤类方歌（六首）

一、半夏泻心汤：半夏泻心芩连姜，人参草枣融合方。心下痞满兼呕吐，去渣重煎调胃肠。

二、大黄黄连泻心汤：大黄黄连泻心汤，黄芩黄连和大黄。清热泻痞沸汤渍，擅治焦躁吐衄殃。

三、附子泻心汤：附子泻心芩连黄，恶寒汗出痞为殃。专煎轻渍须记住，泻热之中又扶阳。

四、生姜泻心汤：生姜泻心是良方，胃中不和痞为殃。噫气下利芩连草，参枣半夏与二姜。

五、甘草泻心汤：甘草泻心用芩连，干姜半夏参枣全。心下痞硬下利甚，更治狐惑心热烦。

六、旋覆代赭汤：旋覆代赭痞在中，噫气不除饮气冲。参草姜枣半夏予，赭轻姜重方奏功。

## 8．甘草汤类方歌（四首）

一、甘草汤：甘草名汤咽痛求，生用一两不多收。莫道此是中焦药，清解少阴效最优。

二、炙甘草汤：炙甘草汤少阴虚，心慌脉结证无疑。麦地麻胶桂姜枣，清酒与水煎法奇。

三、甘草附子汤：甘草附子汤四味，桂枝白术药方备。骨节掣痛不可近，恶风短气阳虚最。

四、甘草干姜汤：甘草干姜二药齐，温肺运脾暖四肢。金匮用以治肺痿，咳嗽多涎尿也遗。

## 9．苓桂术甘汤类方歌（六首）

一、茯苓桂枝白术甘草汤：苓桂术甘温药方，气上冲胸水为殃。头眩心慌阴邪重，咳嗽短气成效彰。

二、茯苓桂枝甘草大枣汤：苓桂枣甘伏水邪，脐下悸占用则确。或许上冲发奔豚，甘澜水煮效方捷。

三、茯苓甘草汤（苓桂姜甘汤）：茯苓甘草与桂姜，胃中停水悸为殃。气趋小腹或成泄，健胃泻水厥亦良。

四、五苓散：五苓苓桂泽猪术，水停膀胱津不输。口渴心烦尿不利，饮入则吐脉来浮。

五、猪苓汤：猪苓汤治少阴虚，热与水蓄烦呕居。小便不利口又渴，泽胶猪茯及滑石。

六、文蛤散：水潠原逾汗法门，肉上粟起更增烦。意中思水还无渴，文蛤磨调药不繁。

## 10．黄芩黄连汤类方歌（四首）

一、黄芩汤：黄芩汤治太少利，腹痛急切脉弦细。黄芩白芍甘草枣，清热和阴平肝逆。

二、黄芩加半夏生姜汤：黄芩原方加夏姜，呕吐下利胃肠伤。太少合病邪热淫，苦降辛开治少阳。

三、黄连汤：黄连汤内参连草，姜桂半夏和大枣。胃中有痛心胸热，呕吐腹痛此方宝。

四、黄连阿胶汤：黄连阿胶治少阴，焦躁不寐脉数频。舌尖如梅是的候，芩连芍胶黄搅匀。

## 11．白虎汤类方歌（三首）

一、白虎汤：白虎烦渴用石膏，大热汗出脉浩浩。知粳甘草四药足，清气生津润枯焦。

二、白虎加人参汤：白虎加参气阴伤，烦渴脉大饮水浆。汗出过多脉成芤，背微恶寒舌焦黄。

三、竹叶石膏汤：竹叶石膏气阴伤，病后虚羸呕逆方。不欲茶饭参草麦，粳叶石膏半夏匡。

## 12．承气汤类方歌（六首）

一、调胃承气汤：调胃承气用大黄，芒硝甘草三药偿，胃气不和心烦热，便燥谵语舌苔黄。

二、小承气汤：小承气汤朴枳黄，便硬谵语腹胀详。识得燥结分轻重，脉滑不紧用此方。

三、大承气汤：大承气汤用硝黄，厚朴枳实四药强。潮热蒸蒸濈濈汗，腹满硬痛峻攻良。

四、麻子仁丸：麻子仁丸结果好，大便秘结津液少。枳朴大黄泻胃强，麻杏芍药滋脾约。

五、蜜煎导方：（方歌见下）

六、猪胆汁灌方：蜜煎熟后样如饴，稍冷搓挺四寸余。温纳肛门润肠燥，古法导便叹诧异。津亏有热便不出，猪胆一枚方适宜。胆汁调醋灌肠内，虚家便秘奏效奇。

## 13．柴胡汤类方歌（七首）

一、小柴胡汤：小柴胡汤解少阳，胸满胁痛呕吐详。口苦咽干目眩是，柴芩参草枣半姜。

二、大柴胡汤：大柴胡汤大黄枳，柴芩姜夏芍枣宜。少明合病气火郁，呕吐口苦心下急。

三、柴胡加芒硝汤：小柴加硝两解方，芒硝后煎入药良。日晡潮热胸胁满，协调胃胆利少阳。

四、柴胡桂枝汤：柴胡桂枝双边合，善治太少两经疴。心下支结关节痛，前期肝硬亦能和。

五、柴胡桂枝干姜汤：柴胡桂姜痛胁背，大便不实尿欠利。阳邪向阴气化衰，柴芩姜桂草粉蛎。

六、柴胡加龙骨牡蛎汤：柴加龙牡桂丹铅，大黄茯苓记要谙。扣除甘草铅要裹，胸满烦惊小便难。

七、四逆散：柴芍枳草四逆散，肝郁气结肢不暖。脉沉而弦胸胁痛，随证治疗须加减。

## 14．芍药当归汤类方歌（四首）

一、芍药甘草汤：芍药甘草两药投，筋挛拘急足趾抽。苦甘化阴利血统，滋阴柔肝效立瘳。

二、芍药甘草附子汤：芍药甘草附子汤，汗后阴阳两俱伤。恶寒不热应温补，芍甘和阴附助阳。

三、当归四逆汤：当归四逆治厥寒，脉细欲绝病杰出。归芍桂甘枣通细，补血散寒治在肝。

四、当归四逆加吴茱萸生姜汤：当归四逆加萸姜，清酒烹来效始彰。内有久寒厥阴是，药分五次缓服康。

## 15．干姜汤类方歌（三首）

一、干姜附子汤：干姜附子治少阴，阳虚烦躁夜则宁。不呕不渴无表证，身无大热脉微沉。

二、干姜黄芩黄连人参汤：干姜芩连与人参，辛开苦降法超群。四物平行各三两，诸凡格拒此方珍。

三、理中丸（汤）：理中白术与人参，干姜炙草四药亲。脾阳虚衰寒湿甚，腹满吐利脉迟沉。

## 16．赤石脂汤类方（二首）

一、赤石脂禹余粮汤：赤石禹粮两药珍，大便滑脱利不禁。理中不应宜此法，涩以固脱是指针。

二、桃花汤：桃花石脂米干姜，少阴下利脓血方。温固下焦和胃气，汤末搭配力方彰。

## 17．四逆汤类方（九首）

一、四逆汤：四逆生附老干姜，炙草将将有专长。少阴阳虚肢不暖，吐利烦躁欲寐方。

二、四逆加人参汤：四逆加参治何为，下利多时阴亦摧。四逆扶阳参滋血，更取中州化精微。

三、茯苓四逆汤：茯苓四逆少阴虚，心肾阴阳已不支。补阳生附姜甘草，扶阴参苓两药施。

四、通脉四逆汤：通脉四逆草附姜，加重剂量另名方。手足厥逆吐利甚，脉搏不出急回阳。

五、通脉四逆加猪胆汁汤：通脉四逆治亡阳，再加胆汁救阴伤。吐已下断烦呕甚，津液枯竭用此汤。

六、真武汤：真武名汤镇水寒，扶阳法中有心传。附术苓芍生姜共，内惕心悸小便难。

七、白通汤：白通汤治少阴寒，阳虚下利非等闲。葱白四茎姜附一，加入胆尿治呕烦。

八、白通加猪胆汁汤：白通汤治少阴寒，阳虚下利非等闲。葱白四茎姜附一，加入胆尿治呕烦。

九、附子汤：附子汤治背恶寒，脉沉口和阳气残。参附苓术芍药共，更治妊娠腹如扇。

## 18．杂方类方歌（十一首）

一、厚朴生姜半夏甘草人参汤：厚朴夏姜参草寻，善治腹胀妙通神。脾气不运痰气结，三补七消法超群。

二、茵陈蒿汤：茵陈蒿汤治疸黄，阴阳寒热细推详。阳黄大黄栀子入，阴黄附子与干姜。

三、猪肤汤：猪肤斤许用水煎，水煎减半滓须捐。再投粉蜜熬香服，少阴咽痛利且烦。

四、桔梗汤：甘草桔梗治咽痛，消炎解毒妙堪用。阴中伏热结于喉，切忌苦寒投此证。

五、苦酒汤：半夏一枚十四开，鸡清苦酒搅几回。刀环捧壳煎三沸，咽痛频吞绝妙哉。

六、半夏散及汤：半夏研散或用汤，少阴咽痛效最彰。半夏桂甘煎少与，微冷慢呷不用忙。

七、乌梅丸：乌梅丸治蛔厥证，连柏干姜参归用。川椒桂辛与附子，乌梅三百力始胜。

八、白头翁汤：白头翁汤下利寻，黄连黄柏白头秦。识得欲饮属内热，下重难通此方珍。

九、吴茱萸汤：吴茱萸汤暖胃肝，呕吐涎水痛在巅。萸姜人参与大枣，温中降逆治阴寒。

十、烧裈散：近阴裆处剪来烧，研末还须用水调。同气相求疗二易，长沙无法不翘翘。

十一、牡蛎泽泻汤：牡蛎泽泻治如何，下肢肿胀病未瘥。商陆葶苈泻水结，蜀漆海藻破坚邪。
]]></content>
      <categories>
        <category>中医</category>
      </categories>
      <tags>
        <tag>伤寒论</tag>
        <tag>中医</tag>
      </tags>
  </entry>
  <entry>
    <title>形态学总结</title>
    <url>/posts/c1f4dbab.html/</url>
    <content><![CDATA[

## Question

* 开操作和闭操作的作用
* 击中的作用
* 在形态学中如何进行边界提取
* 孔洞填充和连通分量提取的局限性在哪里
* 一般在灰度级的形态学中，结构元的特点
* 顶帽的用途

## 形态学

所有的实现Demo源代码在这里：https://github.com/qcymkxyc/Image-Process

### 腐蚀

腐蚀的作用：

> 腐蚀会清除小于结构元的图像细节，腐蚀比较典型的应用包括去噪、去除断点等

腐蚀的原理：

> 腐蚀会用一个模板（书面的说法是结构元，俗称刷子）依次扫描过图像（类似于滤波），如果该结构元中的非0元素在图像中对应的位置的像素也为非0元素，则该点为1，否则为0。

腐蚀表示为：
$$
A\Theta{B}
$$
以下是腐蚀的原图像：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/腐蚀原图像.png)

腐蚀后的结果为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/腐蚀后的结果.png)

### 膨胀

> 与腐蚀相反，腐蚀的作用是连接断点

膨胀的原理：

> 在结构元扫过的图像时，若重叠部分有超过一个有色的（即模板和对应的像素均大于1），则该点为1

膨胀表示为：
$$
A\bigoplus{B}
$$
以下为原图像：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/膨胀原图像.png)

膨胀后的结果为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/膨胀后的图像.png)

### 开操作和闭操作

书上的对两者作用的解释：

> 开操作一般会平滑物体的轮廓，断开较窄的狭颈并消除细的突出物。闭操作同样也会平滑轮廓的一部分，但与开操作相反，它通常会弥合较窄的间断和细长的沟壑，消除小的孔洞，填补轮廓线中的断裂。

我的理解：

>  虽然腐蚀和膨胀对图像有一定的正向作用，但也有一定的副作用。例如，我们用腐蚀消除噪声，虽然噪声消除了，但也使有些相连的部分断裂了，所以，我们需要用膨胀“还原”
>
> 综上所述，开操作和闭操作的第二步其实就是对 前一步的后处理。两个操作的真正作用在第一步，那么：
>
> * 开操作： 去除小部分，包括椒盐噪声等等
> * 闭操作：连接断点，较大的结构元可以填充孔洞

以下是开操作和闭操作的公式表示,,

* 开操作：

$$
A\circ{B}=(A\Theta{B})\bigoplus{B}
$$

* 闭操作：

$$
A\cdot{B}=(A\bigoplus{B})\Theta{B}
$$

原始图像：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/开操作原图像.png)

开操作结果：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/开操作结果.png)

闭操作结果：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/闭操作结果.png)

### 击中以及不击中

#### 公式说明及理解

> 击中即利用形态学在一幅图中做模板匹配，这在实际应用中相当有用

击中除了需要匹配的模板之外还需要一个模板的补集，才能完成击中。击中的公式表示为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/击中公式1.png)

上式中，$A$表示图像，$B_1$是由与一个目标相联系的$B$的元素构成的集合，$B_2$是由与相应背景相联系的$B$的元素构成的集合。

> 实际上，上式的$B_1$是我们要匹配的模板，$B_2$是一个与模板互为补集的另一个模板

#### 击中实现代码

在OpenCV中没有现成的击中代码，关于击中的核心代码如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hit</span><span class="params">(img:np.ndarray,shape1:np.ndarray,shape2:np.ndarray)</span>:</span></span><br><span class="line">    <span class="string">"""击中"""</span></span><br><span class="line">    <span class="keyword">if</span> shape1.dtype != np.uint8 <span class="keyword">or</span> shape2.dtype != np.uint8:</span><br><span class="line">        <span class="keyword">raise</span> TypeError</span><br><span class="line">        </span><br><span class="line">    part1 = cv2.erode(img,shape1)</span><br><span class="line">    part2 = cv2.erode(<span class="number">1</span> - img, shape2)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> np.logical_and((part1 == part2),part1 == <span class="number">1</span>).astype(int)</span><br></pre></td></tr></table></figure>

#### 击中Demo

图片如下图所示（该图用numpy随机构成）：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/击中原图.png)

公式中的$B_1$如下（实际上模板是白色的矩阵，也就是全是1，不知道为什么用matplotlib显示时，显示的是黑色）：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/击中B1.png)

公式中的$B_2$,$B_2$是在$B_1$的基础上在周围添加$N$个像素，填充为白色（也就是1），以前的$B_1$替换为黑色 （即0），$B_2$如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/击中B2.png)

击中的结果如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/击中的结果.png)

上图中的白点即为击中的位置。

打印的击中位置结果如下 ：

> [(37, 20), (73, 116), (171, 182)]

原结果位置：

> [(37, 20), (73, 116), (171, 182)]

## 边界提取

#### 公式说明

对于形态学而言，边界提取是一件相当简单的事

> 边界提取可以用原图减去腐蚀后的图像，也可以用膨胀后的图像减去腐蚀后的图像

书上是用原图像减去腐蚀后的图像，即：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/边界提取公式.png)

#### Demo

以下是边界提取的原图：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/边界提取原图.png)

提取的结果如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/边界提取结果.png)

### 孔洞填充

#### 公式

孔洞填充的形态学应用不同之前的形态学应用，孔洞填充是一个迭代的过程，当在第$k$次迭代后不再变化则停止。

孔洞填充的第$k$次迭代的公式如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/孔洞填充公式.png)

其中，$A$表示要孔洞填充的图片，$B$表示结构元，$X_{k-1}$表示第$k-1$次迭代的结果。

#### 过程说明

* 首先，在进行形态学的孔洞填充时，我们会给定一个空白的且形状和原图相等的“黑”图（该图的所有像素值均为0），然后找出孔洞填充的起始点，并将该点标为1（即此时该图中仅有一个点的像素值为1，其余的点为0）。该图像即为公式中的$X_1$
* 根据上述公式可以得到$X_2$,以此类推，直到$X_k$和$X_{k-1}$完全相同为止

#### Demo

孔洞填充的核心代码如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">blank_fill</span><span class="params">(img,start_coordination)</span> -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">""""""</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="number">9</span>,<span class="number">9</span>))</span><br><span class="line">    </span><br><span class="line">    last_temp_img = np.zeros_like(img)</span><br><span class="line">    last_temp_img[start_coordination] = <span class="number">1</span></span><br><span class="line">    current_temp_img = cv2.dilate(last_temp_img,kernel)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (current_temp_img != last_temp_img).any():</span><br><span class="line">        last_temp_img = current_temp_img    </span><br><span class="line">        current_temp_img = cv2.dilate(current_temp_img,kernel)</span><br><span class="line"></span><br><span class="line">        current_temp_img = np.logical_and(current_temp_img == <span class="number">1</span>,current_temp_img == (<span class="number">1</span> - img)).astype(float)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> current_temp_img</span><br></pre></td></tr></table></figure>

原图如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/孔洞填充原图.png)

选择（0,27）作为起始的填充点，则填充的结果如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/孔洞填充结果.png)

### 连通分量提取

#### 公式及说明

> 连通分量的限定条件和孔洞填充是相反的，孔洞填充的限定条件是$A^c$,而连通分量提取的限定条件是$A$.因为限定的不同，所造成的结果完全不同。

孔洞填充的公式如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/连通分量提取公式.png)

#### 代码实现

连通分量的核心代码如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">connected_area</span><span class="params">(img,start_coodination)</span> -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">"""提取连通分量"""</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    last_temp_img = np.zeros_like(img)</span><br><span class="line">    last_temp_img[start_coodination] = <span class="number">1</span></span><br><span class="line">    current_temp_img = cv2.dilate(last_temp_img,kernel)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (current_temp_img != last_temp_img).any():</span><br><span class="line">        last_temp_img = current_temp_img    </span><br><span class="line">        current_temp_img = cv2.dilate(current_temp_img,kernel)</span><br><span class="line">        current_temp_img = np.logical_and((current_temp_img == img),current_temp_img == <span class="number">1</span>).astype(float)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> current_temp_img</span><br></pre></td></tr></table></figure>

#### Demo

原图如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/连通分量原图.png)

取坐标（113,57）作为起始坐标点，最终迭代的结果如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/连通分量结果.png)

## 形态学重建

### 测地膨胀

令$D_{G}^{(1)}(F)$表示大小为1的标记图像关于模板的测地膨胀定义为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/测地膨胀公式1.png)

其中$F$表示标记图像，$G$表示模板图像。$F$关于$G$的大小为$n$的测地膨胀定义为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/测地膨胀公式2.png)

### 测地腐蚀

类似有测地膨胀，大小为1的测地腐蚀表示为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/测地腐蚀公式1.png)

$F$关于$G$的大小为$n$的测地腐蚀定义为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/测地腐蚀公式2.png)



**经证明，有限数量的图像的测地膨胀和腐蚀经过有限数量的迭代步骤后总会收敛。**

### 膨胀的形态学重建

> 膨胀的形态学重建即测地膨胀达到稳定状态的结果

所以可以定义膨胀的形态学重建$R_G^D(F)$,实际上就是测地膨胀达到稳定状态的结果（也就是上述所提及的收敛），公式如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/膨胀形态学重建公式.png)

即测地膨胀迭代$k$次，直至$D_G^{(k)}(F)=D_G^{(k+1)}(F)$,停止迭代

### 腐蚀的形态学重建

腐蚀的形态学重建基本上同膨胀的重建，公式表示为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/腐蚀的形态学重建公式.png)

其中，停止的条件为$E_G^{(k)}(F)=E_G^{(k+1)}(F)$

### 重建开操作

>  同普通的开操作，重建开操作也用于删除一些小的物体（例如椒盐噪声）。

重建开操作的公式如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/重建开操作公式.png)

其中，$F\Theta{nB}$表示$B$对$F$的$n$次腐蚀

#### 实现

核心 代码如下 ：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rebuild_open</span><span class="params">(img:np.ndarray,kernel:np.ndarray,erode_time:int = <span class="number">1</span>)</span> -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="string">"""多次腐蚀"""</span></span><br><span class="line">    temp_img = img.copy()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(erode_time):</span><br><span class="line">        temp_img = cv2.erode(temp_img,kernel)</span><br><span class="line">        </span><br><span class="line">    <span class="string">"""测地膨胀"""</span></span><br><span class="line">    dialate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">    last_img = temp_img.copy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        current_img = cv2.dilate(last_img,dialate_kernel)</span><br><span class="line">        current_img  = np.logical_and(current_img  == <span class="number">1</span>,current_img == img)</span><br><span class="line">        current_img = current_img.astype(float)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (current_img ==  last_img).all():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            last_img = current_img</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> current_img</span><br></pre></td></tr></table></figure>

#### Demo

该Demo用于提取垂直笔画的长字符。

原图片如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/重建开操作原图.png)

在进行了一次腐蚀的重建开操作后的结果为：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/重建开操作结果.png)

## 灰度形态学

灰度的形态学基本上同，但有以下不同：

* 灰度的形态学的结构元基本上是圆形
* 腐蚀和膨胀的规则稍有不同

### 灰度腐蚀

灰度腐蚀定义为图像$f$和结构元$b$重合区域的**最小值**,灰度腐蚀的公式如下所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/灰度腐蚀公式.png)

### 灰度膨胀

 相反，灰度膨胀定义为图像$f$和结构元$b$重合区域的**最大值**，灰度膨胀公式如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/灰度膨胀公式.png)

### 灰度开操作和闭操作

#### 公式

灰度的开操作和闭操作完全同二值图像的开操作和闭操作，公式如下：

* 灰度开操作：![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/灰度开操作公式.png)

* 灰度闭操作：![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/灰度闭操作公式.png)

#### 作用

灰度开操作和闭操作的作用：

> * 开操作会使亮度高的区域平滑
> * 闭操作会使亮度低的区域平滑

#### Demo

以下是原图：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/灰度原图.png)

用半径为3的结构元进行开操作得到的结果：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/灰度开操作结果.png)

用半径为5的结构元进行闭操作得到的结果 ：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/灰度闭操作结果.png)

### 灰度形态学梯度

#### 公式

灰度的形态学梯度很像在二值图像中的边界提取，公式如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/形态学梯度公式.png)

#### Demo

原图：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/形态学梯度原图.png)

提取的梯度结果：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/形态学梯度结果.png)

### 顶帽和底帽变换

#### 公式

**顶帽变换的一个重要用途是校正不均匀光照的影响，通过顶帽变换，背景应会变得均匀**

顶帽和底帽变换的公式如下：

* 顶帽变换：![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/顶帽公式.png)
* 底帽变换：![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/底帽公式.png)

#### Demo

该Demo是从以下图中选出米粒。如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/顶帽原图.png)

通过一系列变换，最终分离出的米粒如下图中最右图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/顶帽结果.png)

上图中，第1幅图为原图像（即最左面的图像）。第2幅图是通过一个全局阈值分离出的米粒，可以看到左上角并未明显的分离。第3幅图是将原图进行开操作的结果，所用的结构元为半径为40的圆形结构元。第4幅图是顶帽操作的结果。第5幅图对第4幅图进行阈值分离的结果，可以看到米粒更加清晰的分离出来。但第5幅图中发现有噪声存在，所以需要对该图去噪 ，第6幅图是对第5幅图进行腐蚀后的结果。

### 纹理分割

> 纹理分割是用于分离不同形状不同大小的图形

#### Demo

该 Demo用来分离下图中大小两个不同圆，从而在两个圆之间形成一条分割线。

用于纹理分割的原图如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/纹理分割原图.png)

如果我们用一个半径在大圆和小圆的之间的结构元进行闭操作，这样会填平小的圆。下图 图2表示以50为半径的圆形结构元进行闭操作的结果。要想形成一条明显的分割线我们对图2做开操作，只要开操作的结构元足够大，那么右半部分黑色圆的空隙就会被填平，这里选用半径为100的结构元进行开操作，得到 的结果如下图3所示。图4表示将图3加入原图得到的分割曲线。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/纹理分割结果.png)

## 参考

> * 冈萨雷斯版《数字图像处理》]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>Demo</tag>
      </tags>
  </entry>
  <entry>
    <title>骨架算法</title>
    <url>/posts/311496b5.html/</url>
    <content><![CDATA[
## Question

## 概述

骨架算法是什么？

> 下图中，左图是书法字，右图是骨架后的结果<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/示例对比.png" style="zoom: 67%;">

骨架算法有什么用？

> 例如，在基于毛笔OCR识别中，通常会使用字的骨架进行识别，而非原图像

## 骨架算法

### 什么是好的骨架算法

好的骨架算法必须满足以下三点：

* 不能删除端点
* 不能破坏连接性
* 不能导致区域过度腐蚀

### 基于MAT（中轴变换）的一种实现

基于MAT思想认为骨架为一条线最中间的部分（例如上图中一竖，他对应的骨架就是这一竖最中间的像素点组成的一条线）。那么，该骨架满足该条线上的点到两个边缘的距离是相等的。

此时，一个很自然的形成骨架的算法是：对于一个笔画，我们从边缘等量的向中轴减少像素点，直到中轴上的仅有一个像素点宽，自然而然的就是该笔画的骨架了。

下面是一个基于MAT思想算法实现的代码：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@decorators.func_output_type_check()</span></span><br><span class="line"><span class="meta">@decorators.func_input_type_check()</span></span><br><span class="line"><span class="meta">@decorators.input_shape_check(0, (3, 3))</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__mat_process_first</span><span class="params">(around_area: np.ndarray)</span> -&gt; bool:</span></span><br><span class="line">    <span class="string">"""MAT算法步骤1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    对于相邻像素区域：</span></span><br><span class="line"><span class="string">    [</span></span><br><span class="line"><span class="string">        [p9,p2,p3],</span></span><br><span class="line"><span class="string">        [p8,p1,p4],</span></span><br><span class="line"><span class="string">        [p7,p6,p5]</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">    包括以下几个部分：</span></span><br><span class="line"><span class="string">    a. 2 &lt;=非零像素个数 &lt;= 6</span></span><br><span class="line"><span class="string">    b. 顺时针跳数 = 1</span></span><br><span class="line"><span class="string">    c. p2 * p4 * p6 = 0</span></span><br><span class="line"><span class="string">    d. p4 * p6 * p8 = 0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param around_area: numpy.array, 一个像素的相邻像素，为3*3</span></span><br><span class="line"><span class="string">    :return: bool，是否满足以上所有条件</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    result_list = list()    <span class="comment"># 保存所有步骤是否符合条件</span></span><br><span class="line">    <span class="string">"""步骤a"""</span></span><br><span class="line">    near_one_count = __near_pix_equal_one_count(around_area)</span><br><span class="line">    result_list.append(<span class="number">2</span> &lt;= near_one_count &lt;= <span class="number">6</span>)</span><br><span class="line">    <span class="string">"""步骤b"""</span></span><br><span class="line">    result_list.append(__binary_transform_count(around_area) == <span class="number">1</span>)</span><br><span class="line">    <span class="string">"""步骤c"""</span></span><br><span class="line">    pix_2 = around_area[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    pix_4 = around_area[<span class="number">1</span>][<span class="number">2</span>]</span><br><span class="line">    pix_6 = around_area[<span class="number">2</span>][<span class="number">1</span>]</span><br><span class="line">    result_list.append(pix_2 * pix_4 * pix_6 == <span class="number">0</span>)</span><br><span class="line">    <span class="string">"""步骤d"""</span></span><br><span class="line">    pix_8 = around_area[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">    result_list.append(pix_4 * pix_6 * pix_8 == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bool(reduce(<span class="keyword">lambda</span> x, y: x <span class="keyword">and</span> y, result_list))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__mat_process_second</span><span class="params">(around_area: np.ndarray)</span> -&gt; bool:</span></span><br><span class="line">    <span class="string">"""MAT算法步骤2</span></span><br><span class="line"><span class="string">    对于相邻像素区域：</span></span><br><span class="line"><span class="string">    [</span></span><br><span class="line"><span class="string">        [p9,p2,p3],</span></span><br><span class="line"><span class="string">        [p8,p1,p4],</span></span><br><span class="line"><span class="string">        [p7,p6,p5]</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">    包括以下几个部分：</span></span><br><span class="line"><span class="string">    a. 2 &lt;=非零像素个数 &lt;= 6</span></span><br><span class="line"><span class="string">    b. 顺时针跳数 = 1</span></span><br><span class="line"><span class="string">    c. p2 * p4 * p8 = 0</span></span><br><span class="line"><span class="string">    d. p2 * p6 * p8 = 0</span></span><br><span class="line"><span class="string">    :param around_area: numpy.array, 周围的区域</span></span><br><span class="line"><span class="string">    :return: bool,是否全部子条件</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    result_list = list()    <span class="comment"># 保存所有步骤是否符合条件</span></span><br><span class="line">    <span class="string">"""步骤a"""</span></span><br><span class="line">    near_one_count = __near_pix_equal_one_count(around_area)</span><br><span class="line">    result_list.append(<span class="number">2</span> &lt;= near_one_count &lt;= <span class="number">6</span>)</span><br><span class="line">    <span class="string">"""步骤b"""</span></span><br><span class="line">    result_list.append(__binary_transform_count(around_area) == <span class="number">1</span>)</span><br><span class="line">    <span class="string">"""步骤c"""</span></span><br><span class="line">    pix_2 = around_area[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    pix_4 = around_area[<span class="number">1</span>][<span class="number">2</span>]</span><br><span class="line">    pix_8 = around_area[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">    pix_6 = around_area[<span class="number">2</span>][<span class="number">1</span>]</span><br><span class="line">    result_list.append(pix_2 * pix_4 * pix_8 == <span class="number">0</span>)</span><br><span class="line">    <span class="string">"""步骤d"""</span></span><br><span class="line">    result_list.append(pix_2 * pix_6 * pix_8 == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bool(reduce(<span class="keyword">lambda</span> x, y: x <span class="keyword">and</span> y, result_list))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@decorators.func_output_type_check()</span></span><br><span class="line"><span class="meta">@decorators.func_input_type_check()</span></span><br><span class="line"><span class="meta">@decorators.input_shape_check(0, (3, 3))</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__near_pix_equal_one_count</span><span class="params">(around_area: np.ndarray)</span> -&gt; int or np.int:</span></span><br><span class="line">    <span class="string">"""计算相邻像素中为1的个数(不包括中间点)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    即，对于相邻像素区域：</span></span><br><span class="line"><span class="string">    [</span></span><br><span class="line"><span class="string">        [p9,p2,p3],</span></span><br><span class="line"><span class="string">        [p8,p1,p4],</span></span><br><span class="line"><span class="string">        [p7,p6,p5]</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">    统计出p1之外所有的1的个数</span></span><br><span class="line"><span class="string">    :param around_area: numpy.array, 一个像素的相邻像素，为3*3</span></span><br><span class="line"><span class="string">    :return int,像素为1的个数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    temp_around_area = np.copy(around_area)</span><br><span class="line">    temp_around_area[<span class="number">1</span>][<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> int(np.sum(temp_around_area, dtype=np.int))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@decorators.input_shape_check(0, (3, 3))</span></span><br><span class="line"><span class="meta">@decorators.func_input_type_check()</span></span><br><span class="line"><span class="meta">@decorators.func_output_type_check()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__binary_transform_count</span><span class="params">(around_area: np.ndarray)</span> -&gt; int or np.int:</span></span><br><span class="line">    <span class="string">"""给定一个3*3的二进制图片，获取其顺时针的跳数（从0到1）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    即，对于相邻像素区域：</span></span><br><span class="line"><span class="string">    [</span></span><br><span class="line"><span class="string">        [p9,p2,p3],</span></span><br><span class="line"><span class="string">        [p8,p1,p4],</span></span><br><span class="line"><span class="string">        [p7,p6,p5]</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">    以p9,p2,p3,p4,p5,p6,p7,p8的顺序访问，如果是0到1，则为一跳</span></span><br><span class="line"><span class="string">    :param around_area: numpy.array, 一个像素的相邻像素，为3*3</span></span><br><span class="line"><span class="string">    :return int, 顺时针跳数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next_index</span><span class="params">(current_coor: <span class="params">(int, int)</span>)</span> -&gt; (int, int):</span></span><br><span class="line">        <span class="string">"""给定当前位置，返回下一个位置</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param current_coor: (int,int),当前位置</span></span><br><span class="line"><span class="string">        :return: (int,int), 下一个位置</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="string">'''四个方向的下一个位置'''</span></span><br><span class="line">        right_next = (current_coor[<span class="number">0</span>], current_coor[<span class="number">1</span>] + <span class="number">1</span>)</span><br><span class="line">        down_next = (current_coor[<span class="number">0</span>] + <span class="number">1</span>, current_coor[<span class="number">1</span>])</span><br><span class="line">        left_next = (current_coor[<span class="number">0</span>], current_coor[<span class="number">1</span>] - <span class="number">1</span>)</span><br><span class="line">        up_next = (current_coor[<span class="number">0</span>] - <span class="number">1</span>, current_coor[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="string">"""按照指定的规则寻找，不报错则表示正确的方向"""</span></span><br><span class="line">        next_coordinate_list = [right_next, down_next, left_next, up_next]</span><br><span class="line">        <span class="keyword">for</span> i, next_coordinate <span class="keyword">in</span> enumerate(next_coordinate_list):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                around_area[next_coordinate]</span><br><span class="line">            <span class="keyword">except</span> IndexError:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="string">'''如果该点已经走过'''</span></span><br><span class="line">                <span class="keyword">if</span> is_walked[next_coordinate[<span class="number">0</span>], next_coordinate[<span class="number">1</span>]]:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    is_walked[next_coordinate[<span class="number">0</span>], next_coordinate[<span class="number">1</span>]] = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">return</span> next_coordinate</span><br><span class="line"></span><br><span class="line">    is_walked = np.full_like(around_area, <span class="literal">False</span>)  <span class="comment"># 用于标识该点是否已经走过</span></span><br><span class="line">    is_walked[<span class="number">1</span>][<span class="number">1</span>] = <span class="literal">True</span></span><br><span class="line">    transform_count = <span class="number">0</span>  <span class="comment"># 用于记录跳数</span></span><br><span class="line">    <span class="string">"""循环对比"""</span></span><br><span class="line">    last_pix = around_area[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># 上一个的值</span></span><br><span class="line">    current_coordinate = (<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">while</span> current_coordinate != (<span class="number">0</span>, <span class="number">0</span>):</span><br><span class="line">        current_pix = around_area[current_coordinate[<span class="number">0</span>], current_coordinate[<span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">if</span> last_pix == <span class="number">0</span> <span class="keyword">and</span> current_pix == <span class="number">1</span>:</span><br><span class="line">            transform_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        last_pix = current_pix</span><br><span class="line">        current_coordinate = __next_index(current_coordinate)</span><br><span class="line"></span><br><span class="line">    <span class="string">'''当循环到第一个点时再对比一次'''</span></span><br><span class="line">    current_pix = around_area[current_coordinate[<span class="number">0</span>], current_coordinate[<span class="number">0</span>]]</span><br><span class="line">    <span class="keyword">if</span> last_pix == <span class="number">0</span> <span class="keyword">and</span> current_pix == <span class="number">1</span>:</span><br><span class="line">        transform_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transform_count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@decorators.func_input_type_check()</span></span><br><span class="line"><span class="meta">@decorators.func_output_type_check()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__remove_pix_by_coordination</span><span class="params">(img: np.ndarray, points: list)</span>:</span></span><br><span class="line">    <span class="string">"""给定坐标的list，删除图像上的点（实际就是标记为0）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param img: numpy.array,图像</span></span><br><span class="line"><span class="string">    :param points: List[(int,int)]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">for</span> single_coordination <span class="keyword">in</span> points:</span><br><span class="line">        i_row, i_col = single_coordination</span><br><span class="line">        img[i_row][i_col] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__get_remove_points</span><span class="params">(img: np.ndarray, func)</span> -&gt; [(int, int)]:</span></span><br><span class="line">    <span class="string">"""给定图像以及，删除点的规则，返回要删除的点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param img: numpy.array, 原图像</span></span><br><span class="line"><span class="string">    :param func: function, 规则，也就是一个函数</span></span><br><span class="line"><span class="string">    :return: List[（int,int）],坐标的list</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    remove_points_list = list()</span><br><span class="line">    temp_img = img</span><br><span class="line">    img_iter = np.nditer(temp_img, flags=[<span class="string">"multi_index"</span>])</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> img_iter.finished:</span><br><span class="line">        current_pix = img_iter[<span class="number">0</span>]</span><br><span class="line">        i_row, i_col = img_iter.multi_index</span><br><span class="line">        img_iter.iternext()</span><br><span class="line">        <span class="string">'''如果是背景点则直接跳过'''</span></span><br><span class="line">        <span class="keyword">if</span> current_pix != <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="string">"""如果是前景点"""</span></span><br><span class="line">        around_area = temp_img[i_row - <span class="number">1</span>:i_row + <span class="number">2</span>, i_col - <span class="number">1</span>:i_col + <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> func(around_area):</span><br><span class="line">            remove_points_list.append((i_row, i_col))</span><br><span class="line"></span><br><span class="line">        img_iter.iternext()</span><br><span class="line">    <span class="keyword">return</span> remove_points_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@decorators.func_input_type_check()</span></span><br><span class="line"><span class="meta">@decorators.func_output_type_check()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_img_skeleton_by_mat</span><span class="params">(img: np.ndarray)</span> -&gt; np.ndarray:</span></span><br><span class="line">    <span class="string">"""根据字体的图像得到字的骨架</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param img, numpy.array, 原图片</span></span><br><span class="line"><span class="string">    :raise ValueError</span></span><br><span class="line"><span class="string">        - 图片不为单通道</span></span><br><span class="line"><span class="string">        - 图片并未归一化</span></span><br><span class="line"><span class="string">        - 图片并未标准化</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="string">'''检验图片是否是单通道'''</span></span><br><span class="line">    <span class="keyword">if</span> len(img.shape) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"该图片不是单通道"</span>)</span><br><span class="line">    <span class="string">"""检验标准化"""</span></span><br><span class="line">    <span class="keyword">if</span> img.max() &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"该图片并未标准化"</span>)</span><br><span class="line">    <span class="string">"""检验二值化"""</span></span><br><span class="line">    <span class="keyword">if</span> (np.unique(img.flatten()) != (<span class="number">0</span>, <span class="number">1</span>)).all():</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"该函数并未二值化"</span>)</span><br><span class="line"></span><br><span class="line">    temp_img = img.copy()</span><br><span class="line">    <span class="string">"""遍历每一个像素点"""</span></span><br><span class="line">    is_remove_flag = <span class="literal">True</span>  <span class="comment"># 表示是否继续删除的标志</span></span><br><span class="line">    i_round = <span class="number">1</span>  <span class="comment"># 记录迭代的轮数</span></span><br><span class="line">    <span class="keyword">while</span> is_remove_flag:</span><br><span class="line">        is_remove_flag = <span class="literal">False</span></span><br><span class="line">        logger.info(<span class="string">"正在执行MAT算法的第&#123;&#125;轮"</span>.format(i_round))</span><br><span class="line">        <span class="string">"""执行步骤1"""</span></span><br><span class="line">        remove_points = __get_remove_points(temp_img, __mat_process_first)</span><br><span class="line">        <span class="keyword">if</span> len(remove_points) != <span class="number">0</span>:</span><br><span class="line">            is_remove_flag = <span class="literal">True</span></span><br><span class="line">            __remove_pix_by_coordination(temp_img, remove_points)</span><br><span class="line"></span><br><span class="line">        <span class="string">"""执行步骤2"""</span></span><br><span class="line">        remove_points = __get_remove_points(temp_img, __mat_process_second)</span><br><span class="line">        <span class="keyword">if</span> len(remove_points) != <span class="number">0</span>:</span><br><span class="line">            is_remove_flag = <span class="literal">True</span></span><br><span class="line">            __remove_pix_by_coordination(temp_img, remove_points)</span><br><span class="line"></span><br><span class="line">        i_round += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> temp_img</span><br></pre></td></tr></table></figure>

## 参考

* 《数字图像处理》 冈萨雷斯版]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>MCMC</title>
    <url>/posts/90e44d07.html/</url>
    <content><![CDATA[

## Question

* 蒙特卡洛采样的作用
* Inverse Sampling的适用范围
* Inverse Sampling的过程
* Rejection Sampling的大致思想
* Rejection Sampling的流程
* 什么是影响Rejection Sampling效率的关键因素
* Importance Sampling的大致思想
* Importance Sampling的流程

## 蒙特卡洛采样

### 蒙特卡洛的作用（引子）

当我们要计算函数$f(x)$的期望时,有：
$$
E[f(z)]=\int{P(z)f(z) \, {\rm dx}} \\
\approx\frac{1}{N}\sum_{i=1}^{N}f(z_i)
$$

> 如果是$z_i$是一个已知的分布，我们可以直接从上面采样（比如高斯分布，均匀分布），获得$z$，然后计算期望值$E[f(z)]$,但如果是一个不规则的分布，我们无法直接从上面采样，蒙特卡洛采样的目的就是解决求函数$f(z)$的期望。

**总而言之，蒙特卡洛采样就是对于一个非常罕见.**

**的分布解决怎样采样的问题**



蒙特卡洛采样有许多种，常用的有以下几种：

### Inverse Sampling

> Inverse Sampling(逆采样)适用于**累积分布函数已知（可求得）**的情况，例如高斯分布，指数分布等

首先介绍均匀分布的采样，因为**所有Inverse Sampling都是根据均匀分布而来**：

**均匀分布的采样可以看成生成一定范围的随机数**（比如（0,1）的均匀分布采样可以看成在（0,1）之间生成随机数），每一个数生成的可能都是相等的。

此时，均匀分布的采样问题就变成了随机数的生成问题。

在计算机中，**伪随机数**的生成过程如下：
$$
x_{n+1}=(ax_n+c) \, \rm mod \,  m
$$
其中，$m$表示均匀分布的范围，$a$和$c$是数学推导出的常数，$x_n$表示当前值。**伪随机数是通过当前值计算下一个值**，以此递推。

至此，我们就能在均匀分布上采样了。



但对于其他分布如何采样呢？

> Inverse Sampling是将概率密度函数转换为累积分布函数（CDF），然后利用CDF反映射求得采样值

具体过程如下：

* 对要采样的分布$P(x)$计算其累积分布函数(CDF)-$F$(x)
* 求出$F(x)$的反函数$F^{-1}(y)$
* 在一个均匀分布$U(0,1)$中采样，得到$y_i$,再通过$F^{-1}(y)$计算得到$x_i$

$x_i$即为采样得到的值

构建的PDF如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/Inverse-Sampling.png)



但对于无法求得CDF的分布，Inverse Sampling无能为力，以下两种方法是解决CDF无法计算的情况下的采样方式。

### Rejection Sampling

>  Rejection Sampling的大致思想是用一个已知的分布来辅助未知的分布采样。

流程如下：

设我们需要采样的未知分布为$P(z)$

* 预设一个已知的分布$z$服从于一个已知分布$Q(z)$,(例如$Q(z)$为一个正态分布)

* 对于$\forall{z}$ 服从于$Q(z)$,给定一个正数$m$,有$mQ(z)\geq{P(z)}$

* 在$Q(z)$中采样得到采样的结果为$z_{i}$

* 计算接收率$\alpha=\frac{P(z_{i})}{mQ(z_{i})}$(接收率即分布$P(z)$占$mQ(z)$的比例,且有$0\leq\alpha\leq1$)

* 设有变量$u$服从于均匀分布$U(0,1)$,并从$u$中采样得到$u_i$

* 如果$u_i\leq{\alpha}$,则接受$z_{i}$,否则拒绝$z_{i}$,即
  $$
  \begin{cases} accept, & if \, {\rm u_{i}}\leq{z_i} \\ reject ,& other \end{cases}
  $$
  



两个分布的情况如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/Rejection-Sampling.png)

**注:**

> * $m$的值越大，会导致接收率$\alpha$的值越小，采样的效率也就会越低。所以，应该在满足条件的情况下尽量小的选择$m$的值
> * 分布的维数越高，采样的效率也会越低
> * 分布$Q$和分布$P$越接近，采样的效率也越高

### Importance Sampling

> Importance Sampling是用两个分布的比例作为采样的权重来辅助未知分布的采样

函数期望$E[f(z)]$可写成：
$$
E[f(z)] = \int{P(z)f(z)dz}
$$
设有一个已知的分布$Q(Z)$，有:
$$
E[f(z)]=\int{\frac{P(z)}{Q(z)}Q(z)\cdot f(z) \, \rm dz} \\
\approx\frac{1}{N}\sum_{i=1}^{N}{f(z_i)\frac{P(z_i)}{Q(z_i)}}
$$
其中,$z_i$服从于分布$Q(z)$。也就是说，$z_i$是从$P(Z)$中采样而来。



> * $\frac{P(Z)}{Q(Z)}$ 实际上是一个权值，它代表的是两个分布的相近程度，也就是重要程度，故该采样的叫Importance Sampling
> * $P(Z)$和$Q(Z)$两个分布越接近，采样的效率越高



## MCMC

马氏链经过若干步之后会形成平稳分布（平稳分布是在某一步之后分布不在变化）

## 参考

> * https://www.cnblogs.com/daniel-D/p/3388724.html
> * 白板机器学习系列：MCMC



]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>统计</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow Dataset模块笔记</title>
    <url>/posts/df0579b5.html/</url>
    <content><![CDATA[

## 基本用法

### 创建一个datasets：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">datasets = tf.data.DataSets.from_tensor_slices([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">datasets</span><br></pre></td></tr></table></figure>

### 遍历datasets：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> elem <span class="keyword">in</span> dataset:</span><br><span class="line">  print(elem.numpy())</span><br></pre></td></tr></table></figure>

### 迭代器单独取出datasets中的数：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">it = iter(dataset)</span><br><span class="line"></span><br><span class="line">print(next(it).numpy())</span><br></pre></td></tr></table></figure>

### reduce函数

dataset可以用类似于spark中的map、reduce计算结果**（但用法略有不同）**

> reduce函数的第一个参数就是后面lambda函数的state，然后reduce函数会遍历datasets中的每一个元素，转换为lambda函数中的value，直到返回结果。

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">datasets = tf.data.DataSets.from_tensor_slices([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">print(dataset.reduce(<span class="number">0</span>, <span class="keyword">lambda</span> state, value: state + value).numpy())</span><br></pre></td></tr></table></figure>

### map函数

> map函数也是同样的道理

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = dataset.map(<span class="keyword">lambda</span> x:x**<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> elem <span class="keyword">in</span> y:</span><br><span class="line">    print(elem.numpy())</span><br></pre></td></tr></table></figure>

## 数据的结构

### TypeSpec

通过数据的element_spec属性可以看数据的Type

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([<span class="number">4</span>, <span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line">dataset1.element_spec</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果为：</span></span><br><span class="line"><span class="comment"># TensorSpec(shape=(10,), dtype=tf.float32, name=None)</span></span><br></pre></td></tr></table></figure>

### 数据的合并

多个子数据集可以合并成为一个总的数据集，**这些子数据集可以有不同的TypeSpec**

> 通过zip函数即可合并

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset1 = tf.data.Dataset.from_tensor_slices(</span><br><span class="line">    tf.random.uniform([<span class="number">4</span>, <span class="number">10</span>], minval=<span class="number">1</span>, maxval=<span class="number">10</span>, dtype=tf.int32))</span><br><span class="line">    </span><br><span class="line">dataset2 = tf.data.Dataset.from_tensor_slices(</span><br><span class="line">   (tf.random.uniform([<span class="number">4</span>]),</span><br><span class="line">    tf.random.uniform([<span class="number">4</span>, <span class="number">100</span>], maxval=<span class="number">100</span>, dtype=tf.int32)))</span><br><span class="line"></span><br><span class="line">dataset3 = tf.data.Dataset.zip((dataset1, dataset2))</span><br><span class="line"></span><br><span class="line"><span class="string">'''打印数据'''</span></span><br><span class="line"><span class="keyword">for</span> a, (b,c) <span class="keyword">in</span> dataset3:</span><br><span class="line">  print(<span class="string">'shapes: &#123;a.shape&#125;, &#123;b.shape&#125;, &#123;c.shape&#125;'</span>.format(a=a, b=b, c=c))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果为</span></span><br><span class="line">shapes: (<span class="number">10</span>,), (), (<span class="number">100</span>,)</span><br><span class="line">shapes: (<span class="number">10</span>,), (), (<span class="number">100</span>,)</span><br><span class="line">shapes: (<span class="number">10</span>,), (), (<span class="number">100</span>,)</span><br><span class="line">shapes: (<span class="number">10</span>,), (), (<span class="number">100</span>,)</span><br></pre></td></tr></table></figure>

## 读取输入数据

### 方式一：直接从Numpy读取

如果数据足够小，最简单也最便捷的方式是直接从numpy中读取，调用`  from_tensor_slices`即可

### 方式二：用生成器读取

由于内存的限制，所以大部分情况下，我们都会从generator中读取，**但此方式有一定的局限性**，有以下几点需要注意：

> * 只能在同一进程下写一个生成器
> * 需要遵守[GIL](https://en.wikipedia.org/wiki/Global_interpreter_lock).

调用`tf.data.Dataset.from_generator`即可

关于`from_generator`函数：

> * args必须要用list，起码是一个iter
> * output_types是必选参数，官方的解释是tf.data模块会在内部生成一个`tf.Graph`,而`tf.Graph`需要`tf.dtype`

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">(stop)</span>:</span></span><br><span class="line">  i = <span class="number">0</span></span><br><span class="line">  <span class="keyword">while</span> i&lt;stop:</span><br><span class="line">    <span class="keyword">yield</span> i</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 如果generator的参数仅有一个，则args外层也一定要加一个list包住，否则报错</span></span><br><span class="line">ds_counter = tf.data.Dataset.from_generator(count, args=[<span class="number">25</span>], output_types=tf.int32, output_shapes = (), )  </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> count_batch <span class="keyword">in</span> ds_counter.repeat().batch(<span class="number">10</span>).take(<span class="number">10</span>):</span><br><span class="line">  print(count_batch.numpy())</span><br></pre></td></tr></table></figure>

* `repeat`表示该生成器循环多少次，如果不填，则表示一直循环

* `batch`表示一次循环取多少个数据

* `take`表示基于前面的结果一次取多少个数据



### 方式三：TFRecord

## Batch Data

### Simple Batch

> 最简单的方式就是调用batch函数，batch中的值表示一个batch取几个，代码如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inc_dataset = tf.data.Dataset.range(<span class="number">100</span>)</span><br><span class="line">dec_dataset = tf.data.Dataset.range(<span class="number">0</span>, <span class="number">-100</span>, <span class="number">-1</span>)</span><br><span class="line">dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))</span><br><span class="line">batched_dataset = dataset.batch(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> batched_dataset.take(<span class="number">4</span>):</span><br><span class="line">  print([arr.numpy() <span class="keyword">for</span> arr <span class="keyword">in</span> batch])</span><br></pre></td></tr></table></figure>

>  如果在取batch的过程中想忽略掉最后一个batch(因为最后一个数可能数据不齐)，则加入参数`drop_remainder`即可。

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batched_dataset = dataset.batch(<span class="number">7</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">batched_dataset</span><br></pre></td></tr></table></figure>

### Batching tensors with padding

>  当遇到输入数据的维度不齐时，可以调用` padded_batch`函数，该函数可以将不整齐的输入数据补齐，如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = tf.data.Dataset.range(<span class="number">100</span>)</span><br><span class="line">dataset = dataset.map(<span class="keyword">lambda</span> x: tf.fill([tf.cast(x, tf.int32)], x))</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> dataset.take(<span class="number">5</span>):</span><br><span class="line">  print(batch.numpy())</span><br><span class="line">  print()</span><br><span class="line">    </span><br><span class="line">print(<span class="string">"==================================="</span>)</span><br><span class="line">dataset = dataset.padded_batch(<span class="number">4</span>, padded_shapes=(<span class="literal">None</span>,))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> dataset.take(<span class="number">2</span>):</span><br><span class="line">  print(batch.numpy())</span><br><span class="line">  print()</span><br></pre></td></tr></table></figure>

 结果为：

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[]</span><br><span class="line"></span><br><span class="line">[1]</span><br><span class="line"></span><br><span class="line">[2 2]</span><br><span class="line"></span><br><span class="line">[3 3 3]</span><br><span class="line"></span><br><span class="line">[4 4 4 4]</span><br><span class="line"></span><br><span class="line">===================================</span><br><span class="line">[[0 0 0]</span><br><span class="line"> [1 0 0]</span><br><span class="line"> [2 2 0]</span><br><span class="line"> [3 3 3]]</span><br><span class="line"></span><br><span class="line">[[4 4 4 4 0 0 0]</span><br><span class="line"> [5 5 5 5 5 0 0]</span><br><span class="line"> [6 6 6 6 6 6 0]</span><br><span class="line"> [7 7 7 7 7 7 7]]</span><br></pre></td></tr></table></figure>

##  Training workflows

### Processing multiple epochs

> repeat函数即可实现epoch循环

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_batch_sizes</span><span class="params">(ds)</span>:</span></span><br><span class="line">  batch_sizes = [batch.shape[<span class="number">0</span>] <span class="keyword">for</span> batch <span class="keyword">in</span> ds]</span><br><span class="line">  plt.bar(range(len(batch_sizes)), batch_sizes)</span><br><span class="line">  plt.xlabel(<span class="string">'Batch number'</span>)</span><br><span class="line">  plt.ylabel(<span class="string">'Batch size'</span>)</span><br><span class="line"></span><br><span class="line">titanic_file = tf.keras.utils.get_file(<span class="string">"train.csv"</span>, <span class="string">"https://storage.googleapis.com/tf-datasets/titanic/train.csv"</span>)</span><br><span class="line">titanic_lines = tf.data.TextLineDataset(titanic_file)</span><br><span class="line"></span><br><span class="line">titanic_batches = titanic_lines.repeat(<span class="number">3</span>).batch(<span class="number">128</span>)</span><br><span class="line">plot_batch_sizes(titanic_batches)</span><br></pre></td></tr></table></figure>

得到的结果如下图所示：

![](Tensorflow-Dataset模块笔迹/1.png)

教程中还提到另外一种方式：

![](Tensorflow-Dataset模块笔迹/2.png)

###  Randomly shuffling input data

调用`shuffle`函数即可，这里重点说明一下`shuffle`函数中的`buffer_size`参数：

tensorflow中的打乱顺序是通过采样实现的。也就是说，给定一个`batch_size`，在数据集中抽取这么多个（`batch_size`个数据）数据，从而达到打乱顺序的目的。但有时候，原数据集太大，这么抽很耗时，所以就有了`buffer`，buffer的作用是代替原数据集来进行抽样，即`batch`中的数据是从`buffer`里面抽，这个buffer越大，越能够代表原数据集，所以`buffer_size`参数实际上是代表`buffer`的大小的。

以下是原文：

> This dataset fills a buffer with `buffer_size` elements, then randomly
> samples elements from this buffer, replacing the selected elements with new
> elements. For perfect shuffling, a buffer size greater than or equal to the
> full size of the dataset is required.
> 
> For instance, if your dataset contains 10,000 elements but `buffer_size` is
> set to 1,000, then `shuffle` will initially select a random element from
> only the first 1,000 elements in the buffer. Once an element is selected,
> its space in the buffer is replaced by the next (i.e. 1,001-st) element,
> maintaining the 1,000 element buffer.

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lines = tf.data.TextLineDataset(titanic_file)</span><br><span class="line">counter = tf.data.experimental.Counter()</span><br><span class="line"></span><br><span class="line">dataset = tf.data.Dataset.zip((counter, lines))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">100</span>)</span><br><span class="line">dataset = dataset.batch(<span class="number">20</span>)</span><br><span class="line">dataset</span><br></pre></td></tr></table></figure>

## Preprocessing data

### 数据map

见 [map函数](#map函数)

### py_function函数

> `py_function`使得tensorflow可以调用非tensorflow库，如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">tf.py_function(f,[x],[tf.int32])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>编程</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>产品笔记</title>
    <url>/posts/e989d30a.html/</url>
    <content><![CDATA[

## 产品文章

* [B端和C端的本质区别](https://www.zhihu.com/question/36016196/answer/311844945?utm_source=cn.ticktick.task&utm_medium=social&utm_oi=734158589647675392)

* [2B中产品和定制的利弊权衡](http://www.woshipm.com/operate/1875475.html)
]]></content>
      <categories>
        <category>产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
      </tags>
  </entry>
  <entry>
    <title>RANSAC算法</title>
    <url>/posts/e108c696.html/</url>
    <content><![CDATA[

## Question

* RANSAC有什么用
* RANSAC的中文名叫什么
* RANSAC的流程

## RANSAC

### 概述

> RANSAC(Random Sample Consensus，随机采样一致）可以将数据中的噪声排除在外，从而使模型拟合正常点。
>
> RANSAC的基本假设是数据由“内点”和“外点”组成，内点即为正常数据，外点(outliers)非正常数据（包括异常点、噪声等），而RANSAC的目的是将“外点”排除在外，仅拟合内点。

### 流程

RANSAC是通过反复选择数据集去估计出模型，一直迭代到估计出认为比较好的模型。
具体的实现步骤可以分为以下几步：

1. 选择出可以估计出模型的最小数据集；(对于直线拟合来说就是两个点，对于计算Homography矩阵就是4个点)
2. 使用这个数据集来计算出数据模型；
3. 将所有数据带入这个模型，计算出“内点”的数目；(累加在一定误差范围内的适合当前迭代推出模型的数据)
4. 比较当前模型和之前推出的最好的模型的“内点“的数量，记录最大“内点”数的模型参数和“内点”数；
5. 重复1-4步，直到迭代结束或者当前模型已经足够好了(“内点数目大于一定数量”)。

## 实验代码

### 数据准备

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n_real = <span class="number">100</span></span><br><span class="line">n_fake = <span class="number">30</span></span><br><span class="line"></span><br><span class="line">x = np.random.uniform(low=<span class="number">0</span>,high = <span class="number">100</span>,size = n_real + n_fake)</span><br><span class="line"></span><br><span class="line">k,b = <span class="number">3</span>,<span class="number">7</span></span><br><span class="line">y = k * x + b</span><br><span class="line"></span><br><span class="line">x = np.random.normal(scale = <span class="number">20</span>,size = x.shape) + x</span><br><span class="line">y = np.random.normal(scale = <span class="number">20</span>,size = y.shape) + y</span><br><span class="line"></span><br><span class="line">y_fake = np.asarray([<span class="number">500</span>] *n_fake) + np.random.normal(scale=<span class="number">20</span>,size=n_fake)</span><br><span class="line">y[n_real:] = y_fake</span><br><span class="line"></span><br><span class="line">plt.scatter(x[:n_real],y[:n_real],label = <span class="string">"Real"</span>)</span><br><span class="line">plt.scatter(x[n_real:],y[n_real:],label = <span class="string">"Fake"</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>

数据分布的散点图如下图：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/数据散点图.png)

### 对比

这里用线性回归来拟合散点图，对比不用 RANSAC和用RANSAC的区别，代码如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">0</span></span><br><span class="line">alpha = <span class="number">5</span> <span class="comment"># 判断的宽限条件</span></span><br><span class="line">best_model = <span class="literal">None</span></span><br><span class="line">best_fit_num = <span class="number">0</span> <span class="comment">#最多的拟合个数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> i &lt; <span class="number">100</span>:</span><br><span class="line">    model = LinearRegression()</span><br><span class="line">    </span><br><span class="line">    sample_i = np.random.choice(range(len(x)),size = <span class="number">2</span>)</span><br><span class="line">    sample_x = x[sample_i]</span><br><span class="line">    sample_y = y[sample_i]</span><br><span class="line">    temp_x = sample_x.reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    model.fit(temp_x,sample_y)</span><br><span class="line">    predict_y = model.predict(x.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    current_fit_num = np.sum(np.abs(predict_y - y) &lt; alpha)</span><br><span class="line">    <span class="keyword">if</span> current_fit_num &gt; best_fit_num:</span><br><span class="line">        best_model = model</span><br><span class="line">        best_fit_num = current_fit_num</span><br><span class="line">    </span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">normal_model = LinearRegression()</span><br><span class="line">temp_x = x.reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">normal_model.fit(temp_x,y)</span><br></pre></td></tr></table></figure>

得到的结果如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/拟合结果.png)

代码见：https://github.com/qcymkxyc/AlgorithmImplement/blob/master/notebooks/RANSAC.ipynb

## 参考



> * https://lixin97.com/2019/04/10/RANSAC/

]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Haar特征</title>
    <url>/posts/da5401e0.html/</url>
    <content><![CDATA[
## Question

* Haar特征的流程
* 积分图的作用是什么
* 用分类器做目标检测的思路
* 为何人脸识别会用Adaboost

## Haar特征

### Haar特征的流程

Haar特征实际上非常简单：

> 即用一个类似于卷积层的模板滑过图片，用白色区域的和减去黑色区域的和即为Haar特征

但在Haar特征的模板多种多样，不同的模板有不同的作用，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1328274-20180802215641326-115308739.png)

上图中A和B检验的是竖直和水平的边缘，C模板是检测一条线模板

### 积分图

>  积分图的作用是加快Haar特征的计算的

因为在计算Haar特征时，如果不用积分图，一个区域的像素点会相加很多次，这在效率上很不划算，所以就会计算积分图（一句话，用空间换时间）

至于具体如何做，就是从左上角往右下角叠加

## 关于基于Adaboost的人脸检测

### 基于分类器的检测算法的大体流程

众所周知，分类器是不能直接进行目标检测的。用分类器做目标检测的大体思路是：先用不同大小的Bounding Box扫过图像（类似于穷举），再用分类器对Bounding Box内的图像进行判断，判断该Bounding Box中是否有目标（2分类问题）

在训练分类器时，有Ground Truth即标为正样本，无Ground Truth标为负样本

### Haar +Adaboost级联人脸识别

该流程分为两部分：

* 用**不同大小，不同形态**的模板对图片提取Haar特征
* 用Adaboost模型基于上述的目标检测思路进行识别



那为什么这么多分类器会选Adaboost？

> 主要还是因为效率问题。由于在第一步会提取非常多的Haar特征，如果后续的分类器速度太慢，效率非常低，识别速度会很慢；如果用复杂度较低的模型，识别效果又会非常不理想。所以，这里的识别器要兼顾两点：
>
> * 速度较快
> * 识别效果好
>
> 能很好的兼顾以上两点的只有级联分类器（大神就是大神）
>
> * 在该级联分类器的前面，都是一些较为简单但效果很差的模型（或许只比猜好一点点），简单模型的好处是速度快，它可以过滤掉明显不是目标的样本，这样，数据就不会往后传了（这就可以保证速度快的特点）
> * 随着数据流逐渐往后走，模型会相对的复杂，此时识别效果会上升。并且，由于Adaboost本身也是一个集成模型，随着分类器的增多，识别的精度也会上升，这就保证了识别的精度（此时可以保证识别效果）

## 参考

> * https://www.cnblogs.com/zyly/p/9410563.html
> * https://blog.csdn.net/liulina603/article/details/8617281

]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>机器学习</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>对JS散度的KL散度总结以及实现</title>
    <url>/posts/46a23.html/</url>
    <content><![CDATA[
## Question

* KL散度有什么性质
* KL散度主要的作用是什么
* JS散度有什么性质
* JS散度如何计算

## KL散度

> KL( Kullback–Leibler divergence)散度又名相对熵（relative entropy)，用来衡量两个分布之间的距离

公式为：
$$
D(P||Q)=\sum_{i\in{X}}{P(i)[log(\frac{P(i)}{Q(i)})]}
$$
如果是P和Q为连续分布，则公式为：
$$
D(P||Q)=\int_x{P(x)*\left[log(\frac{P(x)}{Q(x)})\right] dx}
$$
**KL散度的性质**

* **KL散度不具有对称性**，即$D(P||Q)\neq D(Q||P)$
* KL散度不满足三角不等式，即$D(A||B) > D(A||C)+D(C||B)$

## JS散度

> 由于KL散度不具有对称性，于是就有了JS散度

**JS散度即为两个方向的KL散度取平均**,即：
$$
JS(P||Q)=\frac{1}{2}D(P||Q)+\frac{1}{2}D(Q||P)
$$

## 代码实现

### 一维KL散度实现

> 通常情况下，我们遇到的数据均是属于连续数据，而连续数据无法直接计算KL散度，这里用
> 蒙特卡洛采样来计算，采样所用的分布用p的分布（也就是第一列数据）

下面是一维的KL散度的实现，

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kl_divergence</span><span class="params">(p_seq, q_seq, n_sample=<span class="number">5000</span>)</span>:</span></span><br><span class="line">    <span class="string">"""计算KL散度</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    由于签字数据中多是连续数据，对于连续数据无法直接计算KL散度，这里用</span></span><br><span class="line"><span class="string">    蒙特卡洛采样来计算。对于采样与数据的分布说明如下：</span></span><br><span class="line"><span class="string">        - 蒙特卡洛采样的分布用P的分布采样</span></span><br><span class="line"><span class="string">        - P和Q均是采用正态分布拟合</span></span><br><span class="line"><span class="string">        - 默认的采样个数为50000个</span></span><br><span class="line"><span class="string">    :param p_seq: List or pandas.Serise</span></span><br><span class="line"><span class="string">    :param q_seq: List or pandas.Serise</span></span><br><span class="line"><span class="string">    :param n_sample: int, 蒙特卡洛的采样点，默认为50000个</span></span><br><span class="line"><span class="string">    :return: float,KL散度</span></span><br><span class="line"><span class="string">    :raise TypeError: 参数类型错误</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># TODO 没有考虑离散的分布</span></span><br><span class="line">    <span class="string">"""错误的类型判断"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (isinstance(p_seq, (list, pd.Series))</span><br><span class="line">            <span class="keyword">and</span> isinstance(q_seq, (list, pd.Series))):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"数据类型错误"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""分布拟合"""</span></span><br><span class="line">    p_loc, p_std = stats.norm.fit(p_seq)</span><br><span class="line">    q_loc, q_std = stats.norm.fit(q_seq)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""采样并计算概率密度"""</span></span><br><span class="line">    samples = stats.norm.rvs(loc=p_loc, scale=p_std, size=n_sample)</span><br><span class="line">    <span class="comment"># 计算概率密度</span></span><br><span class="line">    p_y = stats.norm.pdf(samples, loc=p_loc, scale=p_std)</span><br><span class="line">    q_y = stats.norm.pdf(samples, loc=q_loc, scale=q_std)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""计算KL散度"""</span></span><br><span class="line">    <span class="keyword">return</span> np.sum(p_y * np.log(p_y / q_y))</span><br></pre></td></tr></table></figure>

### 多维KL散度实现

多维原理同一维的KL散度，这里不再阐述，代码如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_multi_kl_divergence</span><span class="params">(p_matrix, q_matrix, n_sample=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    <span class="string">"""多维情况下计算KL散度，设置同单维的KL散度计算</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param p_matrix: pandas.DataFrame or numpy.array, 矩阵P</span></span><br><span class="line"><span class="string">    :param q_matrix: pandas.DataFrame or numpy.array, 矩阵Q</span></span><br><span class="line"><span class="string">    :param n_sample: int, 蒙特卡洛采样的个数,默认为10000</span></span><br><span class="line"><span class="string">    :return: float, KL散度</span></span><br><span class="line"><span class="string">    :raise</span></span><br><span class="line"><span class="string">        - TypeError： 参数类型不对</span></span><br><span class="line"><span class="string">        - ValueError: P和Q的维数不统一</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="string">"""类型判断"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(p_matrix, (pd.DataFrame, np.ndarray)):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"参数类型错误"</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(q_matrix, (pd.DataFrame, np.ndarray)):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"参数类型错误"</span>)</span><br><span class="line">    <span class="string">"""维数判断，两个输入的维数一定要相等"""</span></span><br><span class="line">    <span class="keyword">if</span> p_matrix.shape[<span class="number">1</span>] != q_matrix.shape[<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"P和Q的维数不统一"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""生成两个矩阵的分布"""</span></span><br><span class="line">    p_mean = np.mean(p_matrix, axis=<span class="number">0</span>)</span><br><span class="line">    q_mean = np.mean(q_matrix, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    p_cov = np.cov(p_matrix.T, bias=<span class="literal">False</span>)</span><br><span class="line">    q_cov = np.cov(q_matrix.T, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    p_distribution = stats.multivariate_normal(mean=p_mean, cov=p_cov)</span><br><span class="line">    q_distribution = stats.multivariate_normal(mean=q_mean, cov=q_cov)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""采样"""</span></span><br><span class="line">    samples = p_distribution.rvs(size=n_sample)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""计算概率密度"""</span></span><br><span class="line">    p_probs = p_distribution.pdf(samples)</span><br><span class="line">    q_probs = q_distribution.pdf(samples)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.sum(p_probs * np.log(p_probs / q_probs))</span><br></pre></td></tr></table></figure>

### JS散度

JS计算就很简单了，如下：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_js_divergence</span><span class="params">(p_seq, q_seq, n_sample=<span class="number">50000</span>)</span>:</span></span><br><span class="line">    <span class="string">"""计算JS散度，详细参考KL散度</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param p_seq: List or pandas.Serise</span></span><br><span class="line"><span class="string">    :param q_seq: List or pandas.Serise</span></span><br><span class="line"><span class="string">    :param n_sample: int, 蒙特卡洛的采样点，默认为50000个</span></span><br><span class="line"><span class="string">    :return: float,KL散度</span></span><br><span class="line"><span class="string">    :raise TypeError: 参数类型错误</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kl_diver1 = <span class="number">0.5</span> * get_kl_divergence(p_seq, q_seq)</span><br><span class="line">    kl_diver2 = <span class="number">0.5</span> * get_kl_divergence(q_seq, p_seq)</span><br><span class="line">    <span class="keyword">return</span> kl_diver1 + kl_diver2</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_multi_js_divergence</span><span class="params">(p_matrix, q_matrix, n_sample=<span class="number">10000</span>)</span>:</span></span><br><span class="line">    <span class="string">"""多维情况下计算JS散度，设置同单维的JS散度计算</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       :param p_matrix: pandas.DataFrame or numpy.array, 矩阵P</span></span><br><span class="line"><span class="string">       :param q_matrix: pandas.DataFrame or numpy.array, 矩阵Q</span></span><br><span class="line"><span class="string">       :param n_sample: int, 蒙特卡洛采样的个数,默认为10000</span></span><br><span class="line"><span class="string">       :return: float, KL散度</span></span><br><span class="line"><span class="string">       :raise</span></span><br><span class="line"><span class="string">           - TypeError： 参数类型不对</span></span><br><span class="line"><span class="string">           - ValueError: P和Q的维数不统一</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    js_diver1 = <span class="number">0.5</span> * get_multi_kl_divergence(p_matrix, q_matrix, n_sample)</span><br><span class="line">    js_diver2 = <span class="number">0.5</span> * get_multi_kl_divergence(q_matrix, p_matrix, n_sample)</span><br><span class="line">    <span class="keyword">return</span> js_diver1 + js_diver2</span><br></pre></td></tr></table></figure>

## 参考

> * https://blog.csdn.net/qq_40406773/article/details/80630280
> * https://blog.csdn.net/leviopku/article/details/81388306]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title>self-Attention总结</title>
    <url>/posts/d9717497.html/</url>
    <content><![CDATA[
**DeepLearningAi**上的Attention机制似乎和李宏毅教程上的有一定出入，本文以李宏毅教程上的为准

## Question

* 和LSTM层相比，Attention机制的优势是什么
* Attention 机制一般用在什么任务中
* Attention的流程
* Multi Head Attention好于self-Attention机制的解释是什么
* Multi Head Attention的流程

## 概述

Transformer模型的主要创新点就是Self-Attention机制

只要以前可以用seq-to-seq模型的地方，均可以用Attention机制代替。Attention机制的优点分为以下几点：

* 可以并行计算（而LSTM层需要等上一次的输出）
* 由于Self-Attention的第一层采用卷积的思想，所以即使相隔很远也可以建立联系（总结一句话就是：天涯若比邻）
* 在Seq-to-Seq模型的翻译任务中，在Decoder部分，如果用LSTM层，Bleu Score会因为句子的增长而降低。Attention机制可以避免这个问题（出自NG DeepLearning课程）

**只要能用Seq2Seq的地方，都可以用Attention机制代替**，如下图所示：

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-859dc652d45bcb8a.png" style="zoom: 80%;">



## 基本Attention机制的流程

### 第一步

Attention机制先将$a^i$输入乘以三个个权重，得到一个三个值$q^i,k^i,v^i$,如下图所示：

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-3af6168784972c3d.png" style="zoom:80%;">

### 第二步

计算$q^i$和$k^j$的内积，得到一个值$a_{i,j}$。

> 实质上，计算$q^i$和$k^j$的内积是计算$i$和$j$的相似度。对于 $t=1$的，它会计算从$t=1$到$t=T$的相似程度（注意，会计算自身到自身的相似程度），
>
> 那么，对于一个长度为$T$的序列，会计算一个$T \times T$的相似矩阵。

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-162d501ebec07596.png" style="zoom:80%;">

### 第三步

将$a_{i,j}$,通过一个$softmax$函数**归一化**，得到归一化后的结果$\hat{a_{i,j}}$,该结果作为权重，如下图所示：

> 这里即将上述矩阵按行归一化，归一化的结果可以看成权重。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-7ae69a8fe1679bab.png)

### 第四步

用第三步得到的权重和$v^i$进行加权计算，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-c0d9670deb5a794c.png)

所得的结果$b^1$就是$a^1$对应的结果，后面的$b^2$,$b^3$等以此类推

## Multi Head Attention

> 之所以会有Multi Head，文中的理由是会分成多个子空间，可以让Multi Head关注不同方面的信息	

Multi Head Attention的流程如下：

* Multi Head在之前$q^{i},k^i,v^i$的基础上再乘以$n$个矩阵（有多少个Head就乘以多少个矩阵），得到$q^{i,1},q^{i,2}...,q^{i,n}$(以$q^i$为例，其他相同)

* 然后以每个Head为单位分别计算，得到$b^{i,1},b^{i,2},...,b^{i,n}$
* 最终将$b^{i,1},b^{i,2},...,b^{i,n}$乘以一个矩阵$w$得到最终的结果$b^i$

如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/11864412-7c5882bac6e86c4a.png)

## Position Encoding

但在`Self-Attention`中，并没有体现位置的关系（因为全部用相似度加权），这就丧失了序列本身的特性，所以加上序列信息是必要的。在`Attention`机制中，是将位置信息生成一个向量，将这个向量加在`token Embedding`中，即：
$$
\text {final Embedding}= \text{Position Encoding} + \text{token Embedding}
$$
那么，下一个问题是，`position Encoding`如何生成？

[Attention is All you Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)中是用如下方式生成的：
$$
PE_{(pos,2i)}=sin(\frac{pos}{10000^{2i/d_{model}}})		\tag {1}
$$

$$
PE_{(pos,2i+1)}=cos(\frac{pos}{10000^{2i/d_{model}}})	\tag {2}
$$

其中，

* $pos$表示位置信息，也就是位置的`index`,例如第一个为0，第二个为1，以此类推。
* $i$为一个自然数，$PE_{(pos,2i)}$表示位置信息$pos$在生成的`Position Encoding`向量中位置在$2i$的值。同理$PE_{(pos,2i+1)}$表示在$2i+1$的值。（即偶数位置和奇数位置的计算方式不同）
* $d_{model}$代表`token Embedding`的维度

那么，位置为$1$的`Position Encoding`为：
$$
PE(1)={\left[sin(\frac{1}{10000^{0/512}}),cos(\frac{1}{10000^{0/512}}),sin(\frac{1}{10000^{2/512}}),cos(\frac{1}{10000^{2/512}}),...\right]}
$$
其中，$PE(1)$是一个$1 \times d_{model}$的向量，和`token Embedding`的向量维度等同。

## 参考

> * [Self-Attention机制的论文](https://arxiv.org/abs/1706.03762)
> * https://www.jianshu.com/p/50130426e5e8
> * [李宏毅官网](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html)
> * [知乎上的一个对于Multi Head Attention的详细解释](https://www.zhihu.com/question/341222779)
> * [Multi Head Attention论文](https://arxiv.org/pdf/1905.09418.pdf)
> * [对Transformer中的Positional Encoding一点解释和理解](https://zhuanlan.zhihu.com/p/98641990)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>神经网络</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>对Pearson，Spearman，协方差等相关性的总结</title>
    <url>/posts/75634b1e.html/</url>
    <content><![CDATA[
## Question

> 1. 在numpy中协方差矩阵是以行为单位计算还是以列为单位计算
> 2. 在numpy中计算协方差是有偏的还是无偏的
> 3. 协方差以及Pearson相识度的计算流程
> 4. Pearson相关度和协方差的区别
> 5. 什么时候适合用spearman相关度
> 6. spearman相似度计算的流程

## 协方差

首先说最简单的——协方差，协方差的计算比较简单：
$$
Cov(x,y)=E[(x-\overline{x})\cdot(y-\overline{y})]
$$
或者将 $x$ 和$y$的协方差表示为,设$x$和$y$均为**维度为n的向量**，则两个向量的协方差可以表示为：
$$
Cov(x,y)=\frac{1}{n}\sum_{i=1}^{n}{(x_i-\overline{x})(y_i-\overline{y})}
$$
对于一个矩阵如何计算向量呢，在numpy中，是将矩阵**以行为单位看成是一个feature**（即一行一个feature），计算相关性（**所以，在计算特征的相关度时需要transform一下**）。并且，在numpy中计算方差基本都是使用无偏估计（也就是自由度为1）。下面是演示代码：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">print(np.cov(x))</span><br></pre></td></tr></table></figure>

结果为：

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[[<span class="number">1.66666667</span> <span class="number">1.66666667</span> <span class="number">1.66666667</span>]</span><br><span class="line"> [<span class="number">1.66666667</span> <span class="number">1.66666667</span> <span class="number">1.66666667</span>]</span><br><span class="line"> [<span class="number">1.66666667</span> <span class="number">1.66666667</span> <span class="number">1.66666667</span>]]</span><br></pre></td></tr></table></figure>

总结一下：

1. numpy的协方差矩阵计算是以行为单位计算
2. 在计算协方差时是用$n-1$计算的

## Pearson相关性

**Pearson相关度可以看成是归一化后的协方差**，公式为：
$$
Pearson-correlation = \frac{cov(x,y)}{\sqrt{cov(x,x)*cov(y,y)}}
$$

## Spearman相关性

>  Spearman主要是用于测量两个时间距离的相似度，因为如果用Pearson相似度测量两个时间序列的相似度，数字的序列性将无法体现。

### 算法流程

1. 对两个序列（向量）进行排序，获取每个数字在序列中的个数，例如$x=[12,2,7,90]$得到的结果为$rankx=[3,1,2,4]$
2. 对两个序列排序的结果进行pearson相似度的计算

## 参考

> * https://www.cnblogs.com/weiyinfu/p/10693445.html
> * https://blog.csdn.net/lambsnow/article/details/79972145

]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>相似度</tag>
        <tag>距离度量</tag>
      </tags>
  </entry>
  <entry>
    <title>距离总结</title>
    <url>/posts/348aa22b.html/</url>
    <content><![CDATA[
## Queston

1. 欧氏距离和曼哈顿距离的在几何上的区别
2. [Jaccard距离](#Jaccard距离)在什么场景用

## 闵可夫斯基距离

曼哈顿距离和欧式距离可以看成是特殊的闵可夫斯基距离。

设有两个向量$P=(x_1,x_2,...,x_n)$和$Q=(y_1,y_2,..,y_n)$,则两个向量的欧式距离和曼哈顿距离可以分别表示为：
$$
\left(\sum_{i=1}^{n}{(x_i-y_i)}^2\right)^{\frac{1}{2}}
$$

$$
\sum_{i=1}^{n}{|x_i-y_i|}
$$

而闵可夫斯基距离表示为：
$$
\left(\sum_{i=1}^{n}{|x_i-y_i|}^p\right)^{\frac{1}{p}}
$$
所以，欧式距离和曼哈顿距离可以表示成特殊的闵可夫斯基距离，关于曼哈顿距离和欧氏距离的区别网上有一张形象的图，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20140423145904625.jpg)

**图中，绿线表示欧氏距离，红蓝黄三条线表示曼哈顿距离**

## Jaccard距离

`Jaccard距离`和`Jaccard相似度`相反.下面说明`Jaccard相似度`

**`Jaccard相似度`衡量的是两个集合的相似度**。设有两个集合$A$和$B$，则他们的`Jaccard相似度`可以表示为：
$$
J(A,B)=\frac{|A\bigcap{B}|}{|A\bigcup{B|}}
$$
而`Jaccard距离`$J_{\epsilon}$为：
$$
J_{\epsilon}=1-J(A,B)=\frac{|A\bigcup{B}-A\bigcap{B}|}{|A\bigcup{B}|}
$$


## 马氏距离

> 马氏距离可以看成是欧式距离的一种改良，他在欧氏距离的基础上考虑了特征（维度）的相关性，对于数据集的距离衡量也更加合理。

对于数据集中的两个点，A和B。A和B对于聚点中心的欧氏距离都相同，但可以明显的看出A点是一个离群点，而B不是。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/v2-3cee35b79d272dda86e2604c160934ee_720w.jpg)



## 参考

> * https://blog.csdn.net/eric41050808/article/details/24365765
>
> * https://www.jianshu.com/p/5706a108a0c6
> * https://zhuanlan.zhihu.com/p/46626607]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>距离度量</tag>
        <tag>指标</tag>
      </tags>
  </entry>
  <entry>
    <title>衡量指标汇总</title>
    <url>/posts/88a0752d.html/</url>
    <content><![CDATA[
## FAR以及FRR

### Question

> * FAR和FRR的全分别叫什么
> * FAR和FRR表示什么意义
> * FAR和FRR的如何计算

### 概要

> FAR和FRR是做指纹识别、人脸识别、手写识别等的常用指标，他们的全名如下
>
> * 误识率（FAR，false acceptance rate）
>
> * 拒识率（FRR，false rejection rate）

### 计算方式

对于匹配的结果又以下几种可能：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/指纹匹配-1584601149727.png)

其中，*=>*表示模型的识别结果。



$$
误识率（FAR）=\frac{不同的人=>相同的人}{（不同的人=>相同的人） + （不同的人 =>不同的人）}
$$

$$
拒识率（FRR）=\frac{相同的人=>不同的人}{（相同的人=>不同的人+相同的人=>相同的人）}
$$

### 表示的意义

> 误识率（FAR）：**度量的是他人可以冒充本人的程度**，这个值越高，表示他人模仿本人更容易
>
> 拒识率（FRR）：度量的是对本人一致性的衡量

**在实际项目中，通常误识率比拒识率重要**，因为拒识率即使较高，在指纹识别时可以多打几次。但若误识率较高，他人就能轻易冒充本人的指纹，所造成的麻烦会大得多。

## Recall以及Precision

### Question

* $Precision$和$Recall$的意义是什么
* $Precision$和$Recall$的计算公式

### 两个指标的意义

* $Precision$表示有多少正确的被检测
* $Recall$表示模型结果认为正确的有多少对了

### 两个指标的计算公式

以下是$Precision$和$Recall$的计算公式：

对于一个分类器，有以下四种可能：

| 真\预 |  正  | 负   |
| ----: | :--: | :--- |
|    正 |  TP  | FN   |
|    负 |  FP  | TN   |

其计算公式表示为：

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow>
    <mo>{</mo>
    <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
      <mtr>
        <mtd>
          <mi>R</mi>
          <mi>e</mi>
          <mi>c</mi>
          <mi>a</mi>
          <mi>l</mi>
          <mi>l</mi>
          <mo>=</mo>
          <mfrac>
            <mrow>
              <mi>T</mi>
              <mi>P</mi>
            </mrow>
            <mrow>
              <mo stretchy="false">(</mo>
              <mi>T</mi>
              <mi>P</mi>
              <mo>+</mo>
              <mi>F</mi>
              <mi>N</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mi>P</mi>
          <mi>r</mi>
          <mi>e</mi>
          <mi>c</mi>
          <mi>i</mi>
          <mi>s</mi>
          <mi>i</mi>
          <mi>o</mi>
          <mo>=</mo>
          <mfrac>
            <mrow>
              <mi>T</mi>
              <mi>P</mi>
            </mrow>
            <mrow>
              <mo stretchy="false">(</mo>
              <mi>F</mi>
              <mi>P</mi>
              <mo>+</mo>
              <mi>T</mi>
              <mi>P</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mtd>
      </mtr>
    </mtable>
    <mo fence="true" stretchy="true" symmetric="true"></mo>
  </mrow>
</math>

<!--
$$
\begin{cases} Recall = \frac{TP}{(TP+FN)} \\ Precision=\frac{TP}{(FP + TP)}\end{cases}
$$



-->]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>指标计算</tag>
      </tags>
  </entry>
  <entry>
    <title>Hough变换</title>
    <url>/posts/e9f2d7e8.html/</url>
    <content><![CDATA[


## Question

1. 笛卡尔坐标系中多点共线，在Hough空间中表现如何
2. 在Hough变换中，如何保证多点共线，即保证共线的原理是什么
3. 霍夫变换对图像的输入有什么要求
4. [以$k$和$b$为基的空间的缺点在哪儿](#霍夫变换原理)
5. 霍夫变换的大体流程

## 霍夫变换原理

对于笛卡尔坐标系中的一条线$y=kx+b$,可以转换成霍夫空间下的一个点（霍夫空间是以$k$和$b$为坐标），如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1085343-20170424185145272-8035578-1584177392001.png)

那么，对于笛卡尔坐标系中的一个点$(x_1,y_1)$，则转换为霍夫空间下的一条线，如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1085343-20170424185846412-1947419957-1584177461604.png)

**它表示经过改点的所有直线**

那么，在笛卡尔坐标系中经过两点的直线，表现为在霍夫空间下两条直线的交点：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1085343-20170424190504412-864862338-1584177533599.png)

三点共线在霍夫空间中表现为三条线相交于一点：

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1085343-20170424213944022-348637873.png" style="zoom:80%;">

**再次引申，如果多个点共线，那么在Hough空间中表现为多条线相交于一点**

**如果一条线是垂直于x轴的，那么该线在Hough空间中无法表示（此时为$\infty$）**，所以这里将k和q表示的Hough空间转换为极坐标，如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1085343-20170424215910740-145827126.png)

同以*k*和*q* 组成的Hough空间，三点共线表示为三线相交，以下是两个Hough空间的对比图：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1085343-20170424221329412-431224652-1584178146121.png)

## 流程

1. 首先，获取一个二值化图像

2. 建立一个矩阵$H$，行为$p$的所有取值，列为$\theta$（$\theta$的取值范围为(-90,180)）

3. 遍历图像中的所有边缘点，得到该点的坐标$(x,y)$，再遍历$\theta$的取值，通过公式$p=xcos{\theta}+ysin{\theta}$ 得到$p$,用伪代码表示为：

   <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> each edge Point(x,y):</span><br><span class="line">	<span class="keyword">for</span> theta <span class="keyword">in</span> range(<span class="number">-90</span>,<span class="number">90</span>):</span><br><span class="line">		p = x * cos(theta) + y * sin(theta)</span><br><span class="line">		H(theta,p) += <span class="number">1</span></span><br><span class="line">	end</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

4. 在$H$中找出最大的n个值即找出n条直线

## 参考

> https://www.cnblogs.com/php-rearch/p/6760683.html]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>机器学习</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>DTW距离</title>
    <url>/posts/4df0af7c.html/</url>
    <content><![CDATA[
## DTW距离

### Question

1. DTW的作用
2. DTW的大致流程

### DTW距离

> DTW全称Dynamic Time Warping，用于衡量两个不同长度的两个序列的距离

1. 构造匹配矩阵

设序列1$Q=q_1,q_2,...,q_n$,序列2$C=c_1,c_2,...,c_m$ ,其中$n\neq m$,然后构造一个$m\times n$的矩阵，矩阵中的值是$q_i$和$c_j$的距离（通常用欧式距离），如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20130620200852375-1584176187632.jpg)

2. 路径规划限制条件	

> 即找到一条从左下角到右上角的路径,路径表示为：
> $$
> W=w_1,w_2,w_3,...,w_k,...,w_K   ，\text max(m,n) \leqslant K \leqslant m+n-1
> $$

> **前置条件**
>
> 但是该路径必须满足几个条件：
>
> 1. 边界约束：$w_1=(1,1)$,$w_K=(m,n)$,就是说两条序列的开始点和结束点一定是重合的
> 2. 连续性：如果$w_{k-1}= (a’, b’)$，那么对于路径的下一个点$w_k=(a, b)$需要满足 (a-a’) <=1和 (b-b’) <="1。就是说序列上的每一个点都要计算距离"> 3. 单调性： 如果$w_{k-1}= (a’, b’)$，那么对于路径的下一个点$w_{k}=(a, b)$需要满足0<=(a-a’)和0<= (b-b’)。也就是说不能回头连接算距离>
> **以上三个约束其实就一个目的，限定路径只能往这几个方向走，且只能走一步。**
>
> ![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20130620200949125-1584176277643.jpg)

3. 路劲规划

   > 即找到权重和最小路径

最后使用动态规划实现计算DTW距离，在上图中找到一条路径实现距离之和最小（从$w_1=(1,1)$开始,$w_K=(m,n)$结束），公式表示为：
$$
DTW（Q，C）=min（\sqrt{\sum_{k=1}^K{w_k}}）
$$
有时候为了增加路径长度的惩罚，路径可以表示为：
$$
DTW（Q，C）=min（\left(\sqrt{\sum_{k=1}^K{w_k}} \right)/K）
$$

### 代码实现

#### 整体的DTW距离：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dtw_distance</span><span class="params">(matrix_a, matrix_b, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">"""计算DTW距离</span></span><br><span class="line"><span class="string">    所用的距离度量标准是欧式距离，但前提是两个矩阵的列数必须一致，若不一致则报错，</span></span><br><span class="line"><span class="string">    计算距离分下面几种情况：</span></span><br><span class="line"><span class="string">    1. 若两个矩阵行数相同，则直接计算欧式距离</span></span><br><span class="line"><span class="string">    2. 若两个矩阵的行数不同，则计算DTW距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param matrix_a: np.array,矩阵或向量A</span></span><br><span class="line"><span class="string">    :param matrix_b: np.array,矩阵或向量B</span></span><br><span class="line"><span class="string">    :return: float,np.array(int,int)</span></span><br><span class="line"><span class="string">        - 序列之间的距离</span></span><br><span class="line"><span class="string">        - 最短路径的坐标</span></span><br><span class="line"><span class="string">    :raise: ValueError:</span></span><br><span class="line"><span class="string">        - 1. Weight的shape不对，其shape必须和两个矩阵的列相等</span></span><br><span class="line"><span class="string">        - 2.两个矩阵的列数不同</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n_row_a, n_col_a = matrix_a.shape</span><br><span class="line">    n_row_b, n_col_b = matrix_b.shape</span><br><span class="line"></span><br><span class="line">    <span class="string">"""两个矩阵的列不同则报错"""</span></span><br><span class="line">    <span class="keyword">if</span> n_col_a != n_col_b:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"两个矩阵的列必须相同"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""列相等且为1的情况，直接计算欧式距离"""</span></span><br><span class="line">    <span class="keyword">if</span> n_row_a == n_row_b:</span><br><span class="line">        <span class="comment"># 如果矩阵A和矩阵B均为1维，则直接计算欧式距离</span></span><br><span class="line">        <span class="keyword">if</span> n_col_a == <span class="number">1</span> <span class="keyword">and</span> n_col_b == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> np.sqrt(np.sum(pow(matrix_a - matrix_b, <span class="number">2</span>))), [(<span class="number">0</span>, <span class="number">0</span>)]</span><br><span class="line">        <span class="comment"># 如果是矩阵，则计算矩阵范数，这里采用的是2范数</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            path = list(range(n_row_a))</span><br><span class="line">            path = list(zip(path, path))</span><br><span class="line">            <span class="keyword">return</span> np.sqrt(np.sum(pow(matrix_a - matrix_b, <span class="number">2</span>))), path</span><br><span class="line"></span><br><span class="line">    <span class="string">"""行数不相等的情况，计算DTW距离"""</span></span><br><span class="line">    distance_matrix = np.zeros((n_row_a, n_row_b))</span><br><span class="line">    <span class="comment"># 获取权重并且判断weights的shape是否正确</span></span><br><span class="line">    weights = kwargs.get(<span class="string">"weights"</span>)</span><br><span class="line">    <span class="keyword">if</span> weights <span class="keyword">is</span> <span class="literal">None</span>:     <span class="comment"># 默认情况下，权重为1</span></span><br><span class="line">        weights = np.ones(n_col_a)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        weights = np.asarray(weights)</span><br><span class="line">        <span class="string">"""验证weights的shape是否正确"""</span></span><br><span class="line">        <span class="keyword">if</span> weights.shape[<span class="number">0</span>] != n_col_a <span class="keyword">and</span> len(weights.shape) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Weights的shape错误"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> a_row_index, a_row <span class="keyword">in</span> enumerate(matrix_a):</span><br><span class="line">        <span class="keyword">for</span> b_row_index, b_row <span class="keyword">in</span> enumerate(matrix_b):</span><br><span class="line">            single_dtw_distance = np.sqrt(</span><br><span class="line">                np.sum(weights * pow((a_row - b_row), <span class="number">2</span>)))</span><br><span class="line">            distance_matrix[a_row_index][b_row_index] = single_dtw_distance</span><br><span class="line"></span><br><span class="line">    shortest_path, shortest_distance = __shortest_distance_with_dynamic(</span><br><span class="line">        distance_matrix)</span><br><span class="line">    <span class="keyword">return</span> shortest_distance, shortest_path</span><br></pre></td></tr></table></figure>

#### 生成的DTW矩阵寻找最短路径

对于寻找最短路径有两种方式：

1. 递归
2. 动态规划

下面是递归部分：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__shortest_distance_with_recursion</span><span class="params">(distance_matrix, current_row=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       current_col=<span class="number">0</span>, path=[], last_distance=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""用递归查找DTW距离的最短距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param distance_matrix: np.array, DTW矩阵</span></span><br><span class="line"><span class="string">    :param current_row: int, 当前位置所在的行，</span></span><br><span class="line"><span class="string">    :param current_col: int, 当前位置所在的列</span></span><br><span class="line"><span class="string">    :param path: list[(int,int)] , 之前所走的路径</span></span><br><span class="line"><span class="string">    :return: List[(int,int)], int</span></span><br><span class="line"><span class="string">        - 最短路径</span></span><br><span class="line"><span class="string">        - 最短路径的长度</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    path = copy.copy(path)</span><br><span class="line">    n_row, n_col = distance_matrix.shape</span><br><span class="line"></span><br><span class="line">    <span class="string">""" 退出限定"""</span></span><br><span class="line">    <span class="comment"># 如果没有到达最下角，即超出边界,此时返回的路径是无穷大</span></span><br><span class="line">    <span class="keyword">if</span> current_row &gt;= n_row <span class="keyword">or</span> current_col &gt;= n_col:</span><br><span class="line">        <span class="keyword">return</span> path, np.inf</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果到达了最下角</span></span><br><span class="line">    path.append((current_row, current_col))</span><br><span class="line">    current_num = distance_matrix[current_row][current_col]</span><br><span class="line">    current_distance = last_distance + current_num</span><br><span class="line">    <span class="keyword">if</span> (current_row + <span class="number">1</span>, current_col + <span class="number">1</span>) == distance_matrix.shape:</span><br><span class="line">        <span class="keyword">return</span> path, current_distance</span><br><span class="line"></span><br><span class="line">    <span class="string">"""递归的向三个方向走"""</span></span><br><span class="line">    <span class="comment"># 向右走</span></span><br><span class="line">    right_path, right_length = __shortest_distance_with_recursion(distance_matrix, current_row, current_col + <span class="number">1</span>,</span><br><span class="line">                                                                  path=path, last_distance=current_distance)</span><br><span class="line">    <span class="comment"># 向下走</span></span><br><span class="line">    down_path, down_length = __shortest_distance_with_recursion(distance_matrix, current_row + <span class="number">1</span>,</span><br><span class="line">                                                                current_col, path=path, last_distance=current_distance)</span><br><span class="line">    <span class="comment"># 向斜下走</span></span><br><span class="line">    decline_path, decline_length = __shortest_distance_with_recursion(distance_matrix, current_row + <span class="number">1</span>,</span><br><span class="line">                                                                      current_col + <span class="number">1</span>, path=path, last_distance=current_distance)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""在以上3个方向中选出最短路径"""</span></span><br><span class="line">    last_pathes = (right_path, down_path, decline_path)</span><br><span class="line">    last_lengthes = (right_length, down_length, decline_length)</span><br><span class="line">    shortest_index = np.argmin(last_lengthes)</span><br><span class="line">    shortest_path, shortest_lengthes = last_pathes[shortest_index], last_lengthes[shortest_index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> shortest_path, shortest_lengthes</span><br></pre></td></tr></table></figure>

动态规划方式：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__get_property_value</span><span class="params">(matrix, current_row, current_col)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        value = matrix[current_row][current_col]</span><br><span class="line">    <span class="keyword">except</span> IndexError:</span><br><span class="line">        value = np.inf</span><br><span class="line">    <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__shortest_distance_with_dynamic</span><span class="params">(distance_matrix)</span>:</span></span><br><span class="line">    <span class="string">"""用动态规划查找DTW距离</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param distance_matrix: np.array, DTW矩阵</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n_row, n_col = distance_matrix.shape</span><br><span class="line"></span><br><span class="line">    <span class="string">"""计算到达当前位置最小的路径值"""</span></span><br><span class="line">    min_distance_matrix = np.zeros(distance_matrix.shape)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> range(n_row):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> range(n_col):</span><br><span class="line">            <span class="comment"># 第一步则不计算</span></span><br><span class="line">            <span class="keyword">if</span> row == <span class="number">0</span> <span class="keyword">and</span> col == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 左上</span></span><br><span class="line">            upleft_value = __get_property_value(</span><br><span class="line">                min_distance_matrix, row - <span class="number">1</span>, col - <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 左边</span></span><br><span class="line">            left_value = __get_property_value(</span><br><span class="line">                min_distance_matrix, row, col - <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 上面</span></span><br><span class="line">            up_value = __get_property_value(min_distance_matrix, row - <span class="number">1</span>, col)</span><br><span class="line"></span><br><span class="line">            min_value = np.min([upleft_value, left_value, up_value])</span><br><span class="line">            min_distance_matrix[row][col] = distance_matrix[row][col] + min_value</span><br><span class="line"></span><br><span class="line">    <span class="string">"""查找最短路径"""</span></span><br><span class="line">    row, col = n_row - <span class="number">1</span>, n_col - <span class="number">1</span></span><br><span class="line">    path = [(row, col)]</span><br><span class="line">    <span class="keyword">while</span> row &gt;= <span class="number">0</span> <span class="keyword">and</span> col &gt;= <span class="number">0</span>:</span><br><span class="line">        <span class="string">'''当已经到达原点则直接退出'''</span></span><br><span class="line">        <span class="keyword">if</span> row == <span class="number">0</span> <span class="keyword">and</span> col == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 左上</span></span><br><span class="line">        upleft_value = __get_property_value(</span><br><span class="line">            min_distance_matrix, row - <span class="number">1</span>, col - <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 左边</span></span><br><span class="line">        left_value = __get_property_value(min_distance_matrix, row, col - <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 上面</span></span><br><span class="line">        up_value = __get_property_value(min_distance_matrix, row - <span class="number">1</span>, col)</span><br><span class="line"></span><br><span class="line">        candidate_values = [upleft_value, left_value, up_value]</span><br><span class="line">        min_index = np.argmin(candidate_values)</span><br><span class="line">        <span class="comment"># 往左上寻址</span></span><br><span class="line">        <span class="keyword">if</span> min_index == <span class="number">0</span>:</span><br><span class="line">            row -= <span class="number">1</span></span><br><span class="line">            col -= <span class="number">1</span></span><br><span class="line">        <span class="comment"># 往左寻址</span></span><br><span class="line">        <span class="keyword">elif</span> min_index == <span class="number">1</span>:</span><br><span class="line">            col -= <span class="number">1</span></span><br><span class="line">        <span class="comment"># 往上寻址</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            row -= <span class="number">1</span></span><br><span class="line">        path.append((row, col))</span><br><span class="line"></span><br><span class="line">    path.reverse()</span><br><span class="line">    <span class="keyword">return</span> path, min_distance_matrix[n_row - <span class="number">1</span>][n_col - <span class="number">1</span>]</span><br></pre></td></tr></table></figure>



### 参考

> https://blog.csdn.net/qq_40006058/article/details/79992255</=(a-a’)和0<=></=1和>]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>距离</tag>
      </tags>
  </entry>
  <entry>
    <title>LBP特征</title>
    <url>/posts/edf1298.html/</url>
    <content><![CDATA[
## LBP特征

### Question

* LBP特征的流程
* LBP特征的改进点在哪里，解决了什么问题

### LBP特征

> LBP特征用于提取纹理特征

1. 将图像切分block，比如切分成16*16

2. 对每个block内以3*3为单位，提取LBP特征

   ​	对比3*3的方格中周围的值和中间的值，如果周围的值大于中间的值，则表示为1，反之则表示为0，公式表示如下：
   $$
   img(i,j)=\begin{cases} 0, & img(i,j)>=img(center) \\ 1, & img(i,j)<img(center)\end{cases} $$ ![](https: blog-1253764997.cos.ap-chongqing.myqcloud.com 14596362-7ea1a8cd7c2757f7-1584175992695.png) 上述操作得到一个二进制表格，从左上角开始顺时针排列得到一个二进制数，将该二进制数转换为十进制数即为该cell的lbp特征> **改进点：**为了保证LBP特征的旋转不变性，转换为二进制特征的方式改为跳数，即如果上一个数和下一个数不同（即一个是0，一个是1），则算为1，否则为0，用公式表示为：

   $$
   cell(i)=\begin{cases} 1,& cell(i-1) \neq cell(i) \\ 0, & cell(i-1) =cell(i) \end{cases} (i\in(2,..,9)
   $$


3. 直方图统计

   由于不同大小的图片得到的LBP特征也不同，所以这里以block为单位进行直方图统计，每个block在统计后进行归一化处理。
   
4. 整幅图的block拉成一条向量即为该图片的LBP特征

## 参考

> [《Multiresolution gray-scale and rotation invariant texture classification with local binary patterns》](http://citeseer.ist.psu.edu/viewdoc/download;jsessionid=145DB5D01FBCC36DA0EA57425B04AA9A?doi=10.1.1.157.1576&rep=rep1&type=pdf)</img(center)\end{cases}>]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>计算机视觉</tag>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title>Triple网络</title>
    <url>/posts/d5b27990.html/</url>
    <content><![CDATA[
# Triplet Network

## Question

1. `Triplet Network`和`Siamese Network`相比哪个效果好
2. `Triplet Network`的大体流程
3. `Triplet NetWork`的主体思想是什么
4. `loss`中$\alpha$的作用

## Triplet Network

> 既然`Siamese`网络是衡量两个样本间的相似度，`Triple Network`是衡量三个样本间的相似度
>
> 且**Triple Network的效果要好于Siamese Network**

`Triple Network`的主体思想是：

> 相同类别间的距离尽可能的小，不同类别间的距离尽可能的大

### 网络结构图：

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1338991-20181213135951412-1275320373.png" style="zoom:80%;">

**输入解释**

* Anchor表示需要衡量的图片（输入）
* Postive表示正类图片
* negative表示负类图片

### Loss函数

$$
L(A,P,N)=max(D_w(A,P)-D_w(A,N)+\alpha,0)
$$

>  $D_w$表示两个输入值在经过子网络后的距离，有：
>  $$
>  D_w(X,Y)=\sqrt{[G_w(X)-G_w(Y)]^2}
>  $$
>  其中，$G_w$表示经过网络的输出（也就是`Embedding`层）

对`loss`函数的理解：

> 同`Siamese`网络，$\alpha$的大小直接衡量了学习的难度，$\alpha$越大，则学习的难度越大,要求：
> $$
> D_w(A,P) + \alpha \leqslant D_w(A,N)
> $$

## 参考

> * https://www.cnblogs.com/Lee-yl/p/10113386.html
>* https://blog.csdn.net/koala_tree/article/details/78647528
> * [论文原文](https://arxiv.org/pdf/1412.6622.pdf)

]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Siamese网络</title>
    <url>/posts/e2e6b321.html/</url>
    <content><![CDATA[
# Siamese网络

## Question

1. 孪生网络的两个网络结构需要相同吗？权重是否一定要一致？
2. 孪生网络的大体流程
3. 在生成的结果中，两个向量的相似程度如何计算？是直接算欧氏距离还是loss
4. 孪生网络中的loss中m的作用，增大m会有什么影响
5. 2-Channel的主体思想
6. Triple Network的主体思想

## Siamese网络

### 作用

> Siamese适用的情景：
>
> 1. 少样本甚至1个样本的情况（俗称的One-Shot 或者Few-Shot问题）
> 2. 分类的类别数不确定

### 主体思想

> 样本通过网络编码，量化为一个向量，最后计算向量之间的相似度

<img src="https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1338991-20181213123654582-1284082097.png" style="zoom:50%;">

图中，input 1和input 2是需要对比的两个输入，输入可以是图像，可以是文本，甚至可以是数字

两个输入通过网络之后均形成一个向量，然后对比两个向量的相似程度**（也就是Loss）**

### 损失函数

$$
（1-Y）\frac{1}{2}(D_w)^2+(Y)\frac{1}{2}[max(0,m-D_w)^2]
$$

* 其中$D_w$表示两个姐妹子网络输出的欧氏距离,如下：
  $$
  D_w=\sqrt{[G_w(X_1)-G_w(X_2)]^2}
  $$

* Y为label，如果两个子网络输出相似，则0，否则为1

* $m$表示边际价值，为一个自己设定的参数。实际上，我的理解是加大学习的难度。**就是说，m越大，则学习的难度越大**

## 改进

### 2-Channel

> 个人认为，2-Channel在结果上可能并不能改进什么，可能在速度上有所改进

2-Channel的主体思想如下：

将两个输入的图片合成一张，看成是有多个通道的图片，然后一起带入网络中。此时，**两张图片就可以通过CNN一起卷积**，卷积的结果最后代入后面的全连接层，最终输出一个结果。该结果为0表示相同，1表示不同。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/1338991-20181213130146077-1166762109.png)

### Triple Network

> 既然Siamese网络是衡量两个样本间的相似度，Triple Network是衡量三个样本间的相似度

Triple Network笔记：[Triple Network ](Triple网络.md)

## 对Siamese网络以及度量学习的一点理解

**loss的大小并不能完全表示度量模型学习程度的好坏**

（以下是本人的一些理解，仅供参考）

### 结果指标

下面是一个本人在一次Metric Learning任务中训练所得的Siamese模型，得到的Train Loss和Validation Loss如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/火狐截图_2020-05-26T08-40-16.697Z.png)

可以看到Train和Validation  Loss都较小。

通过以上的模型，通过移动阈值，可以绘制$FAR$和$FRR$曲线，所得的验证集的$FAR$和$FRR$曲线如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/低loss对应指标.png)

根据上图得到的$ERR$点结果如下：

> * $FAR = FRR = 0.5933333333333334$
>
> * $threshoold = 0.516687226098579$

并附上预测结果

|      | Predict Distance | Label |
| ---- | ---------------- | ----- |
| 0    | 0.511279         | 0.0   |
| 1    | 0.500313         | 0.0   |
| 2    | 0.511920         | 1.0   |
| 3    | 0.512624         | 1.0   |
| 4    | 0.504918         | 1.0   |
| 5    | 0.861020         | 0.0   |
| 6    | 0.500000         | 0.0   |
| 7    | 0.499787         | 0.0   |
| 8    | 0.510990         | 1.0   |
| 9    | 0.516549         | 1.0   |
| 10   | 0.500447         | 1.0   |
| 11   | 0.874551         | 0.0   |
| 12   | 0.516883         | 0.0   |
| 13   | 0.514373         | 0.0   |
| 14   | 0.528016         | 1.0   |
| 15   | 0.515205         | 1.0   |
| 16   | 0.516599         | 1.0   |
| 17   | 0.860529         | 0.0   |
| 18   | 0.508360         | 0.0   |
| 19   | 0.503932         | 0.0   |
| 20   | 0.515846         | 1.0   |

可以看到以上模型预测的结果（也就是两个子网络的距离）基本上都在0.5左右，在计算Loss时，再加上平方（参见[Siamese Loss](#损失函数)），造成算出的Loss结果就会相当的小，但$FAR$和$FRR$却居高不下。换句话说，该模型根本没有辨识能力，loss效果却相当的好看。

另外，反过来看，Loss大不一定代表模型不好，如下图。

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/火狐截图_2020-05-28T08-28-47.927Z.png)

得到的$ERR$图如下：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/index1.png)

$ERR$结果:

> * $FAR = FRR = 0.3559322033898305$
>
> * $threshoold = 0.1881966181994088$

## 参考

> * https://www.cnblogs.com/Lee-yl/p/10113386.html
>
> * https://blog.csdn.net/qq_35826213/article/details/86313469]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown语法手册(转)</title>
    <url>/posts/60b0c1f1.html/</url>
    <content><![CDATA[
# Cmd Markdown 简明语法手册

---

### 1. 斜体和粗体

使用 * 和 ** 表示斜体和粗体。

示例：

这是 *斜体*，这是 **粗体**。

### 2. 分级标题

使用 === 表示一级标题，使用 --- 表示二级标题。

示例：

<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">这是一个一级标题</span><br><span class="line">============================</span><br><span class="line"></span><br><span class="line">这是一个二级标题</span><br><span class="line">--------------------------------------------------</span><br><span class="line"></span><br><span class="line">### 这是一个三级标题</span><br></pre></td></tr></table></figure>

你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。

### 3. 外链接

使用 \[描述](链接地址) 为文字增加外链接。

示例：

这是去往 [本人博客](http://ghosertblog.github.com) 的链接。

### 4. 无序列表

使用 *，+，- 表示无序列表。

示例：

- 无序列表项 一
- 无序列表项 二
- 无序列表项 三

### 5. 有序列表

使用数字和点表示有序列表。

示例：

1. 有序列表项 一
2. 有序列表项 二
3. 有序列表项 三

### 6. 文字引用

使用 > 表示文字引用。

示例：

> 野火烧不尽，春风吹又生。

### 7. 行内代码块

使用 \`代码` 表示行内代码块。

示例：

让我们聊聊 `html`。

### 8.  代码块

使用 四个缩进空格 表示代码块。

示例：

    这是一个代码块，此行左侧有四个不可见的空格。

### 9.  插入图像

使用 \!\[描述](图片链接地址) 插入图像。

示例：

![我的头像](https://www.zybuluo.com/static/img/my_head.jpg)

# Cmd Markdown 高阶语法手册

### 1. 内容目录

在段落中填写 `[TOC]` 以显示全文内容的目录结构。

[TOC]

### 2. 标签分类

在编辑区任意行的列首位置输入以下代码给文稿标签：

标签： 数学 英语 Markdown

或者

Tags： 数学 英语 Markdown

### 3. 删除线

使用 ~~ 表示删除线。

~~这是一段错误的文本。~~

### 4. 注脚

使用 [^keyword] 表示注脚。

这是一个注脚[^footnote]的样例。

这是第二个注脚[^footnote2]的样例。

### 5. LaTeX 公式

$ 表示行内公式： 

质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。

$$ 表示整行公式：

$$\sum_{i=1}^n a_i=0$$

$$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$

$$\sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}$$

访问 [MathJax](http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) 参考更多使用方法。

### 6. 加强的代码块

支持四十一种编程语言的语法高亮的显示，行号显示。

非代码示例：

<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ sudo apt-<span class="builtin-name">get</span> install vim-gnome</span><br></pre></td></tr></table></figure>

Python 示例：

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@requires_authorization</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">somefunc</span><span class="params">(param1=<span class="string">''</span>, param2=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''A docstring'''</span></span><br><span class="line">    <span class="keyword">if</span> param1 &gt; param2: <span class="comment"># interesting</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Greater'</span></span><br><span class="line">    <span class="keyword">return</span> (param2 - param1 + <span class="number">1</span>) <span class="keyword">or</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SomeClass</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>message = <span class="string">'''interpreter</span></span><br><span class="line"><span class="string"><span class="meta">... </span>prompt'''</span></span><br></pre></td></tr></table></figure>

JavaScript 示例：

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* nth element in the fibonacci series.</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param </span>n &gt;= 0</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return </span>the nth element, &gt;= 0.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">fib</span>(<span class="params">n</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> a = <span class="number">1</span>, b = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">var</span> tmp;</span><br><span class="line">  <span class="keyword">while</span> (--n &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    tmp = a;</span><br><span class="line">    a += b;</span><br><span class="line">    b = tmp;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">document</span>.write(fib(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>

### 7. 流程图

#### 示例

<div id="flowchart-0" class="flow-chart"></div>

#### 更多语法参考：[流程图语法参考](http://adrai.github.io/flowchart.js/)

### 8. 序列图

#### 示例 1

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Alice-&gt;Bob: Hello Bob, how are you?</span><br><span class="line">Note right of Bob: Bob thinks</span><br><span class="line">Bob--&gt;Alice: I am good thanks!</span><br></pre></td></tr></table></figure>

#### 示例 2

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Title: Here is a title</span><br><span class="line">A-&gt;B: Normal line</span><br><span class="line">B--&gt;C: Dashed line</span><br><span class="line">C-&gt;&gt;D: Open arrow</span><br><span class="line">D--&gt;&gt;A: Dashed open arrow</span><br></pre></td></tr></table></figure>

#### 更多语法参考：[序列图语法参考](http://bramp.github.io/js-sequence-diagrams/)

### 9. 甘特图

甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">title 项目开发流程</span><br><span class="line">section 项目确定</span><br><span class="line">    需求分析       :a1, 2016-06-22, 3d</span><br><span class="line">    可行性报告     :after a1, 5d</span><br><span class="line">    概念验证       : 5d</span><br><span class="line">section 项目实施</span><br><span class="line">    概要设计      :2016-07-05  , 5d</span><br><span class="line">    详细设计      :2016-07-08, 10d</span><br><span class="line">    编码          :2016-07-15, 10d</span><br><span class="line">    测试          :2016-07-22, 5d</span><br><span class="line">section 发布验收</span><br><span class="line">    发布: 2d</span><br><span class="line">    验收: 3d</span><br></pre></td></tr></table></figure>

#### 更多语法参考：[甘特图语法参考](https://knsv.github.io/mermaid/#gant-diagrams)

### 10. Mermaid 流程图

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A[Hard edge] --&gt;|Link text| B(Round edge)</span><br><span class="line">B --&gt; C&#123;Decision&#125;</span><br><span class="line">C --&gt;|One| D[Result one]</span><br><span class="line">C --&gt;|Two| E[Result two]</span><br></pre></td></tr></table></figure>

#### 更多语法参考：[Mermaid 流程图语法参考](https://knsv.github.io/mermaid/#flowcharts-basic-syntax)

### 11. Mermaid 序列图

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Alice-&gt;John: Hello John, how are you?</span><br><span class="line">loop every minute</span><br><span class="line">    John--&gt;Alice: Great!</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

#### 更多语法参考：[Mermaid 序列图语法参考](https://knsv.github.io/mermaid/#sequence-diagrams)

### 12. 表格支持

| 项目   |   价格 | 数量 |
| ------ | -----: | :--: |
| 计算机 | \$1600 |  5   |
| 手机   |   \$12 |  12  |
| 管线   |    \$1 | 234  |


### 13. 定义型列表

名词 1
:   定义 1（左侧有一个可见的冒号和四个不可见的空格）

代码块 2
:   这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格）

        代码块（左侧有八个不可见的空格）

### 14. Html 标签

本站支持在 Markdown 语法中嵌套 Html 标签，譬如，你可以用 Html 写一个纵跨两行的表格：

    <table>
        <tr>
            <th rowspan="2">值班人员</th>
            <th>星期一</th>
            <th>星期二</th>
            <th>星期三</th>
        </tr>
        <tr>
            <td>李强</td>
            <td>张明</td>
            <td>王平</td>
        </tr>
    </table>


<table>
    <tr>
        <th rowspan="2">值班人员</th>
        <th>星期一</th>
        <th>星期二</th>
        <th>星期三</th>
    </tr>
    <tr>
        <td>李强</td>
        <td>张明</td>
        <td>王平</td>
    </tr>
</table>

### 15. 内嵌图标

本站的图标系统对外开放，在文档中输入

    <i class="icon-weibo"></i>

即显示微博的图标： <i class="icon-weibo icon-2x"></i>

替换 上述 `i 标签` 内的 `icon-weibo` 以显示不同的图标，例如：

    <i class="icon-renren"></i>

即显示人人的图标： <i class="icon-renren icon-2x"></i>

更多的图标和玩法可以参看 [font-awesome](http://fortawesome.github.io/Font-Awesome/3.2.1/icons/) 官方网站。

### 16. 待办事宜 Todo 列表

使用带有 [ ] 或 [x] （未完成或已完成）项的列表语法撰写一个待办事宜列表，并且支持子列表嵌套以及混用Markdown语法，例如：

    - [ ] **Cmd Markdown 开发**
        - [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率
        - [ ] 支持以 PDF 格式导出文稿
        - [x] 新增Todo列表功能 [语法参考](https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments)
        - [x] 改进 LaTex 功能
            - [x] 修复 LaTex 公式渲染问题
            - [x] 新增 LaTex 公式编号功能 [语法参考](http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers)
    - [ ] **七月旅行准备**
        - [ ] 准备邮轮上需要携带的物品
        - [ ] 浏览日本免税店的物品
        - [x] 购买蓝宝石公主号七月一日的船票

对应显示如下待办事宜 Todo 列表：
        
- [ ] **Cmd Markdown 开发**
    - [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率
    - [ ] 支持以 PDF 格式导出文稿
    - [x] 新增Todo列表功能 [语法参考](https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments)
    - [x] 改进 LaTex 功能
        - [x] 修复 LaTex 公式渲染问题
        - [x] 新增 LaTex 公式编号功能 [语法参考](http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers)
- [ ] **七月旅行准备**
    - [ ] 准备邮轮上需要携带的物品
    - [ ] 浏览日本免税店的物品
    - [x] 购买蓝宝石公主号七月一日的船票
      
        
[^footnote]: 这是一个 *注脚* 的 **文本**。

[^footnote2]: 这是另一个 *注脚* 的 **文本**。<script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: Start:>https://www.zybuluo.com
io=>inputoutput: verification
op=>operation: Your Operation
cond=>condition: Yes or No?
sub=>subroutine: Your Subroutine
e=>end

st->io->op->cond
cond(yes)->e
cond(no)->sub->io</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script>]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>人物背景抠图 (二)</title>
    <url>/posts/cc52d48c.html/</url>
    <content><![CDATA[

# 效果  

## 当前效果

本文章是对<a href="/posts/10cdf8fe.html/" title="人物背景抠图">人物背景抠图</a>的改进,先看效果图:

**原图像:**

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/效果原图像-1580099162567.png)

**本次替换后:**

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/改进效果.png)

## 原效果

对比<a href="/posts/10cdf8fe.html/" title="人物背景抠图">人物背景抠图</a>中的效果:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/效果图-1580099178206.png)

可以看到,针对原效果中结果不太好的有明显改进.例如第一行第四张图片,人物的头发处有许多的"空洞",在改进后得到了填充;第二行第一张图片,原效果背景也有许多"空洞",改进后有明显改善.

# 过程及思路

事实上,对于这个特定任务,分离前景和背景,前景对象有且仅有一个,从图(数据结构中的图)的角度上看,我只需要找到一个连通域即可,其他的连通域都可以看成是误识别的结果,应该合并成背景.并且,这个前景对应的连通域应该是最大的连通域.下面介绍过程:

下面是对原图像进行掩膜后的结果(开运算后):

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/开运算结果.png)

可以看到一般效果较好的图片对应的掩膜结果都比较成型,且仅有一个连通域,而效果不好的有多个连通域,通常情况下,最大的连通域就是人物,所以,我们选择最大的连通域作为掩膜结果,下面以第一行第4张图片为例,在得到掩膜结果后我们对连通域编号,并计算每个连通域的大小:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取连通图并找出最大连通图</span></span><br><span class="line">contours,hierarchy = cv2.findContours(template_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">areas = list()</span><br><span class="line"><span class="keyword">for</span> contour <span class="keyword">in</span> contours:</span><br><span class="line">    areas.append(cv2.contourArea(contour))</span><br><span class="line">max_contour_index = np.argmax(areas)</span><br><span class="line">print(<span class="string">"最大连通图: &#123;&#125;"</span>.format(max_contour_index))</span><br></pre></td></tr></table></figure>

在得到每个连通域大小后,找到最大的连通域:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w,h = template_img.shape</span><br><span class="line">black_back = np.zeros(shape=(w,h,<span class="number">3</span>))</span><br><span class="line">plt.imshow(cv2.drawContours(black_back, contours, max_contour_index, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

下面是最大连通域对应的外边框:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/最大连通域.png)

最大连通域中有许多背景空洞,我们需要填充:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">template_img = np.zeros(shape=template_img.shape)</span><br><span class="line">template_img = cv2.fillConvexPoly(template_img,contours[max_contour_index],(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br></pre></td></tr></table></figure>

最终结果:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r_img = replace_img(img,template_img,back_img)</span><br><span class="line">plt.imshow(r_img)</span><br></pre></td></tr></table></figure>

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/单图测试.png)

# 问题及改进思路

## 前景和背景边缘问题

> 如上图,前景和背景是有明显的毛边的.事实上,在之前的步骤中,并没有利用边缘检测技术对边缘修正,或者,现在我们的前景和背景已经大致的分出来了,利用Graph Cut或Grab Cut算法来修正应该更加精准.

## 前景和背景颜色相近问题

> 这个问题并没有想到解决办法,Grab Cut对于此类问题效果并不理想.或许利用Selective Search中的动态阈值来修正前景和背景效果会比较好,但我并没有尝试过.

如果你有什么想法或者解决思路,请在下方留言.]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>Demo</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOV3总结</title>
    <url>/posts/69cad793.html/</url>
    <content><![CDATA[
以下是`YOLO V3`的结构图：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210423111811.jpg)

总的来说,YOLO V3针对V2的改进并不多,有以下几点: 

1. 网络结构的改变

   > YOLO V3采用Darknet-53 的网络结构,整个网络采用全卷积结构,相比于ResNet-152和ResNet-101强很多,速度也更快

2. Anchor Box

   > 由于 YOLO V1和V2 都对小目标支持不好,所以,V3在这上面作出了改进,对大中小目标分别进行处理,大目标的Feature Map缩小,中小目标的Feature Map呈放大
   >
   > V3的Anchor Box一共9个,大中小各3个

3. Loss Function

   > V3不再用softmax,而是用logistic(即对每一类做logistic),其目的还是对应V2中出现]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测 - 计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>KCF目标跟踪测试</title>
    <url>/posts/849e7948.html/</url>
    <content><![CDATA[

        <style>.bbplayer{width: 100%; max-width: 850px; margin: auto}</style>
        <div class="bbplayer">
        <iframe class="bbplayer" id="mmedia-ZuxuUuVd" src="//player.bilibili.com/player.html?aid=85098088&page=1&high_quality=1&danmaku=true" allowfullscreen="no" scrolling="no" frameborder="0" sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups"></iframe>
        </div>
        <script>
            document.getElementById("mmedia-ZuxuUuVd").style.height=document.getElementById("mmedia-ZuxuUuVd").scrollWidth*0.76+"px";
            window.onresize = function(){
              document.getElementById("mmedia-ZuxuUuVd").style.height=document.getElementById("mmedia-ZuxuUuVd").scrollWidth*0.76+"px";
            };
        </script>
        ]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>Demo</tag>
        <tag>计算机视觉</tag>
        <tag>目标跟踪</tag>
      </tags>
  </entry>
  <entry>
    <title>mAP的计算总结</title>
    <url>/posts/b8ba7454.html/</url>
    <content><![CDATA[
## Question

* `mAP`的流程

## mAP的流程

`mAP`是目标检测中最为常见的指标,要了解`mAP(mean Average Precision)`,就必须了解`recall`和`precision`(目标检测中这两个指标的计算和略有机器学习不同)

| 真\预 |  正  | 负   |
| ----: | :--: | :--- |
|    正 |  TP  | FN   |
|    负 |  FP  | TN   |

首先,在进行目标检测时,预测出一个`BBox`,和对应某类$i$的概率$P_i$,给出一个阈值$t$,即可以判断出预测是否是这一类,即判定上表中在第一列还是第二列.

然后,对于上一部中分到第一列的,计算`BBox`和`Ground Truth`的`IOU`,大于0.5的标为`TP`,小于为`FP`.最后,对于1中第二列的标为`FN`.

根据公式:

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow>
    <mo>{</mo>
    <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
      <mtr>
        <mtd>
          <mi>R</mi>
          <mo>=</mo>
          <mfrac>
            <mrow>
              <mi>T</mi>
              <mi>P</mi>
            </mrow>
            <mrow>
              <mo stretchy="false">(</mo>
              <mi>T</mi>
              <mi>P</mi>
              <mo>+</mo>
              <mi>F</mi>
              <mi>N</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mtd>
      </mtr>
      <mtr>
        <mtd>
          <mi>P</mi>
          <mo>=</mo>
          <mfrac>
            <mrow>
              <mi>T</mi>
              <mi>P</mi>
            </mrow>
            <mrow>
              <mo stretchy="false">(</mo>
              <mi>F</mi>
              <mi>P</mi>
              <mo>+</mo>
              <mi>T</mi>
              <mi>P</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mtd>
      </mtr>
    </mtable>
    <mo fence="true" stretchy="true" symmetric="true"></mo>
  </mrow>
</math>

<!--
$$
\begin{cases} R = \frac{TP}{(TP+FN)} \\ P=\frac{TP}{(FP + TP)}\end{cases}
$$



-->

对于上述给定的阈值$t$,逐渐减小,可形成多组`RP`数据对,在坐标上绘制,其与坐标轴围成的面积即为`AP`值.如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/2019042821031836.png)

## 参考

* https://blog.csdn.net/xiezongsheng1990/article/details/89608923]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLO9000总结</title>
    <url>/posts/5ca973ed.html/</url>
    <content><![CDATA[
# Question

* Better体现在哪些方面
* Anchor Box的数据结构是怎样的
* Anchor Box 聚类的衡量标准是什么
* 约束预测边框的目的是什么，是怎么做的
* pass through层是怎么做的
* 对于Faster，YOLOV2采用了什么办法
* 何为WordTree，如何构成
* 在WordTree上如何打标签
* WordTree上非根节点表示什么
* 一个类别的绝对概率如何计算
* 在许多类时，绝对阈值计算如何处理

# Better:

## Batch Normalization

通过在`YOLO`的所有卷积层上添加`Batch Normalization`层，发现`mAP`提高了$2 \%$

## High Resolution Classifier

在`YOLOV1`的版本中，采用$224 \times 224$ 的输入，在`V2`版本中加入$448 \times 448$的图片对模型训练，发现模型提高了$4\%$的`mAP`值

具体过程是先用$224 \times 224$的图片训练160个`epoch`，再用$448 \times 448$的图片训练10个`epoch`

## Convolutional With Anchor Boxes

去掉`V1`中的全连接层，仿照`Faster R-CNN`加入`Anchor Box` 

## Dimension Cluster

在`YOLO V2`中的`Anchor Box`的长宽比并未采用`Faster R-CNN`的手动输入，而是采用用`Ground Truth`聚类的方式，所用的聚类算法采用`K-Means`,距离的度量指标为：
$$
D(box,centroid)=1-IOU(box,centroid)
$$
其中，$box$表示一个`Ground Truth`的框，$centroid$表示聚点的框，$IOU(box,centroid)$表示一个`Ground Truth`和聚点之间的$IOU$.

至于 $K$  的选择，文中作者选择了5个`Anchor Box`,至于为什么选择5个，用作者的话说就是在效果和复杂度之间找到一个平衡。如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210420104719.png)

从图中可以看出，在5个`Anchor Box`之后平均的$IOU$增长并没有这么快了，所以这里选择5个。

## Direct location prediction

在`Faster R-CNN`中，是直接预测的$t$,也就是直接预测的`Ground Truth`和`Anchor Box`的偏移量。在`YOLO V2`中，论文沿用的`V1`的概念，以$grid \ cell$为单位计算，也就是说，`YOLO V2`预测的是相对于$grid \ cell$的偏移量：
$$
b_x = \sigma(t_x) + c_x
$$

$$
b_y =\sigma(t_y)+c_y
$$

$$
b_w=p_we^{t_w}
$$

$$
b_h=p_he{t_h}
$$

上式中，$\sigma$表示一个$sigmoid$函数，利用$sigmoid$,可以将偏移量限制在$(0,1)$之间.$c_x$和$c_y$表示当前$grid \ cell$相对于左上角的坐标（**注意，不是距离**），如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210423104433.png)

加入$sigmoid$函数的目的：在模型训练的早期，预测的`box`并不稳定，所以加入$sigmoid$函数使预测结果固定在$(0,1)$之间

## Fine-Grained Features

加入Pass Through层，过程如下

> Pass Through层类似做步数为2的Pooling,按照相同位置组合成4个块,最后再在通道上叠加,比如上一层的输出为$26 \times 26 \times 512$,拆分成$4 \times 13 \times 13 \times 512$ 最后组成$13 \times 13 \times 3072$

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/passthrough1.jpg)

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/passthrough2.jpg)

## Mult-Scale Training

YOLO V2在训练的时候每经过几轮（每经过10epochs）迭代后就会微调网络，随机选择新的图片尺寸。YOLO网络使用的降采样参数为32，那么就使用32的倍数进行尺度{320,352,⋯，608}

# Faster:

采用Darknet-19网络结构，结构如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210423111421.png)

# Stronger(YOLO 9000)

为了能识别9000个目标,构建了一个WordTree,与一般的$softmax$不同的是类别本身和气父节点均需标记为1.比如Dog,在Animal位置也需标记为1.

!['WordTree'](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/WordTree.png)

在预测时,一个类别的概率为根节点到该节点所有概率的乘积,如
$$
P(Hunting Dog)=p(Hunting Dog|Dog, Animal)P(Dog| Animal)
$$
其中,由于Animal处于根节点有$P(Animal)=1$

注:在实际计算绝对概率时,并不会真的计算每一个子节点的概率,而是采用贪婪算法,当从根节点项子节点走时,如果小于阈值,则不在向下走了.》

# 参考

> * [Direct location prediction详细说明](https://www.cnblogs.com/wangguchangqing/p/10480995.html)
> * 吴恩达DeepLearningai系列课程]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLO V1总结</title>
    <url>/posts/16c1a0a5.html/</url>
    <content><![CDATA[
YOLO​ v1的总结,备忘

## Question

* 对于不同尺寸的输入图像YOLO是怎么解决的
* YOLO V1输出的数据结构如何（几维数据，每一维数据分别代表什么）
* 为何YOLO V1要用两个BBox
* 标签中的$Confidence$如何确定
* $Confidence$是什么时候得到的
* YOLO的$Loss$是$L1 Loss$还是$L2 Loss$
* YOLO V1的优点及缺点

## 网络设计

YOLO算法的设计理念是将图像分成$s \times s$的网络结构,每个网格分别来判定是否目标在其中,这其中运用了用卷积层来代替全连接层,这项技术是Idea的关键.所以最终的结果是

$$s \times  s \times(B \times 5 + C)$$

其中,B表示BBox的个数,C代表类别个数,5表示(x,y,w,h,confidence)。

总体的网络图如下图所示：

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/20210319133657.png)

## 训练

由于YOLO算法是将图像切割成方格并预测的思想,所以对图像的输入尺寸并不敏感.

在输出方面,如下图所示:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/YOLOV1结构.jpg)

1. Feature Map中的一个值给出一个预测,为何输出中却是两个BBox?

> YOLO由3类标签组成:类别,置信度,BBox位置.其中Feature Map中的一个值有两个BBox,而仅有一个One-Hot类别向量.之所以用两个BBox,文中的解释是:两个BBox用结果好的那个,另一个舍去,这样总好过仅用一个BBox的结果.
>
> 那么,怎么样判定哪一个BBox结果好呢,答案是IOU,即$IOU_{pred}^{truth}$,选择IOU大的那个

2. 训练集中的confidence如何确定?

> 在1中可以得到$IOU_{pred}^{truth}$,如果该Feature Map值中有物体,则为IOU,否则为0.
>
> $$ confidenc标签=\begin{cases} IOU_{pred}^{truth},&有物体\\ 0,&无物体 \end{cases}$$
>
> 值得说明的是,两个BBox,一个为$IOU_{pred}^{truth}$,另一个的confidence也为0



## LOSS函数

由于`YOLO`的结果分为三部分（即位置，confidence以及class），所以，其`loss`函数也分为三部分：
$$
loss= \sum_{i=0}^{s^2}\sum_{j=0}^{B}{ coord_{err}+confidence_{err}+class_{err}}
$$
其中，$coord_{err}$表示坐标的`loss`,$confidence_{err}$表示置信度的`loss`,$class_{err}$表示分类的`loss`。

* 坐标的`loss`可以展开为：
  $$
  coord_{err}=\lambda_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}1_{ij}^{obj}[(x_i-\hat{x_i})^2+(y_i-\hat{y_i})^2]+\lambda_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}1_{ij}^{obj}[(\sqrt{w_i}-\sqrt{\hat{w_i}})^2+(\sqrt{h_i}-\sqrt{\hat{h_i}})^2]
  $$
  其中，有帽的表示标注值，否则表示预测值。$\lambda_{coord}$表示坐标权重，实际上也可以看成坐标的`loss`在总的`loss`中所占的权重。$1_{ij}^{obj}$表示该方格是否有物体，有物体则为1，否则为0。可以看出，坐标的`loss`仅关心有物体的`cell`，无物体的不计入`loss`范围内。

* $confidence$的`loss`展开为：

$$
confidence_{err}=\sum_{i=0}^{S^2}\sum_{j=0}^{B}1_{ij}^{obj}(C_i-\hat{C_i})^2+\lambda_{noobj}\sum_{i=0}^{S^2}\sum_{j=0}^{B}1_{ij}^{noobj}(C_i-\hat{C_i})^2
$$

​		其中，$\lambda_{noobj}$表示没有物体的权重，在实际的预测任务中，有物体的`cell`会多于没有物体的`cell`,这就造成两者的不均衡，所以这里加入一个权重参数，以平衡两者。论文中$\lambda_{noobj}=0.5$.

* class的loss展开为：

$$
\sum_{i=0}^{S^2}1_{i}^{obj}\sum_{c\in{classes}}(p_i(c)-\hat{p_i}(c))^2
$$

​		同坐标的`loss`一样，分类的`loss`也仅用有物体的`cell`，并且，**分类也是采用的回归**，非`Cross-Entropy`.

整体的Loss如下所示：

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true">
    <mlabeledtr>
      <mtd id="mjx-eqn-1">
        <mtext>(1)</mtext>
      </mtd>
      <mtd>
        <mi>L</mi>
        <mi>o</mi>
        <mi>s</mi>
        <mi>s</mi>
        <mo>=</mo>
        <msub>
          <mi>&#x03BB;<!-- λ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>c</mi>
            <mi>o</mi>
            <mi>o</mi>
            <mi>r</mi>
            <mi>d</mi>
          </mrow>
        </msub>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msup>
              <mi>S</mi>
              <mn>2</mn>
            </msup>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">[</mo>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>x</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>x</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>y</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>y</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo stretchy="false">]</mo>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <msub>
          <mi>&#x03BB;<!-- λ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>c</mi>
            <mi>o</mi>
            <mi>o</mi>
            <mi>r</mi>
            <mi>d</mi>
          </mrow>
        </msub>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msup>
              <mi>S</mi>
              <mn>2</mn>
            </msup>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">[</mo>
          <mo stretchy="false">(</mo>
          <msqrt>
            <msub>
              <mi>w</mi>
              <mi>i</mi>
            </msub>
          </msqrt>
          <mo>&#x2212;<!-- − --></mo>
          <msqrt>
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <msub>
                  <mi>w</mi>
                  <mi>i</mi>
                </msub>
                <mo stretchy="false">&#x005E;<!-- ^ --></mo>
              </mover>
            </mrow>
          </msqrt>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <mo stretchy="false">(</mo>
        <msqrt>
          <msub>
            <mi>h</mi>
            <mi>i</mi>
          </msub>
        </msqrt>
        <mo>&#x2212;<!-- − --></mo>
        <msqrt>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>h</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </msqrt>
        <msup>
          <mo stretchy="false">)</mo>
          <mn>2</mn>
        </msup>
        <mo stretchy="false">]</mo>
        <mo>+</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>S</mi>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>c</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>c</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <msub>
          <mi>&#x03BB;<!-- λ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
            <mi>o</mi>
            <mi>o</mi>
            <mi>b</mi>
            <mi>j</mi>
          </mrow>
        </msub>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>S</mi>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>n</mi>
              <mi>o</mi>
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>c</mi>
            <mi>i</mi>
          </msub>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>c</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <msup>
            <mo stretchy="false">)</mo>
            <mn>2</mn>
          </msup>
          <mo>+</mo>
        </mstyle>
        <mspace linebreak="newline">
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msup>
              <mi>S</mi>
              <mn>2</mn>
            </msup>
          </mrow>
        </munderover>
        <mstyle mathsize="1.2em">
          <msubsup>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mi>j</mi>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>o</mi>
              <mi>b</mi>
              <mi>j</mi>
            </mrow>
          </msubsup>
          <munder>
            <mo>&#x2211;<!-- ∑ --></mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>C</mi>
              <mo>&#x2208;<!-- ∈ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>c</mi>
                <mi>l</mi>
                <mi>a</mi>
                <mi>s</mi>
                <mi>s</mi>
              </mrow>
            </mrow>
          </munder>
          <mo stretchy="false">[</mo>
          <msub>
            <mi>p</mi>
            <mi>i</mi>
          </msub>
          <mo stretchy="false">(</mo>
          <mi>c</mi>
          <mo stretchy="false">)</mo>
          <mo>&#x2212;<!-- − --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <msub>
                <mi>p</mi>
                <mi>i</mi>
              </msub>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
          <mo stretchy="false">(</mo>
          <mi>c</mi>
          <mo stretchy="false">)</mo>
          <msup>
            <mo stretchy="false">]</mo>
            <mn>2</mn>
          </msup>
        </mstyle>
      </mspace></mspace></mspace></mspace></mtd>
    </mlabeledtr>
  </mtable>
</math>

<!-- 以下公式hexo无法换行,用以下公式生成MathML,粘贴在上面
$$
Loss=\lambda_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}\large 1_{ij}^{obj}[(x_i-\hat{x_i})^2+(y_i-\hat{y_i})^2] + \\
\lambda_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}\large 1_{ij}^{obj}[(\sqrt{w_i}-\sqrt{\hat{w_i}})^2+\\
(\sqrt{h_i}-\sqrt{\hat{h_i}})^2]+ \sum_{i=0}^{S}\sum_{j=0}^{B} \large 1_{ij}^{obj} (c_i-\hat{c_i})^2 + \\ 
\lambda_{noobj}\sum_{i=0}^{S}\sum_{j=0}^{B} \large 1_{ij}^{noobj} (c_i-\hat{c_i})^2 +\\
\sum_{i=0}^{S^2}\large 1_{ij}^{obj}\sum_{C\in{class}}[p_i(c)-\hat{p_i}(c)]^2
$$
-->

YOLO 算法的LOSS是一个L2 LOSS

## 预测

对于模型得出的$S\times S \times 2$个BBox

> 1. 先用NMS得出一系列BBox(依据是confidence)
>
> 2. 再在这些框中选最大概率的类别
> 

## 优点以及缺点
> 优点:
>
> 1. 速度快
> 2.  End-2-End
>
> 缺点: 
>
> 1. 小物体效果不好
>
> 2. 定位不准确	]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>人物背景抠图</title>
    <url>/posts/10cdf8fe.html/</url>
    <content><![CDATA[
## 示例图片

免冠照人物背景抠图实现,先展示一下示例结果:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/原始示例图片.png)

人物背景抠图后:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/替换示例图片.png)

## 执行步骤

### 将RGB空间转换为HSV空间

首先需要统计出背景(蓝色部分)的颜色范围,这里将RGB空间转换为HSV空间,然后只用H分量统计,就可以统计出蓝色背景的大概范围:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">blue_photo_hsv = cv2.cvtColor(blue_photo,cv2.COLOR_RGB2HSV)</span><br><span class="line">h_ele = blue_photo_hsv[:,:,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

### 做H分量的统计

为了简单起见,这里截取上1/6的部分图像

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">sns.set_style(<span class="string">"darkgrid"</span>)</span><br><span class="line"></span><br><span class="line">w,h,_= blue_photo_hsv.shape</span><br><span class="line">hist_bins = plt.hist(blue_photo_hsv[:int(w/<span class="number">6</span>),:,<span class="number">0</span>].flatten(),bins = <span class="number">60</span>)</span><br></pre></td></tr></table></figure>

直方图统计结果:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/直方图结果.png)

### 掩膜

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lower_h = hist_bins[<span class="number">1</span>][hist_bins[<span class="number">0</span>].argmax()]</span><br><span class="line">bins_interval = hist_bins[<span class="number">1</span>][<span class="number">1</span>] - hist_bins[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">upper_h = lower_h + <span class="number">1</span> * bins_interval</span><br><span class="line">lower = np.array([lower_h,<span class="number">43</span>,<span class="number">46</span>])</span><br><span class="line">upper = np.array([upper_h,<span class="number">256</span>,<span class="number">256</span>])</span><br><span class="line"></span><br><span class="line">mask = cv2.inRange(blue_photo_hsv, lower,upper)</span><br><span class="line">plt.imshow(mask)</span><br></pre></td></tr></table></figure>

掩膜结果:

!['掩膜结果'](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/掩膜结果.png)

### 腐蚀和膨胀

腐蚀的目的是去除分割线周围的噪声,膨胀是填补掩膜结果中的小空白.这里的腐蚀和膨胀的模板都是用的3*3

腐蚀:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 取反</span></span><br><span class="line">mask = <span class="number">255</span> - mask</span><br><span class="line"><span class="comment"># 边长</span></span><br><span class="line">side_len = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">kernel = np.ones((side_len,side_len))</span><br><span class="line">erode_img = cv2.erode(mask,kernel,iterations = <span class="number">1</span>)</span><br><span class="line">erode_img.shape</span><br><span class="line">plt.imshow(erode_img)</span><br></pre></td></tr></table></figure>

腐蚀后结果:

!['腐蚀后结果'](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/腐蚀后.png)

膨胀:

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">side_len =<span class="number">3</span></span><br><span class="line"></span><br><span class="line">kernel = np.ones((side_len,side_len))</span><br><span class="line">dilate_img = cv2.dilate(erode_img,kernel,iterations = <span class="number">1</span>)</span><br><span class="line">plt.imshow(dilate_img)</span><br></pre></td></tr></table></figure>

膨胀后:

!['膨胀后'](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/膨胀后.png)

### 替换背景

一旦替换模板比较准确,人物背景抠图就比较容易了.下面是背景图:

!['背景图'](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/背景图.png)

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n_row,n_col = dilate_img.shape</span><br><span class="line"></span><br><span class="line">start_coor = [<span class="number">10</span>,<span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> range(n_row):</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> range(n_col):</span><br><span class="line">        <span class="keyword">if</span> dilate_img[row][col] == <span class="number">255</span>:</span><br><span class="line">            back_img[start_coor[<span class="number">0</span>] + row][start_coor[<span class="number">1</span>] + col] = blue_photo[row][col]</span><br><span class="line"></span><br><span class="line">plt.imshow(back_img)</span><br></pre></td></tr></table></figure>

根据模板替换后:

!['人物背景抠图后'](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/替换示例图片-1580097685097.png)

最后根据原有的图片尺寸切割出结果图像就可以实现替换了.

## 多图测试

网上爬取了十张大小不一图像测试,缩放到200*150(如有侵权请告知,谢谢).

原图像:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/效果原图像-1580099162567.png)

替换后:

![](https://blog-1253764997.cos.ap-chongqing.myqcloud.com/效果图-1580099178206.png)

]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
        <tag>Demo</tag>
      </tags>
  </entry>
</search>
